{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CEqf_9j_Gd-V"
      },
      "source": [
        "# Configurar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r_8buVqoFNnO"
      },
      "outputs": [],
      "source": [
        "# === 00) CONFIGURAR VARI√ÅVEIS ===\n",
        "\n",
        "import os\n",
        "\n",
        "# Endere√ßo do link compartilhado para Download dos arquivos\n",
        "GOPRO_URL_DEFAULT = \"https://gopro.com/v/40423e24-5ee0-42ce-9ffa-f136954b09dc\"\n",
        "\n",
        "# Modo pode ser \"original\" ou \"compressed\"\n",
        "os.environ[\"GOPRO_DL_MODE\"] = \"compressed\"\n",
        "\n",
        "# Estabelece a API KEy para uso da Open AI\n",
        "os.environ[\"OPENAI_API_KEY\"]=\"YOUR_OPENAI_API_KEY_HERE\"\n",
        "\n",
        "# Define os modelos que ser√£o utilizados\n",
        "OPENAI_WHISPER    = \"whisper-1\"\n",
        "OPENAI_GPT        = \"gpt-4o-mini\"\n",
        "\n",
        "# ======== Op√ß√µes de Ambiente ========\n",
        "MAKE_COMPAT_LINKS = False   # True = cria atalhos legados (\"01 - Original\" / \"01 - Compressed\")\n",
        "HARD_RESET        = True    # True = apaga e recria 01..05 e remove sobras legadas\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qqjVq_poHpKv",
        "outputId": "81f0ccba-24bc-48e3-92fa-721d7480d0da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Instala√ß√£o] Google Chrome...\n",
            "Selecting previously unselected package google-chrome-stable.\n",
            "(Reading database ... 121703 files and directories currently installed.)\n",
            "Preparing to unpack .../google-chrome-stable_current_amd64.deb ...\n",
            "Unpacking google-chrome-stable (142.0.7444.162-1) ...\n",
            "Processing triggers for mailcap (3.70+nmu1ubuntu1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Chrome:  Google Chrome 142.0.7444.162 \n",
            "FFmpeg:  ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n",
            "ExifTool:12.40\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "dpkg: dependency problems prevent configuration of google-chrome-stable:\n",
            " google-chrome-stable depends on libatk-bridge2.0-0 (>= 2.5.3); however:\n",
            "  Package libatk-bridge2.0-0 is not installed.\n",
            " google-chrome-stable depends on libatk1.0-0 (>= 2.11.90); however:\n",
            "  Package libatk1.0-0 is not installed.\n",
            " google-chrome-stable depends on libatspi2.0-0 (>= 2.9.90); however:\n",
            "  Package libatspi2.0-0 is not installed.\n",
            " google-chrome-stable depends on libvulkan1; however:\n",
            "  Package libvulkan1 is not installed.\n",
            " google-chrome-stable depends on libxcomposite1 (>= 1:0.4.4-1); however:\n",
            "  Package libxcomposite1 is not installed.\n",
            "\n",
            "dpkg: error processing package google-chrome-stable (--install):\n",
            " dependency problems - leaving unconfigured\n",
            "Errors were encountered while processing:\n",
            " google-chrome-stable\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/1.8 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[91m‚ï∏\u001b[0m\u001b[90m‚îÅ\u001b[0m \u001b[32m1.7/1.8 MB\u001b[0m \u001b[31m51.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hMounted at /content/99-Drive\n",
            "üîê Drive montado em: /content/99-Drive\n",
            "[OK] selenium v4.38.0\n",
            "[OK] webdriver_manager v4.0.2\n",
            "\n",
            "Config: \n",
            "  URL:  https://gopro.com/v/40423e24-5ee0-42ce-9ffa-f136954b09dc \n",
            "  Modo: original \n",
            "  Labels: ['Qualidade original', 'Qualidade original (4k)', 'Original quality', 'Original Quality', 'Original Quality (4k)', 'Highest quality', 'Full quality']\n",
            "\n",
            "Pastas:\n",
            "  - /content/01 - Downloads\n",
            "  - /content/02 - Mesclado\n",
            "  - /content/03 - Teasers\n",
            "  - /content/04 - Assets\n",
            "  - /content/05 - Final\n"
          ]
        }
      ],
      "source": [
        "# === 01) CONFIGURAR AMBIENTE (limpo + parametriz√°vel: original | compressed) ===\n",
        "# - Instala Chrome / FFmpeg / ExifTool\n",
        "# - Prepara pastas 01..05 SEM duplicar \"compactos\"\n",
        "# - Opcional: cria atalhos legados se MAKE_COMPAT_LINKS=True\n",
        "\n",
        "import os, shutil, pathlib, json, importlib, re\n",
        "\n",
        "# ======== CONFIGURA√á√ïES (vem da c√©lula 00) ========\n",
        "# MAKE_COMPAT_LINKS: define se cria atalhos legados\n",
        "# HARD_RESET: define se apaga e recria pastas\n",
        "\n",
        "ROOT        = pathlib.Path(\"/content\")\n",
        "SETUP_DIR   = ROOT / \"_setup\"          # tempor√°rio p/ .deb do Chrome (apagado ao final)\n",
        "\n",
        "# Montagem do Drive: usar mount real sem espa√ßos e alias com espa√ßos\n",
        "MOUNT_REAL  = ROOT / \"99-Drive\"\n",
        "MOUNT_ALIAS = ROOT / \"99 - Drive\"\n",
        "\n",
        "# ======== Utils ========\n",
        "def _safe_rm(p: pathlib.Path):\n",
        "    try:\n",
        "        if p.is_symlink():\n",
        "            p.unlink()\n",
        "        elif p.exists():\n",
        "            shutil.rmtree(p, ignore_errors=True)\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "def _ensure_dir(p: pathlib.Path):\n",
        "    p.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def ensure_symlink(link: pathlib.Path, target: pathlib.Path):\n",
        "    _safe_rm(link)\n",
        "    try:\n",
        "        link.symlink_to(target, target_is_directory=True)\n",
        "    except Exception:\n",
        "        link.mkdir(parents=True, exist_ok=True)  # fallback se symlink for bloqueado\n",
        "\n",
        "# ======== Estrutura 01..05 (√∫nica, sem \"compactos\") ========\n",
        "DIR_DL        = ROOT / \"01 - Downloads\"\n",
        "DIR_MESCLADO  = ROOT / \"02 - Mesclado\"\n",
        "DIR_TEASERS   = ROOT / \"03 - Teasers\"\n",
        "DIR_ASSETS    = ROOT / \"04 - Assets\"\n",
        "DIR_FINAL     = ROOT / \"05 - Final\"\n",
        "ordered_dirs  = [DIR_DL, DIR_MESCLADO, DIR_TEASERS, DIR_ASSETS, DIR_FINAL]\n",
        "\n",
        "# ======== LIMPEZA TOTAL (se HARD_RESET=True) ========\n",
        "if HARD_RESET:\n",
        "    legacy = [\n",
        "        # atalhos e sobras legadas\n",
        "        ROOT/\"compressed\", ROOT/\"mesclados\", ROOT/\"teasers\", ROOT/\"assets\", ROOT/\"final\",\n",
        "        ROOT/\"01 - Compressed\", ROOT/\"01 - Original\",\n",
        "        ROOT/\"02 - Mesclado\", ROOT/\"03 - Teasers\", ROOT/\"04 - Assets\", ROOT/\"05 - Final\",\n",
        "        ROOT/\"sample_data\", SETUP_DIR,\n",
        "    ]\n",
        "    for p in legacy:\n",
        "        _safe_rm(p)\n",
        "\n",
        "# recria 01..05 limpinhas\n",
        "for d in ordered_dirs:\n",
        "    _ensure_dir(d)\n",
        "\n",
        "# ======== SO: Chrome / FFmpeg / ExifTool ========\n",
        "_ensure_dir(SETUP_DIR)\n",
        "deb_path = str(SETUP_DIR / \"google-chrome-stable_current_amd64.deb\")\n",
        "\n",
        "# apaga .deb perdido antigo (se houver)\n",
        "try: os.remove(str(ROOT / \"google-chrome-stable_current_amd64.deb\"))\n",
        "except Exception: pass\n",
        "\n",
        "get_ipython().run_cell_magic('bash', '', f'''\n",
        "set -euo pipefail\n",
        "if ! command -v google-chrome >/dev/null 2>&1; then\n",
        "  echo \"[Instala√ß√£o] Google Chrome...\"\n",
        "  wget -q -O \"{deb_path}\" https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb\n",
        "  apt-get -qq update\n",
        "  dpkg -i \"{deb_path}\" || true\n",
        "  apt-get -qq -y -f install >/dev/null\n",
        "else\n",
        "  echo \"[OK] Chrome j√° instalado.\"\n",
        "fi\n",
        "apt-get -qq update\n",
        "apt-get -qq install -y exiftool ffmpeg >/dev/null\n",
        "echo -n \"Chrome:  \"; google-chrome --version || true\n",
        "echo -n \"FFmpeg:  \"; ffmpeg -version | head -n 1 || true\n",
        "echo -n \"ExifTool:\"; exiftool -ver || true\n",
        "''')\n",
        "\n",
        "# remove a PASTA /content/_setup inteira (n√£o √© mais necess√°ria)\n",
        "shutil.rmtree(SETUP_DIR, ignore_errors=True)\n",
        "\n",
        "# ======== Deps Python ========\n",
        "get_ipython().run_line_magic('pip', 'install -q --upgrade pip')\n",
        "get_ipython().run_line_magic('pip', 'install -q selenium webdriver-manager')\n",
        "\n",
        "# ======== Vari√°veis + r√≥tulos (PARAMETRIZADO) ========\n",
        "GOPRO_DL_MODE = os.environ.get(\"GOPRO_DL_MODE\", \"original\").strip().lower()\n",
        "if GOPRO_DL_MODE not in {\"original\", \"compressed\"}:\n",
        "    GOPRO_DL_MODE = \"original\"\n",
        "\n",
        "# Labels para detec√ß√£o na UI da GoPro (pt/en comuns)\n",
        "dl_labels = {\n",
        "    \"original\": [\n",
        "        \"Qualidade original\", \"Qualidade original (4k)\", \"Original quality\", \"Original Quality\",\n",
        "        \"Original Quality (4k)\", \"Highest quality\", \"Full quality\"\n",
        "    ],\n",
        "    \"compressed\": [\n",
        "        \"Compactado\", \"Qualidade reduzida\", \"Compressed\", \"Smaller size\", \"Space saver\", \"HEVC (compressed)\"\n",
        "    ],\n",
        "}\n",
        "\n",
        "os.environ[\"GOPRO_URL\"]        = os.environ.get(\"GOPRO_URL\", GOPRO_URL_DEFAULT)\n",
        "os.environ[\"GOPRO_DL_MODE\"]    = GOPRO_DL_MODE\n",
        "os.environ[\"GOPRO_DL_LABELS\"]  = json.dumps(dl_labels, ensure_ascii=False)\n",
        "\n",
        "# Binaries\n",
        "os.environ[\"GOOGLE_CHROME_BIN\"]  = shutil.which(\"google-chrome\") or \"/usr/bin/google-chrome\"\n",
        "os.environ[\"GOOGLE_CHROME_SHIM\"] = os.environ[\"GOOGLE_CHROME_BIN\"]\n",
        "\n",
        "# exporta paths para as outras c√©lulas (mant√©m compatibilidade do pipeline)\n",
        "os.environ[\"DIR_DOWNLOAD\"] = str(DIR_DL)\n",
        "os.environ[\"DIR_MESCLADO\"] = str(DIR_MESCLADO)\n",
        "os.environ[\"DIR_TEASERS\"]  = str(DIR_TEASERS)\n",
        "os.environ[\"DIR_ASSETS\"]   = str(DIR_ASSETS)\n",
        "os.environ[\"DIR_FINAL\"]    = str(DIR_FINAL)\n",
        "\n",
        "# ======== Monta Drive (real sem espa√ßo) + alias com espa√ßo ========\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    _ensure_dir(MOUNT_REAL)\n",
        "    drive.mount(str(MOUNT_REAL), force_remount=True)\n",
        "    print(f\"üîê Drive montado em: {MOUNT_REAL}\")\n",
        "    ensure_symlink(MOUNT_ALIAS, MOUNT_REAL)\n",
        "except Exception as e:\n",
        "    print(\"‚ö†Ô∏è N√£o consegui montar o Drive agora (ok continuar se n√£o precisar):\", e)\n",
        "\n",
        "# ======== Atalhos de compatibilidade (opcional) ========\n",
        "if MAKE_COMPAT_LINKS:\n",
        "    # Cria atalhos legados apontando para a pasta √∫nica de downloads\n",
        "    ensure_symlink(ROOT/\"01 - Original\",   DIR_DL)\n",
        "    ensure_symlink(ROOT/\"01 - Compressed\", DIR_DL)\n",
        "\n",
        "# ======== Sanity curto ========\n",
        "for mod in (\"selenium\", \"webdriver_manager\"):\n",
        "    try:\n",
        "        print(f\"[OK] {mod} v{getattr(importlib.import_module(mod), '__version__', '?')}\")\n",
        "    except Exception as e:\n",
        "        print(f\"[!] Falha ao importar {mod}: {e}\")\n",
        "\n",
        "print(\"\\nConfig:\",\n",
        "      \"\\n  URL: \", os.environ['GOPRO_URL'],\n",
        "      \"\\n  Modo:\", os.environ['GOPRO_DL_MODE'],\n",
        "      \"\\n  Labels:\", json.loads(os.environ[\"GOPRO_DL_LABELS\"])[os.environ['GOPRO_DL_MODE']])\n",
        "print(\"\\nPastas:\")\n",
        "for d in ordered_dirs:\n",
        "    print(\"  -\", d)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6m9_tbEGZoV"
      },
      "source": [
        "# Coletar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nsFiXuCrFU9-",
        "outputId": "14f866d1-818c-4017-cad4-88fef0accabb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìÅ Pasta de downloads: /content/01 - Downloads\n",
            "üéõÔ∏è Modo: compressed  | Labels: ['Compactado', 'Qualidade reduzida', 'Compressed', 'Smaller size', 'Space saver', 'HEVC (compressed)']\n",
            "üåê Acessando p√°gina: https://gopro.com/v/40423e24-5ee0-42ce-9ffa-f136954b09dc\n",
            "üéöÔ∏è Ajustando slider (se existir)...\n",
            "üìú Carregando itens (PageDown)...\n",
            "üîç Itens encontrados: 94\n",
            "\n",
            "‚û°Ô∏è [1] Menu de contexto‚Ä¶\n",
            "üì• Procurando op√ß√£o: COMPRESSED ‚Ä¶\n",
            "   ‚§∑ Clicado: ‚ÄúCompressed‚Äù\n",
            "‚úÖ Download 1 (compressed) disparado.\n",
            "\n",
            "‚û°Ô∏è [2] Menu de contexto‚Ä¶\n",
            "üì• Procurando op√ß√£o: COMPRESSED ‚Ä¶\n",
            "   ‚§∑ Clicado: ‚ÄúCompressed‚Äù\n",
            "‚úÖ Download 2 (compressed) disparado.\n",
            "\n",
            "‚û°Ô∏è [3] Menu de contexto‚Ä¶\n",
            "üì• Procurando op√ß√£o: COMPRESSED ‚Ä¶\n",
            "   ‚§∑ Clicado: ‚ÄúCompressed‚Äù\n",
            "‚úÖ Download 3 (compressed) disparado.\n",
            "\n",
            "‚û°Ô∏è [4] Menu de contexto‚Ä¶\n",
            "üì• Procurando op√ß√£o: COMPRESSED ‚Ä¶\n",
            "   ‚§∑ Clicado: ‚ÄúCompressed‚Äù\n",
            "‚úÖ Download 4 (compressed) disparado.\n",
            "\n",
            "‚û°Ô∏è [5] Menu de contexto‚Ä¶\n",
            "üì• Procurando op√ß√£o: COMPRESSED ‚Ä¶\n",
            "   ‚§∑ Clicado: ‚ÄúCompressed‚Äù\n",
            "‚úÖ Download 5 (compressed) disparado.\n",
            "\n",
            "‚û°Ô∏è [6] Menu de contexto‚Ä¶\n",
            "üì• Procurando op√ß√£o: COMPRESSED ‚Ä¶\n",
            "   ‚§∑ Clicado: ‚ÄúCompressed‚Äù\n",
            "‚úÖ Download 6 (compressed) disparado.\n",
            "\n",
            "‚û°Ô∏è [7] Menu de contexto‚Ä¶\n",
            "üì• Procurando op√ß√£o: COMPRESSED ‚Ä¶\n",
            "   ‚§∑ Clicado: ‚ÄúCompressed‚Äù\n",
            "‚úÖ Download 7 (compressed) disparado.\n",
            "\n",
            "‚û°Ô∏è [8] Menu de contexto‚Ä¶\n",
            "üì• Procurando op√ß√£o: COMPRESSED ‚Ä¶\n",
            "   ‚§∑ Clicado: ‚ÄúCompressed‚Äù\n",
            "‚úÖ Download 8 (compressed) disparado.\n",
            "\n",
            "‚û°Ô∏è [9] Menu de contexto‚Ä¶\n",
            "üì• Procurando op√ß√£o: COMPRESSED ‚Ä¶\n",
            "   ‚§∑ Clicado: ‚ÄúCompressed‚Äù\n",
            "‚úÖ Download 9 (compressed) disparado.\n",
            "\n",
            "‚û°Ô∏è [10] Menu de contexto‚Ä¶\n",
            "üì• Procurando op√ß√£o: COMPRESSED ‚Ä¶\n",
            "   ‚§∑ Clicado: ‚ÄúCompressed‚Äù\n",
            "‚úÖ Download 10 (compressed) disparado.\n",
            "\n",
            "‚û°Ô∏è [11] Menu de contexto‚Ä¶\n",
            "üì• Procurando op√ß√£o: COMPRESSED ‚Ä¶\n",
            "   ‚§∑ Clicado: ‚ÄúCompressed‚Äù\n",
            "‚úÖ Download 11 (compressed) disparado.\n",
            "\n",
            "‚û°Ô∏è [12] Menu de contexto‚Ä¶\n",
            "üì• Procurando op√ß√£o: COMPRESSED ‚Ä¶\n",
            "   ‚§∑ Clicado: ‚ÄúCompressed‚Äù\n",
            "‚úÖ Download 12 (compressed) disparado.\n",
            "\n",
            "‚û°Ô∏è [13] Menu de contexto‚Ä¶\n",
            "üì• Procurando op√ß√£o: COMPRESSED ‚Ä¶\n",
            "   ‚§∑ Clicado: ‚ÄúCompressed‚Äù\n",
            "‚úÖ Download 13 (compressed) disparado.\n",
            "\n",
            "‚û°Ô∏è [14] Menu de contexto‚Ä¶\n",
            "üì• Procurando op√ß√£o: COMPRESSED ‚Ä¶\n",
            "   ‚§∑ Clicado: ‚ÄúCompressed‚Äù\n",
            "‚úÖ Download 14 (compressed) disparado.\n",
            "\n",
            "‚û°Ô∏è [15] Menu de contexto‚Ä¶\n",
            "üì• Procurando op√ß√£o: COMPRESSED ‚Ä¶\n",
            "   ‚§∑ Clicado: ‚ÄúCompressed‚Äù\n",
            "‚úÖ Download 15 (compressed) disparado.\n",
            "\n",
            "‚û°Ô∏è [16] Menu de contexto‚Ä¶\n",
            "üì• Procurando op√ß√£o: COMPRESSED ‚Ä¶\n",
            "   ‚§∑ Clicado: ‚ÄúCompressed‚Äù\n",
            "‚úÖ Download 16 (compressed) disparado.\n",
            "\n",
            "‚û°Ô∏è [17] Menu de contexto‚Ä¶\n",
            "üì• Procurando op√ß√£o: COMPRESSED ‚Ä¶\n",
            "   ‚§∑ Clicado: ‚ÄúCompressed‚Äù\n",
            "‚úÖ Download 17 (compressed) disparado.\n",
            "\n",
            "‚û°Ô∏è [18] Menu de contexto‚Ä¶\n",
            "üì• Procurando op√ß√£o: COMPRESSED ‚Ä¶\n",
            "   ‚§∑ Clicado: ‚ÄúCompressed‚Äù\n",
            "‚úÖ Download 18 (compressed) disparado.\n",
            "\n",
            "‚û°Ô∏è [19] Menu de contexto‚Ä¶\n",
            "üì• Procurando op√ß√£o: COMPRESSED ‚Ä¶\n",
            "   ‚§∑ Clicado: ‚ÄúCompressed‚Äù\n",
            "‚úÖ Download 19 (compressed) disparado.\n",
            "\n",
            "‚û°Ô∏è [20] Menu de contexto‚Ä¶\n",
            "üì• Procurando op√ß√£o: COMPRESSED ‚Ä¶\n",
            "   ‚§∑ Clicado: ‚ÄúCompressed‚Äù\n",
            "‚úÖ Download 20 (compressed) disparado.\n",
            "\n",
            "‚û°Ô∏è [21] Menu de contexto‚Ä¶\n",
            "üì• Procurando op√ß√£o: COMPRESSED ‚Ä¶\n",
            "   ‚§∑ Clicado: ‚ÄúCompressed‚Äù\n",
            "‚úÖ Download 21 (compressed) disparado.\n",
            "\n",
            "‚û°Ô∏è [22] Menu de contexto‚Ä¶\n",
            "üì• Procurando op√ß√£o: COMPRESSED ‚Ä¶\n",
            "   ‚§∑ Clicado: ‚ÄúCompressed‚Äù\n",
            "‚úÖ Download 22 (compressed) disparado.\n",
            "\n",
            "‚û°Ô∏è [23] Menu de contexto‚Ä¶\n",
            "üì• Procurando op√ß√£o: COMPRESSED ‚Ä¶\n",
            "   ‚§∑ Clicado: ‚ÄúCompressed‚Äù\n",
            "‚úÖ Download 23 (compressed) disparado.\n",
            "\n",
            "‚û°Ô∏è [24] Menu de contexto‚Ä¶\n",
            "üì• Procurando op√ß√£o: COMPRESSED ‚Ä¶\n",
            "   ‚§∑ Clicado: ‚ÄúCompressed‚Äù\n",
            "‚úÖ Download 24 (compressed) disparado.\n",
            "\n",
            "‚û°Ô∏è [25] Menu de contexto‚Ä¶\n",
            "üì• Procurando op√ß√£o: COMPRESSED ‚Ä¶\n",
            "   ‚§∑ Clicado: ‚ÄúCompressed‚Äù\n",
            "‚úÖ Download 25 (compressed) disparado.\n",
            "\n",
            "‚û°Ô∏è [26] Menu de contexto‚Ä¶\n",
            "üì• Procurando op√ß√£o: COMPRESSED ‚Ä¶\n",
            "   ‚§∑ Clicado: ‚ÄúCompressed‚Äù\n",
            "‚úÖ Download 26 (compressed) disparado.\n",
            "\n",
            "‚û°Ô∏è [27] Menu de contexto‚Ä¶\n",
            "üì• Procurando op√ß√£o: COMPRESSED ‚Ä¶\n",
            "   ‚§∑ Clicado: ‚ÄúCompressed‚Äù\n",
            "‚úÖ Download 27 (compressed) disparado.\n",
            "\n",
            "‚û°Ô∏è [28] Menu de contexto‚Ä¶\n",
            "üì• Procurando op√ß√£o: COMPRESSED ‚Ä¶\n",
            "   ‚§∑ Clicado: ‚ÄúCompressed‚Äù\n",
            "‚úÖ Download 28 (compressed) disparado.\n",
            "\n",
            "‚û°Ô∏è [29] Menu de contexto‚Ä¶\n",
            "üì• Procurando op√ß√£o: COMPRESSED ‚Ä¶\n",
            "   ‚§∑ Clicado: ‚ÄúCompressed‚Äù\n",
            "‚úÖ Download 29 (compressed) disparado.\n",
            "\n",
            "‚û°Ô∏è [30] Menu de contexto‚Ä¶\n",
            "üì• Procurando op√ß√£o: COMPRESSED ‚Ä¶\n",
            "   ‚§∑ Clicado: ‚ÄúCompressed‚Äù\n",
            "‚úÖ Download 30 (compressed) disparado.\n",
            "\n",
            "‚û°Ô∏è [31] Menu de contexto‚Ä¶\n",
            "üì• Procurando op√ß√£o: COMPRESSED ‚Ä¶\n",
            "   ‚§∑ Clicado: ‚ÄúCompressed‚Äù\n",
            "‚úÖ Download 31 (compressed) disparado.\n",
            "\n",
            "‚û°Ô∏è [32] Menu de contexto‚Ä¶\n",
            "üì• Procurando op√ß√£o: COMPRESSED ‚Ä¶\n",
            "   ‚§∑ Clicado: ‚ÄúCompressed‚Äù\n",
            "‚úÖ Download 32 (compressed) disparado.\n",
            "\n",
            "‚û°Ô∏è [33] Menu de contexto‚Ä¶\n",
            "üì• Procurando op√ß√£o: COMPRESSED ‚Ä¶\n",
            "   ‚§∑ Clicado: ‚ÄúCompressed‚Äù\n",
            "‚úÖ Download 33 (compressed) disparado.\n",
            "\n",
            "‚û°Ô∏è [34] Menu de contexto‚Ä¶\n",
            "üì• Procurando op√ß√£o: COMPRESSED ‚Ä¶\n",
            "   ‚§∑ Clicado: ‚ÄúCompressed‚Äù\n",
            "‚úÖ Download 34 (compressed) disparado.\n",
            "\n",
            "‚û°Ô∏è [35] Menu de contexto‚Ä¶\n",
            "üì• Procurando op√ß√£o: COMPRESSED ‚Ä¶\n",
            "   ‚§∑ Clicado: ‚ÄúCompressed‚Äù\n",
            "‚úÖ Download 35 (compressed) disparado.\n",
            "\n",
            "‚û°Ô∏è [36] Menu de contexto‚Ä¶\n",
            "üì• Procurando op√ß√£o: COMPRESSED ‚Ä¶\n",
            "   ‚§∑ Clicado: ‚ÄúCompressed‚Äù\n",
            "‚úÖ Download 36 (compressed) disparado.\n",
            "\n",
            "‚û°Ô∏è [37] Menu de contexto‚Ä¶\n",
            "üì• Procurando op√ß√£o: COMPRESSED ‚Ä¶\n",
            "   ‚§∑ Clicado: ‚ÄúCompressed‚Äù\n",
            "‚úÖ Download 37 (compressed) disparado.\n",
            "\n",
            "‚û°Ô∏è [38] Menu de contexto‚Ä¶\n",
            "üì• Procurando op√ß√£o: COMPRESSED ‚Ä¶\n",
            "   ‚§∑ Clicado: ‚ÄúCompressed‚Äù\n",
            "‚úÖ Download 38 (compressed) disparado.\n",
            "\n",
            "‚û°Ô∏è [39] Menu de contexto‚Ä¶\n",
            "üì• Procurando op√ß√£o: COMPRESSED ‚Ä¶\n",
            "   ‚§∑ Clicado: ‚ÄúCompressed‚Äù\n",
            "‚úÖ Download 39 (compressed) disparado.\n",
            "\n",
            "‚û°Ô∏è [40] Menu de contexto‚Ä¶\n",
            "üì• Procurando op√ß√£o: COMPRESSED ‚Ä¶\n",
            "   ‚§∑ Clicado: ‚ÄúCompressed‚Äù\n",
            "‚úÖ Download 40 (compressed) disparado.\n",
            "\n",
            "‚û°Ô∏è [41] Menu de contexto‚Ä¶\n",
            "üì• Procurando op√ß√£o: COMPRESSED ‚Ä¶\n",
            "   ‚§∑ Clicado: ‚ÄúCompressed‚Äù\n",
            "‚úÖ Download 41 (compressed) disparado.\n",
            "\n",
            "‚û°Ô∏è [42] Menu de contexto‚Ä¶\n",
            "üì• Procurando op√ß√£o: COMPRESSED ‚Ä¶\n",
            "   ‚§∑ Clicado: ‚ÄúCompressed‚Äù\n",
            "‚úÖ Download 42 (compressed) disparado.\n",
            "\n",
            "‚û°Ô∏è [43] Menu de contexto‚Ä¶\n",
            "üì• Procurando op√ß√£o: COMPRESSED ‚Ä¶\n",
            "   ‚§∑ Clicado: ‚ÄúCompressed‚Äù\n",
            "‚úÖ Download 43 (compressed) disparado.\n",
            "\n",
            "‚û°Ô∏è [44] Menu de contexto‚Ä¶\n",
            "üì• Procurando op√ß√£o: COMPRESSED ‚Ä¶\n",
            "   ‚§∑ Clicado: ‚ÄúCompressed‚Äù\n",
            "‚úÖ Download 44 (compressed) disparado.\n",
            "\n",
            "‚û°Ô∏è [45] Menu de contexto‚Ä¶\n",
            "üì• Procurando op√ß√£o: COMPRESSED ‚Ä¶\n",
            "   ‚§∑ Clicado: ‚ÄúCompressed‚Äù\n",
            "‚úÖ Download 45 (compressed) disparado.\n",
            "\n",
            "‚û°Ô∏è [46] Menu de contexto‚Ä¶\n",
            "üì• Procurando op√ß√£o: COMPRESSED ‚Ä¶\n",
            "   ‚§∑ Clicado: ‚ÄúCompressed‚Äù\n",
            "‚úÖ Download 46 (compressed) disparado.\n",
            "\n",
            "‚û°Ô∏è [47] Menu de contexto‚Ä¶\n",
            "üì• Procurando op√ß√£o: COMPRESSED ‚Ä¶\n",
            "   ‚§∑ Clicado: ‚ÄúCompressed‚Äù\n",
            "‚úÖ Download 47 (compressed) disparado.\n",
            "\n",
            "‚û°Ô∏è [48] Menu de contexto‚Ä¶\n",
            "üì• Procurando op√ß√£o: COMPRESSED ‚Ä¶\n",
            "   ‚§∑ Clicado: ‚ÄúCompressed‚Äù\n",
            "‚úÖ Download 48 (compressed) disparado.\n",
            "\n",
            "‚û°Ô∏è [49] Menu de contexto‚Ä¶\n",
            "üì• Procurando op√ß√£o: COMPRESSED ‚Ä¶\n",
            "   ‚§∑ Clicado: ‚ÄúCompressed‚Äù\n",
            "‚úÖ Download 49 (compressed) disparado.\n",
            "\n",
            "‚û°Ô∏è [50] Menu de contexto‚Ä¶\n",
            "üì• Procurando op√ß√£o: COMPRESSED ‚Ä¶\n",
            "   ‚§∑ Clicado: ‚ÄúCompressed‚Äù\n",
            "‚úÖ Download 50 (compressed) disparado.\n",
            "\n",
            "‚û°Ô∏è [51] Menu de contexto‚Ä¶\n",
            "üì• Procurando op√ß√£o: COMPRESSED ‚Ä¶\n",
            "   ‚§∑ Clicado: ‚ÄúCompressed‚Äù\n",
            "‚úÖ Download 51 (compressed) disparado.\n",
            "\n",
            "‚û°Ô∏è [52] Menu de contexto‚Ä¶\n",
            "üì• Procurando op√ß√£o: COMPRESSED ‚Ä¶\n",
            "   ‚§∑ Clicado: ‚ÄúCompressed‚Äù\n",
            "‚úÖ Download 52 (compressed) disparado.\n",
            "\n",
            "‚û°Ô∏è [53] Menu de contexto‚Ä¶\n",
            "üì• Procurando op√ß√£o: COMPRESSED ‚Ä¶\n",
            "   ‚§∑ Clicado: ‚ÄúCompressed‚Äù\n",
            "‚úÖ Download 53 (compressed) disparado.\n",
            "\n",
            "‚û°Ô∏è [54] Menu de contexto‚Ä¶\n",
            "üì• Procurando op√ß√£o: COMPRESSED ‚Ä¶\n",
            "   ‚§∑ Clicado: ‚ÄúCompressed‚Äù\n",
            "‚úÖ Download 54 (compressed) disparado.\n",
            "\n",
            "‚û°Ô∏è [55] Menu de contexto‚Ä¶\n",
            "üì• Procurando op√ß√£o: COMPRESSED ‚Ä¶\n",
            "   ‚§∑ Clicado: ‚ÄúCompressed‚Äù\n",
            "‚úÖ Download 55 (compressed) disparado.\n",
            "\n",
            "‚û°Ô∏è [56] Menu de contexto‚Ä¶\n",
            "üì• Procurando op√ß√£o: COMPRESSED ‚Ä¶\n",
            "   ‚§∑ Clicado: ‚ÄúCompressed‚Äù\n",
            "‚úÖ Download 56 (compressed) disparado.\n",
            "\n",
            "‚û°Ô∏è [57] Menu de contexto‚Ä¶\n",
            "üì• Procurando op√ß√£o: COMPRESSED ‚Ä¶\n",
            "   ‚§∑ Clicado: ‚ÄúCompressed‚Äù\n",
            "‚úÖ Download 57 (compressed) disparado.\n",
            "\n",
            "‚û°Ô∏è [58] Menu de contexto‚Ä¶\n",
            "üì• Procurando op√ß√£o: COMPRESSED ‚Ä¶\n",
            "   ‚§∑ Clicado: ‚ÄúCompressed‚Äù\n",
            "‚úÖ Download 58 (compressed) disparado.\n",
            "\n",
            "‚û°Ô∏è [59] Menu de contexto‚Ä¶\n",
            "üì• Procurando op√ß√£o: COMPRESSED ‚Ä¶\n",
            "   ‚§∑ Clicado: ‚ÄúCompressed‚Äù\n",
            "‚úÖ Download 59 (compressed) disparado.\n",
            "\n",
            "‚û°Ô∏è [60] Menu de contexto‚Ä¶\n",
            "üì• Procurando op√ß√£o: COMPRESSED ‚Ä¶\n",
            "   ‚§∑ Clicado: ‚ÄúCompressed‚Äù\n",
            "‚úÖ Download 60 (compressed) disparado.\n",
            "\n",
            "‚û°Ô∏è [61] Menu de contexto‚Ä¶\n",
            "üì• Procurando op√ß√£o: COMPRESSED ‚Ä¶\n",
            "   ‚§∑ Clicado: ‚ÄúCompressed‚Äù\n",
            "‚úÖ Download 61 (compressed) disparado.\n",
            "\n",
            "‚û°Ô∏è [62] Menu de contexto‚Ä¶\n",
            "üì• Procurando op√ß√£o: COMPRESSED ‚Ä¶\n",
            "   ‚§∑ Clicado: ‚ÄúCompressed‚Äù\n",
            "‚úÖ Download 62 (compressed) disparado.\n",
            "\n",
            "‚û°Ô∏è [63] Menu de contexto‚Ä¶\n",
            "üì• Procurando op√ß√£o: COMPRESSED ‚Ä¶\n",
            "   ‚§∑ Clicado: ‚ÄúCompressed‚Äù\n",
            "‚úÖ Download 63 (compressed) disparado.\n",
            "\n",
            "‚û°Ô∏è [64] Menu de contexto‚Ä¶\n",
            "üì• Procurando op√ß√£o: COMPRESSED ‚Ä¶\n",
            "   ‚§∑ Clicado: ‚ÄúCompressed‚Äù\n",
            "‚úÖ Download 64 (compressed) disparado.\n",
            "\n",
            "‚û°Ô∏è [65] Menu de contexto‚Ä¶\n",
            "üì• Procurando op√ß√£o: COMPRESSED ‚Ä¶\n",
            "   ‚§∑ Clicado: ‚ÄúCompressed‚Äù\n",
            "‚úÖ Download 65 (compressed) disparado.\n",
            "\n",
            "‚û°Ô∏è [66] Menu de contexto‚Ä¶\n",
            "üì• Procurando op√ß√£o: COMPRESSED ‚Ä¶\n",
            "   ‚§∑ Clicado: ‚ÄúCompressed‚Äù\n",
            "‚úÖ Download 66 (compressed) disparado.\n",
            "\n",
            "‚û°Ô∏è [67] Menu de contexto‚Ä¶\n",
            "üì• Procurando op√ß√£o: COMPRESSED ‚Ä¶\n",
            "   ‚§∑ Clicado: ‚ÄúCompressed‚Äù\n",
            "‚úÖ Download 67 (compressed) disparado.\n",
            "\n",
            "‚û°Ô∏è [68] Menu de contexto‚Ä¶\n",
            "üì• Procurando op√ß√£o: COMPRESSED ‚Ä¶\n",
            "   ‚§∑ Clicado: ‚ÄúCompressed‚Äù\n",
            "‚úÖ Download 68 (compressed) disparado.\n",
            "\n",
            "‚û°Ô∏è [69] Menu de contexto‚Ä¶\n",
            "üì• Procurando op√ß√£o: COMPRESSED ‚Ä¶\n",
            "   ‚§∑ Clicado: ‚ÄúCompressed‚Äù\n",
            "‚úÖ Download 69 (compressed) disparado.\n",
            "\n",
            "‚û°Ô∏è [70] Menu de contexto‚Ä¶\n",
            "üì• Procurando op√ß√£o: COMPRESSED ‚Ä¶\n",
            "   ‚§∑ Clicado: ‚ÄúCompressed‚Äù\n",
            "‚úÖ Download 70 (compressed) disparado.\n",
            "\n",
            "‚û°Ô∏è [71] Menu de contexto‚Ä¶\n",
            "üì• Procurando op√ß√£o: COMPRESSED ‚Ä¶\n",
            "   ‚§∑ Clicado: ‚ÄúCompressed‚Äù\n",
            "‚úÖ Download 71 (compressed) disparado.\n",
            "\n",
            "‚û°Ô∏è [72] Menu de contexto‚Ä¶\n",
            "üì• Procurando op√ß√£o: COMPRESSED ‚Ä¶\n",
            "   ‚§∑ Clicado: ‚ÄúCompressed‚Äù\n",
            "‚úÖ Download 72 (compressed) disparado.\n",
            "\n",
            "‚û°Ô∏è [73] Menu de contexto‚Ä¶\n",
            "üì• Procurando op√ß√£o: COMPRESSED ‚Ä¶\n",
            "   ‚§∑ Clicado: ‚ÄúCompressed‚Äù\n",
            "‚úÖ Download 73 (compressed) disparado.\n",
            "\n",
            "‚û°Ô∏è [74] Menu de contexto‚Ä¶\n",
            "üì• Procurando op√ß√£o: COMPRESSED ‚Ä¶\n",
            "   ‚§∑ Clicado: ‚ÄúCompressed‚Äù\n",
            "‚úÖ Download 74 (compressed) disparado.\n",
            "\n",
            "‚û°Ô∏è [75] Menu de contexto‚Ä¶\n",
            "üì• Procurando op√ß√£o: COMPRESSED ‚Ä¶\n",
            "   ‚§∑ Clicado: ‚ÄúCompressed‚Äù\n",
            "‚úÖ Download 75 (compressed) disparado.\n",
            "\n",
            "‚û°Ô∏è [76] Menu de contexto‚Ä¶\n",
            "üì• Procurando op√ß√£o: COMPRESSED ‚Ä¶\n",
            "   ‚§∑ Clicado: ‚ÄúCompressed‚Äù\n",
            "‚úÖ Download 76 (compressed) disparado.\n",
            "\n",
            "‚û°Ô∏è [77] Menu de contexto‚Ä¶\n",
            "üì• Procurando op√ß√£o: COMPRESSED ‚Ä¶\n",
            "   ‚§∑ Clicado: ‚ÄúCompressed‚Äù\n",
            "‚úÖ Download 77 (compressed) disparado.\n",
            "\n",
            "‚û°Ô∏è [78] Menu de contexto‚Ä¶\n",
            "üì• Procurando op√ß√£o: COMPRESSED ‚Ä¶\n",
            "   ‚§∑ Clicado: ‚ÄúCompressed‚Äù\n",
            "‚úÖ Download 78 (compressed) disparado.\n",
            "\n",
            "‚û°Ô∏è [79] Menu de contexto‚Ä¶\n",
            "üì• Procurando op√ß√£o: COMPRESSED ‚Ä¶\n",
            "   ‚§∑ Clicado: ‚ÄúCompressed‚Äù\n",
            "‚úÖ Download 79 (compressed) disparado.\n",
            "\n",
            "‚û°Ô∏è [80] Menu de contexto‚Ä¶\n",
            "üì• Procurando op√ß√£o: COMPRESSED ‚Ä¶\n",
            "   ‚§∑ Clicado: ‚ÄúCompressed‚Äù\n",
            "‚úÖ Download 80 (compressed) disparado.\n",
            "\n",
            "‚û°Ô∏è [81] Menu de contexto‚Ä¶\n",
            "üì• Procurando op√ß√£o: COMPRESSED ‚Ä¶\n",
            "   ‚§∑ Clicado: ‚ÄúCompressed‚Äù\n",
            "‚úÖ Download 81 (compressed) disparado.\n",
            "\n",
            "‚û°Ô∏è [82] Menu de contexto‚Ä¶\n",
            "üì• Procurando op√ß√£o: COMPRESSED ‚Ä¶\n",
            "   ‚§∑ Clicado: ‚ÄúCompressed‚Äù\n",
            "‚úÖ Download 82 (compressed) disparado.\n",
            "\n",
            "‚û°Ô∏è [83] Menu de contexto‚Ä¶\n",
            "üì• Procurando op√ß√£o: COMPRESSED ‚Ä¶\n",
            "   ‚§∑ Clicado: ‚ÄúCompressed‚Äù\n",
            "‚úÖ Download 83 (compressed) disparado.\n",
            "\n",
            "‚û°Ô∏è [84] Menu de contexto‚Ä¶\n",
            "üì• Procurando op√ß√£o: COMPRESSED ‚Ä¶\n",
            "   ‚§∑ Clicado: ‚ÄúCompressed‚Äù\n",
            "‚úÖ Download 84 (compressed) disparado.\n",
            "\n",
            "‚û°Ô∏è [85] Menu de contexto‚Ä¶\n",
            "üì• Procurando op√ß√£o: COMPRESSED ‚Ä¶\n",
            "   ‚§∑ Clicado: ‚ÄúCompressed‚Äù\n",
            "‚úÖ Download 85 (compressed) disparado.\n",
            "\n",
            "‚û°Ô∏è [86] Menu de contexto‚Ä¶\n",
            "üì• Procurando op√ß√£o: COMPRESSED ‚Ä¶\n",
            "   ‚§∑ Clicado: ‚ÄúCompressed‚Äù\n",
            "‚úÖ Download 86 (compressed) disparado.\n",
            "\n",
            "‚û°Ô∏è [87] Menu de contexto‚Ä¶\n",
            "üì• Procurando op√ß√£o: COMPRESSED ‚Ä¶\n",
            "   ‚§∑ Clicado: ‚ÄúCompressed‚Äù\n",
            "‚úÖ Download 87 (compressed) disparado.\n",
            "\n",
            "‚û°Ô∏è [88] Menu de contexto‚Ä¶\n",
            "üì• Procurando op√ß√£o: COMPRESSED ‚Ä¶\n",
            "   ‚§∑ Clicado: ‚ÄúCompressed‚Äù\n",
            "‚úÖ Download 88 (compressed) disparado.\n",
            "\n",
            "‚û°Ô∏è [89] Menu de contexto‚Ä¶\n",
            "üì• Procurando op√ß√£o: COMPRESSED ‚Ä¶\n",
            "   ‚§∑ Clicado: ‚ÄúCompressed‚Äù\n",
            "‚úÖ Download 89 (compressed) disparado.\n",
            "\n",
            "‚û°Ô∏è [90] Menu de contexto‚Ä¶\n",
            "üì• Procurando op√ß√£o: COMPRESSED ‚Ä¶\n",
            "   ‚§∑ Clicado: ‚ÄúCompressed‚Äù\n",
            "‚úÖ Download 90 (compressed) disparado.\n",
            "\n",
            "‚û°Ô∏è [91] Menu de contexto‚Ä¶\n",
            "üì• Procurando op√ß√£o: COMPRESSED ‚Ä¶\n",
            "   ‚§∑ Clicado: ‚ÄúCompressed‚Äù\n",
            "‚úÖ Download 91 (compressed) disparado.\n",
            "\n",
            "‚û°Ô∏è [92] Menu de contexto‚Ä¶\n",
            "üì• Procurando op√ß√£o: COMPRESSED ‚Ä¶\n",
            "   ‚§∑ Clicado: ‚ÄúCompressed‚Äù\n",
            "‚úÖ Download 92 (compressed) disparado.\n",
            "\n",
            "‚û°Ô∏è [93] Menu de contexto‚Ä¶\n",
            "üì• Procurando op√ß√£o: COMPRESSED ‚Ä¶\n",
            "   ‚§∑ Clicado: ‚ÄúCompressed‚Äù\n",
            "‚úÖ Download 93 (compressed) disparado.\n",
            "\n",
            "‚û°Ô∏è [94] Menu de contexto‚Ä¶\n",
            "üì• Procurando op√ß√£o: COMPRESSED ‚Ä¶\n",
            "   ‚§∑ Clicado: ‚ÄúCompressed‚Äù\n",
            "‚úÖ Download 94 (compressed) disparado.\n",
            "‚è≥ Aguardando finaliza√ß√£o dos downloads...\n",
            "‚úÖ Downloads finalizados (ou timeout).\n",
            "üèÅ Conclu√≠do. Arquivos em: /content/01 - Downloads\n",
            "üö™ Fechando navegador.\n"
          ]
        }
      ],
      "source": [
        "# === COLETAR (Original/Compressed, Colab-friendly) =============================\n",
        "# - Abre a URL da GoPro (env GOPRO_URL)\n",
        "# - Para cada miniatura, menu de contexto ‚Üí clica em r√≥tulo conforme GOPRO_DL_MODE\n",
        "#   (original | compressed), com labels vindos de GOPRO_DL_LABELS (fallback inclu√≠do)\n",
        "# - Downloads headless em /content/01 - Downloads (ou DIR_DOWNLOAD do env)\n",
        "# - Espera .crdownload/.tmp/.part sumirem antes de encerrar\n",
        "\n",
        "import os, time, json, shutil\n",
        "from typing import Optional, List\n",
        "\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.common.action_chains import ActionChains\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from selenium.webdriver.chrome.service import Service as ChromeService\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "from webdriver_manager.chrome import ChromeDriverManager\n",
        "\n",
        "# --- paths e params (v√™m da c√©lula 01) -----------------------------------------\n",
        "DOWNLOAD_DIR = os.environ.get(\"DIR_DOWNLOAD\", \"/content/01 - Downloads\")\n",
        "GOPRO_URL    = os.environ.get(\"GOPRO_URL\", \"\").strip()\n",
        "MODE         = os.environ.get(\"GOPRO_DL_MODE\", \"original\").strip().lower()\n",
        "\n",
        "# Labels (pt/en) para ambos os modos; sobrescrev√≠veis via env GOPRO_DL_LABELS\n",
        "fallback_labels = {\n",
        "    \"original\": [\n",
        "        \"Qualidade original\", \"Qualidade original (4k)\", \"Original quality\",\n",
        "        \"Original Quality\", \"Original Quality (4k)\", \"Highest quality\", \"Full quality\", \"Original\"\n",
        "    ],\n",
        "    \"compressed\": [\n",
        "        \"Compactado\", \"Qualidade reduzida\", \"Compressed\", \"Smaller size\",\n",
        "        \"Space saver\", \"HEVC (compressed)\", \"Reduced quality\", \"Compressed quality\"\n",
        "    ],\n",
        "}\n",
        "try:\n",
        "    env_labels = json.loads(os.environ.get(\"GOPRO_DL_LABELS\", \"{}\"))\n",
        "except Exception:\n",
        "    env_labels = {}\n",
        "DL_LABELS = env_labels.get(MODE, fallback_labels.get(MODE, fallback_labels[\"original\"]))\n",
        "\n",
        "MAX_SCROLL_PAGEDOWN = 60  # aumenta se a p√°gina for muito longa\n",
        "\n",
        "# --- utils ---------------------------------------------------------------------\n",
        "def clear_folder(folder_path: str) -> None:\n",
        "    os.makedirs(folder_path, exist_ok=True)\n",
        "    for filename in os.listdir(folder_path):\n",
        "        fp = os.path.join(folder_path, filename)\n",
        "        try:\n",
        "            if os.path.isfile(fp) or os.path.islink(fp):\n",
        "                os.unlink(fp)\n",
        "            elif os.path.isdir(fp):\n",
        "                shutil.rmtree(fp)\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Erro ao apagar {fp}: {e}\")\n",
        "\n",
        "def find_chrome_binary() -> Optional[str]:\n",
        "    for p in [\n",
        "        os.environ.get(\"GOOGLE_CHROME_BIN\"),\n",
        "        os.environ.get(\"GOOGLE_CHROME_SHIM\"),\n",
        "        \"/usr/bin/google-chrome\",\n",
        "        \"/opt/google/chrome/google-chrome\",\n",
        "        \"/usr/bin/chromium-browser\",\n",
        "        \"/usr/bin/chromium\",\n",
        "    ]:\n",
        "        if p and os.path.exists(p):\n",
        "            return p\n",
        "    return None\n",
        "\n",
        "def wait_for_downloads(folder: str, idle_seconds: int = 10, timeout: int = 3600) -> None:\n",
        "    print(\"‚è≥ Aguardando finaliza√ß√£o dos downloads...\")\n",
        "    start = time.time()\n",
        "    last_change = time.time()\n",
        "\n",
        "    def snapshot():\n",
        "        files = []\n",
        "        for root, _, fs in os.walk(folder):\n",
        "            for f in fs:\n",
        "                files.append(os.path.join(root, f))\n",
        "        return sorted(files)\n",
        "\n",
        "    prev = snapshot()\n",
        "    while True:\n",
        "        time.sleep(2)\n",
        "        curr = snapshot()\n",
        "\n",
        "        if curr != prev:\n",
        "            last_change = time.time()\n",
        "            prev = curr\n",
        "\n",
        "        pend = [f for f in curr if f.endswith((\".crdownload\", \".tmp\", \".part\", \".partial\"))]\n",
        "        if not pend and (time.time() - last_change) >= idle_seconds:\n",
        "            break\n",
        "\n",
        "        if (time.time() - start) > timeout:\n",
        "            print(\"‚ö†Ô∏è Timeout atingido ‚Äî prosseguindo mesmo assim.\")\n",
        "            break\n",
        "    print(\"‚úÖ Downloads finalizados (ou timeout).\")\n",
        "\n",
        "def build_driver(download_path: str, lang: str = \"pt-BR\") -> webdriver.Chrome:\n",
        "    chrome_options = Options()\n",
        "    chrome_options.add_experimental_option(\"prefs\", {\n",
        "        \"download.default_directory\": download_path,\n",
        "        \"download.prompt_for_download\": False,\n",
        "        \"download.directory_upgrade\": True,\n",
        "        \"safebrowsing.enabled\": True,\n",
        "    })\n",
        "\n",
        "    chrome_binary = find_chrome_binary()\n",
        "    if not chrome_binary:\n",
        "        raise SystemExit(\"‚ùå Chrome n√£o encontrado; execute a c√©lula de configura√ß√£o primeiro.\")\n",
        "    chrome_options.binary_location = chrome_binary\n",
        "\n",
        "    for flag in [\n",
        "        \"--headless=new\",\n",
        "        \"--no-sandbox\",\n",
        "        \"--disable-dev-shm-usage\",\n",
        "        \"--window-size=1920,1080\",\n",
        "        f\"--lang={lang}\",\n",
        "        \"--disable-gpu\",\n",
        "        \"--disable-extensions\",\n",
        "        \"--disable-blink-features=AutomationControlled\",\n",
        "        \"--disable-features=TranslateUI\",\n",
        "    ]:\n",
        "        chrome_options.add_argument(flag)\n",
        "\n",
        "    driver = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()),\n",
        "                              options=chrome_options)\n",
        "\n",
        "    # Habilita downloads headless via DevTools (v√°rias tentativas por compat.)\n",
        "    for method in (\"Page.setDownloadBehavior\", \"Browser.setDownloadBehavior\"):\n",
        "        try:\n",
        "            driver.execute_cdp_cmd(method, {\"behavior\": \"allow\", \"downloadPath\": download_path})\n",
        "            break\n",
        "        except Exception:\n",
        "            pass\n",
        "    return driver\n",
        "\n",
        "def close_banners_and_cookies(driver, wait):\n",
        "    for t in (\"Accept\", \"I agree\", \"Aceitar\", \"Concordo\", \"OK\", \"Got it\"):\n",
        "        try:\n",
        "            btn = wait.until(EC.element_to_be_clickable((By.XPATH, f\"//button[contains(., '{t}')]\")))\n",
        "            btn.click()\n",
        "            time.sleep(0.4)\n",
        "            break\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "def get_thumbs(driver) -> List:\n",
        "    els = driver.find_elements(By.XPATH, \"//*[contains(@class,'Grid_multiSelect')]\")\n",
        "    if not els:\n",
        "        els = driver.find_elements(By.XPATH, \"//*[contains(@class,'Grid_') and contains(@class,'multiSelect')]\")\n",
        "    if not els:\n",
        "        els = driver.find_elements(By.XPATH, \"//*[@role='gridcell' or @data-testid]\")\n",
        "    return els\n",
        "\n",
        "def click_menu_label(driver, labels: List[str]) -> bool:\n",
        "    \"\"\"\n",
        "    Procura por qualquer r√≥tulo da lista (case-insensitive, pt/en).\n",
        "    Retorna True se clicou, False se n√£o achou.\n",
        "    \"\"\"\n",
        "    # normaliza para lowercase com diacr√≠ticos\n",
        "    for lbl in labels:\n",
        "        q = lbl.lower()\n",
        "        for tag in (\"p\", \"div\", \"span\", \"li\", \"button\"):\n",
        "            try:\n",
        "                el = WebDriverWait(driver, 6).until(\n",
        "                    EC.element_to_be_clickable(\n",
        "                        (By.XPATH,\n",
        "                         f\"//{tag}[contains(translate(.,\"\n",
        "                         f\"'ABCDEFGHIJKLMNOPQRSTUVWXYZ√á√Å√â√ç√ì√ö√Ç√ä√é√î√õ√É√ï',\"\n",
        "                         f\"'abcdefghijklmnopqrstuvwxyz√ß√°√©√≠√≥√∫√¢√™√Æ√¥√ª√£√µ'),\"\n",
        "                         f\" '{q}')]\")\n",
        "                    )\n",
        "                )\n",
        "                el.click()\n",
        "                print(f\"   ‚§∑ Clicado: ‚Äú{lbl}‚Äù\")\n",
        "                return True\n",
        "            except Exception:\n",
        "                pass\n",
        "    return False\n",
        "\n",
        "# --- fluxo principal -----------------------------------------------------------\n",
        "def coletar(url: str):\n",
        "    if not url:\n",
        "        raise ValueError(\"Defina os.environ['GOPRO_URL'] com a URL da GoPro (ou passe a URL diretamente).\")\n",
        "\n",
        "    download_path = DOWNLOAD_DIR\n",
        "    print(f\"üìÅ Pasta de downloads: {download_path}\")\n",
        "    print(f\"üéõÔ∏è Modo: {MODE}  | Labels: {DL_LABELS}\")\n",
        "    clear_folder(download_path)\n",
        "\n",
        "    driver = build_driver(download_path, lang=\"pt-BR\")\n",
        "    wait = WebDriverWait(driver, 20)\n",
        "\n",
        "    print(f\"üåê Acessando p√°gina: {url}\")\n",
        "    driver.get(url)\n",
        "\n",
        "    try:\n",
        "        time.sleep(5)  # respiro inicial\n",
        "        close_banners_and_cookies(driver, wait)\n",
        "\n",
        "        print(\"üéöÔ∏è Ajustando slider (se existir)...\")\n",
        "        try:\n",
        "            slider = wait.until(EC.presence_of_element_located((By.XPATH, \"//input[@type='range']\")))\n",
        "            try:\n",
        "                ActionChains(driver).click_and_hold(slider).move_by_offset(-300, 0).release().perform()\n",
        "            except Exception:\n",
        "                driver.execute_script(\n",
        "                    \"arguments[0].value = arguments[0].min; arguments[0].dispatchEvent(new Event('input'));\", slider\n",
        "                )\n",
        "            time.sleep(1.0)\n",
        "        except Exception:\n",
        "            print(\"‚ÑπÔ∏è Slider n√£o encontrado; seguindo.\")\n",
        "\n",
        "        # Scroll/lazy-load at√© estabilizar\n",
        "        print(\"üìú Carregando itens (PageDown)...\")\n",
        "        body = driver.find_element(By.TAG_NAME, \"body\")\n",
        "        last_count = 0\n",
        "        stable_rounds = 0\n",
        "        for _ in range(MAX_SCROLL_PAGEDOWN):\n",
        "            body.send_keys(Keys.PAGE_DOWN); time.sleep(0.2)\n",
        "            thumbs = get_thumbs(driver)\n",
        "            if len(thumbs) == last_count:\n",
        "                stable_rounds += 1\n",
        "            else:\n",
        "                stable_rounds = 0\n",
        "                last_count = len(thumbs)\n",
        "            if stable_rounds >= 5:\n",
        "                break\n",
        "        for _ in range(6):  # melhora visibilidade do topo\n",
        "            body.send_keys(Keys.PAGE_UP); time.sleep(0.1)\n",
        "\n",
        "        videos = get_thumbs(driver)\n",
        "        print(f\"üîç Itens encontrados: {len(videos)}\")\n",
        "\n",
        "        # Dispara menu de contexto ‚Üí label conforme MODE\n",
        "        for i, video in enumerate(videos, 1):\n",
        "            try:\n",
        "                print(f\"\\n‚û°Ô∏è [{i}] Menu de contexto‚Ä¶\")\n",
        "                ActionChains(driver).move_to_element(video).context_click(video).perform()\n",
        "                time.sleep(0.4)\n",
        "\n",
        "                print(f\"üì• Procurando op√ß√£o: {MODE.upper()} ‚Ä¶\")\n",
        "                if click_menu_label(driver, DL_LABELS):\n",
        "                    print(f\"‚úÖ Download {i} ({MODE}) disparado.\")\n",
        "                else:\n",
        "                    print(f\"‚ö†Ô∏è Op√ß√£o de qualidade '{MODE}' n√£o encontrada.\")\n",
        "\n",
        "                # fecha o menu clicando fora e d√° respiro\n",
        "                ActionChains(driver).move_by_offset(0, 0).click().perform()\n",
        "                time.sleep(3.0)\n",
        "\n",
        "                # a cada ~20 itens, for√ßa mais scroll (mant√©m lazy-load)\n",
        "                if i % 20 == 0:\n",
        "                    for _ in range(3):\n",
        "                        body.send_keys(Keys.PAGE_DOWN); time.sleep(0.15)\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"‚ö†Ô∏è Erro no item {i}: {e}\")\n",
        "                try:\n",
        "                    ActionChains(driver).move_by_offset(0, 0).click().perform()\n",
        "                except Exception:\n",
        "                    pass\n",
        "                continue\n",
        "\n",
        "        # Espera os downloads realmente terminarem\n",
        "        wait_for_downloads(download_path, idle_seconds=12, timeout=3600)\n",
        "        print(\"üèÅ Conclu√≠do. Arquivos em:\", download_path)\n",
        "\n",
        "    finally:\n",
        "        print(\"üö™ Fechando navegador.\")\n",
        "        driver.quit()\n",
        "\n",
        "# --- EXECU√á√ÉO DIRETA NO COLAB --------------------------------------------------\n",
        "coletar(GOPRO_URL)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IgYygLDOJmbc"
      },
      "source": [
        "# Listar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_YYV5s6Jt20",
        "outputId": "14a1d7c4-48c9-40a1-c3a8-0b4fd3762e41"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìÇ Listando v√≠deos (ordem: NOME) ‚Äî pasta: /content/01 - Downloads\n",
            "Arquivo                                    Tamanho   Dura√ß√£o     FPS    Codec  Resolu√ß√£o  M√≠dia Criada (info)\n",
            "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "GX016562.MP4                               19.89 MB     00:51   29.97     hevc   1280x720  2025:11:17 05:32:24\n",
            "GX016563.MP4                                10.9 MB     00:27   29.97     hevc   1280x720  2025:11:17 04:30:47\n",
            "GX016564.MP4                               14.09 MB     00:35   29.97     hevc   1280x720  2025:11:17 04:32:20\n",
            "GX016565.MP4                               16.42 MB     00:42   29.97     hevc   1280x720  2025:11:17 04:34:59\n",
            "GX016566.MP4                               20.69 MB     00:53   29.97     hevc   1280x720  2025:11:17 04:36:15\n",
            "GX016567.MP4                               14.07 MB     00:35   29.97     hevc   1280x720  2025:11:17 04:35:56\n",
            "GX016568.MP4                                7.65 MB     00:19   29.97     hevc   1280x720  2025:11:17 04:37:51\n",
            "GX016569.MP4                               18.73 MB     00:48   29.97     hevc   1280x720  2025:11:17 04:38:39\n",
            "GX016570.MP4                               14.43 MB     00:36   29.97     hevc   1280x720  2025:11:17 04:39:08\n",
            "GX016571.MP4                                5.19 MB     00:12   29.97     hevc   1280x720  2025:11:17 04:39:04\n",
            "GX016574.MP4                                8.25 MB     00:20   29.97     hevc   1280x720  2025:11:17 04:47:03\n",
            "GX016575.MP4                               10.58 MB     00:27   29.97     hevc   1280x720  2025:11:17 04:48:33\n",
            "GX016576.MP4                               31.06 MB     01:20   29.97     hevc   1280x720  2025:11:17 04:50:32\n",
            "GX016577.MP4                               21.81 MB     00:56   29.97     hevc   1280x720  2025:11:17 04:51:36\n",
            "GX016578.MP4                               13.64 MB     00:34   29.97     hevc   1280x720  2025:11:17 04:52:06\n",
            "GX016579.MP4                               12.87 MB     00:32   29.97     hevc   1280x720  2025:11:17 04:53:04\n",
            "GX016580.MP4                                14.4 MB     00:36   29.97     hevc   1280x720  2025:11:17 04:54:16\n",
            "GX016581.MP4                               20.08 MB     00:51   29.97     hevc   1280x720  2025:11:17 04:55:46\n",
            "GX016582.MP4                               12.25 MB     00:31   29.97     hevc   1280x720  2025:11:17 04:56:39\n",
            "GX016583.MP4                                5.71 MB     00:13   29.97     hevc   1280x720  2025:11:17 04:04:43\n",
            "GX016584.MP4                                8.21 MB     00:19   29.97     hevc   1280x720  2025:11:17 03:53:56\n",
            "GX016585.MP4                               12.71 MB     00:31   29.97     hevc   1280x720  2025:11:17 03:55:25\n",
            "GX016586.MP4                               17.39 MB     00:43   29.97     hevc   1280x720  2025:11:17 03:56:19\n",
            "GX016587.MP4                                9.64 MB     00:23   29.97     hevc   1280x720  2025:11:17 03:57:08\n",
            "GX016588.MP4                                30.4 MB     01:17   29.97     hevc   1280x720  2025:11:17 03:59:54\n",
            "GX016589.MP4                               17.69 MB     00:44   29.97     hevc   1280x720  2025:11:17 04:01:03\n",
            "GX016590.MP4                               21.74 MB     00:55   29.97     hevc   1280x720  2025:11:17 04:02:29\n",
            "GX016591.MP4                               15.64 MB     00:38   29.97     hevc   1280x720  2025:11:17 04:03:07\n",
            "GX016592.MP4                                8.94 MB     00:21   29.97     hevc   1280x720  2025:11:17 04:03:23\n",
            "GX016593.MP4                                8.09 MB     00:26   29.97     h264    768x432  2025:11:17 04:04:18\n",
            "GX016594.MP4                               29.56 MB     01:15   29.97     hevc   1280x720  2025:11:17 03:53:48\n",
            "GX016595.MP4                               19.96 MB     00:50   29.97     hevc   1280x720  2025:11:17 04:06:20\n",
            "GX016596.MP4                               15.49 MB     00:39   29.97     hevc   1280x720  2025:11:17 04:07:17\n",
            "GX016597.MP4                               24.37 MB     01:03   29.97     hevc   1280x720  2025:11:17 04:09:07\n",
            "GX016598.MP4                               14.91 MB     00:38   29.97     hevc   1280x720  2025:11:17 04:10:09\n",
            "GX016599.MP4                               19.82 MB     00:50   29.97     hevc   1280x720  2025:11:17 04:11:40\n",
            "GX016600.MP4                               17.36 MB     00:43   29.97     hevc   1280x720  2025:11:17 04:12:43\n",
            "GX016601.MP4                               26.04 MB     01:06   29.97     hevc   1280x720  2025:11:17 04:14:38\n",
            "GX016602.MP4                               24.24 MB     01:01   29.97     hevc   1280x720  2025:11:17 04:17:11\n",
            "GX016603.MP4                               29.89 MB     01:16   29.97     hevc   1280x720  2025:11:17 04:18:15\n",
            "GX016604.MP4                               17.11 MB     00:42   29.97     hevc   1280x720  2025:11:17 04:47:45\n",
            "GX016605.MP4                               29.09 MB     01:14   29.97     hevc   1280x720  2025:11:17 02:15:26\n",
            "GX016606.MP4                               16.77 MB     00:41   29.97     hevc   1280x720  2025:11:17 05:21:17\n",
            "GX016607.MP4                               19.69 MB     00:49   29.97     hevc   1280x720  2025:11:17 05:22:26\n",
            "GX016608.MP4                               11.65 MB     00:28   29.97     hevc   1280x720  2025:11:17 05:23:18\n",
            "GX016609.MP4                               14.96 MB     00:37   29.97     hevc   1280x720  2025:11:17 05:24:24\n",
            "GX016610.MP4                               24.45 MB     01:02   29.97     hevc   1280x720  2025:11:17 05:26:15\n",
            "GX016611.MP4                               11.63 MB     00:28   29.97     hevc   1280x720  2025:11:17 05:27:01\n",
            "GX016612.MP4                               10.54 MB     00:25   29.97     hevc   1280x720  2025:11:17 05:27:55\n",
            "GX016613.MP4                               11.88 MB     00:29   29.97     hevc   1280x720  2025:11:17 05:28:48\n",
            "GX016614.MP4                               32.22 MB     01:22   29.97     hevc   1280x720  2025:11:17 05:31:09\n",
            "GX016615.MP4                               18.95 MB     00:47   29.97     hevc   1280x720  2025:11:17 05:19:57\n",
            "GX016616.MP4                                7.31 MB     00:17   29.97     hevc   1280x720  2025:11:17 05:32:57\n",
            "GX016617.MP4                               13.15 MB     00:32   29.97     hevc   1280x720  2025:11:17 05:34:03\n",
            "GX016618.MP4                                9.33 MB     00:22   29.97     hevc   1280x720  2025:11:17 05:34:46\n",
            "GX016619.MP4                               18.67 MB     00:46   29.97     hevc   1280x720  2025:11:17 05:36:10\n",
            "GX016620.MP4                                13.1 MB     00:32   29.97     hevc   1280x720  2025:11:17 05:37:15\n",
            "GX016621.MP4                               17.18 MB     00:42   29.97     hevc   1280x720  2025:11:17 05:38:32\n",
            "GX016622.MP4                                1.52 MB     00:02   29.97     hevc   1280x720  2025:11:17 05:38:30\n",
            "GX016623.MP4                                9.66 MB     00:23   29.97     hevc   1280x720  2025:11:17 05:39:32\n",
            "GX016624.MP4                                7.85 MB     00:18   29.97     hevc   1280x720  2025:11:17 05:40:13\n",
            "GX016625.MP4                               16.05 MB     00:41   29.97     hevc   1280x720  2025:11:17 05:11:58\n",
            "GX016626.MP4                               16.94 MB     00:43   29.97     hevc   1280x720  2025:11:17 04:57:59\n",
            "GX016627.MP4                                4.85 MB     00:10   29.97     hevc   1280x720  2025:11:16 12:18:26\n",
            "GX016628.MP4                               31.76 MB     01:21   29.97     hevc   1280x720  2025:11:17 05:00:26\n",
            "GX016629.MP4                               24.33 MB     01:02   29.97     hevc   1280x720  2025:11:17 05:01:56\n",
            "GX016630.MP4                               65.73 MB     02:50   29.97     hevc   1280x720  2025:11:17 05:06:20\n",
            "GX016631.MP4                               15.11 MB     00:38   29.97     hevc   1280x720  2025:11:17 05:07:04\n",
            "GX016632.MP4                               18.84 MB     00:47   29.97     hevc   1280x720  2025:11:17 05:08:22\n",
            "GX016633.MP4                               10.75 MB     00:26   29.97     hevc   1280x720  2025:11:16 12:09:24\n",
            "GX016634.MP4                                10.7 MB     00:26   29.97     hevc   1280x720  2025:11:16 12:10:58\n",
            "GX016635.MP4                               33.08 MB     01:25   29.97     hevc   1280x720  2025:11:17 05:10:59\n",
            "GX016636.MP4                                4.55 MB     00:09   29.97     hevc   1280x720  2025:11:16 12:11:46\n",
            "GX016637.MP4                                8.03 MB     00:19   29.97     hevc   1280x720  2025:11:16 12:06:17\n",
            "GX016638.MP4                               13.31 MB     00:33   29.97     hevc   1280x720  2025:11:17 05:12:31\n",
            "GX016639.MP4                               11.29 MB     00:28   29.97     hevc   1280x720  2025:11:16 12:21:30\n",
            "GX016640.MP4                               17.55 MB     00:45   29.97     hevc   1280x720  2025:11:17 05:13:52\n",
            "GX016641.MP4                                7.41 MB     00:18   29.97     hevc   1280x720  2025:11:16 12:19:55\n",
            "GX016642.MP4                               29.27 MB     01:14   29.97     hevc   1280x720  2025:11:17 05:16:03\n",
            "GX016643.MP4                               14.28 MB     00:36   29.97     hevc   1280x720  2025:11:17 05:16:54\n",
            "GX016644.MP4                               10.42 MB     00:25   29.97     hevc   1280x720  2025:11:16 12:07:45\n",
            "GX016645.MP4                               23.35 MB     01:04   29.97     hevc   1280x720  2025:11:17 05:18:58\n",
            "GX016646.MP4                                 6.3 MB     00:15   29.97     hevc   1280x720  2025:11:17 03:51:21\n",
            "GX016647.MP4                                5.44 MB     00:13   29.97     hevc   1280x720  2025:11:17 03:31:40\n",
            "GX016648.MP4                                6.37 MB     00:15   29.97     hevc   1280x720  2025:11:17 03:32:17\n",
            "GX016649.MP4                               19.06 MB     00:49   29.97     hevc   1280x720  2025:11:17 03:33:48\n",
            "GX016650.MP4                                3.87 MB     00:09   29.97     hevc   1280x720  2025:11:17 03:34:04\n",
            "GX016651.MP4                                9.14 MB     00:23   29.97     hevc   1280x720  2025:11:17 03:34:55\n",
            "GX016652.MP4                               10.35 MB     00:26   29.97     hevc   1280x720  2025:11:17 03:35:50\n",
            "GX016653.MP4                               10.34 MB     00:26   29.97     hevc   1280x720  2025:11:17 03:36:39\n",
            "GX016654.MP4                               24.69 MB     01:07   29.97     hevc   1280x720  2025:11:17 03:38:52\n",
            "GX016655.MP4                               22.47 MB     00:58   29.97     hevc   1280x720  2025:11:17 03:40:09\n",
            "GX016656.MP4                               73.57 MB     03:12   29.97     hevc   1280x720  2025:11:17 03:45:32\n",
            "GX016657.MP4                               95.17 MB     04:08   29.97     hevc   1280x720  2025:11:17 03:51:38\n"
          ]
        }
      ],
      "source": [
        "# === LISTAR (ordenar SEMPRE pelo NOME) =========================================\n",
        "# - Ordena estritamente por nome (case-insensitive).\n",
        "# - Mostra dura√ß√£o, FPS (r_frame_rate/avg_frame_rate), codec, resolu√ß√£o (ffprobe).\n",
        "# - \"M√≠dia criada\" √© informativo (n√£o afeta a ordem).\n",
        "# - Opcional: exporta CSV.\n",
        "# - Novidades: DIR padr√£o -> \"01 - Downloads\"; FILE_GLOBS configur√°vel; sanity de ffprobe; ignora size=0.\n",
        "\n",
        "from pathlib import Path\n",
        "import subprocess, json, shutil, os, csv\n",
        "\n",
        "# Pasta de entrada: usa a estrutura nova (01 - Downloads) ou o env da c√©lula 01\n",
        "DIR = os.environ.get(\"DIR_DOWNLOAD\", \"/content/01 - Downloads\")\n",
        "\n",
        "# Padr√µes de arquivo (configur√°veis via env: \"FILE_GLOBS=*.MP4,*.mp4,*.MOV,*.mov\")\n",
        "FILE_GLOBS = [g.strip() for g in os.environ.get(\"FILE_GLOBS\", \"*.MP4,*.mp4\").split(\",\") if g.strip()]\n",
        "EXPORT_CSV = os.environ.get(\"EXPORT_CSV\", \"\")  # ex.: \"/content/listagem.csv\" (vazio = n√£o exporta)\n",
        "\n",
        "def _have(cmd: str) -> bool:\n",
        "    return shutil.which(cmd) is not None\n",
        "\n",
        "def _fmt_duration_seconds(dur: str | None) -> str:\n",
        "    try:\n",
        "        total = float(dur)\n",
        "        h = int(total // 3600); m = int((total % 3600) // 60); s = int(total % 60)\n",
        "        return f\"{h:02d}:{m:02d}:{s:02d}\" if h else f\"{m:02d}:{s:02d}\"\n",
        "    except Exception:\n",
        "        return \"?\"\n",
        "\n",
        "def _rate_to_fps(rate: str) -> str:\n",
        "    \"\"\"Converte '30000/1001' -> '29.97'; se vier '30' retorna '30.00'.\"\"\"\n",
        "    if not rate:\n",
        "        return \"?\"\n",
        "    if \"/\" in rate:\n",
        "        n, d = rate.split(\"/\", 1)\n",
        "        try:\n",
        "            n = float(n); d = float(d)\n",
        "            return f\"{(n/d):.2f}\" if d else \"?\"\n",
        "        except Exception:\n",
        "            return \"?\"\n",
        "    try:\n",
        "        return f\"{float(rate):.2f}\"\n",
        "    except Exception:\n",
        "        return \"?\"\n",
        "\n",
        "def _ffprobe_info(path: Path):\n",
        "    \"\"\"Retorna (duration_str, fps_str, codec, res_wxH).\"\"\"\n",
        "    if not _have(\"ffprobe\"):\n",
        "        raise SystemExit(\"‚ùå ffprobe n√£o encontrado. Rode a c√©lula de configura√ß√£o (FFmpeg).\")\n",
        "    try:\n",
        "        p = subprocess.run(\n",
        "            [\"ffprobe\",\"-v\",\"error\",\"-show_streams\",\"-show_format\",\"-print_format\",\"json\", str(path)],\n",
        "            capture_output=True, text=True\n",
        "        )\n",
        "        j = json.loads(p.stdout) if p.stdout else {}\n",
        "        fmt = j.get(\"format\", {}) or {}\n",
        "        streams = j.get(\"streams\", []) or []\n",
        "        v = next((s for s in streams if s.get(\"codec_type\")==\"video\"), {})\n",
        "        dur_str = _fmt_duration_seconds(fmt.get(\"duration\"))\n",
        "        fps_str = _rate_to_fps(v.get(\"r_frame_rate\") or v.get(\"avg_frame_rate\") or \"\")\n",
        "        codec   = v.get(\"codec_name\") or \"?\"\n",
        "        res     = f\"{v.get('width','?')}x{v.get('height','?')}\"\n",
        "        return dur_str, fps_str, codec, res\n",
        "    except Exception:\n",
        "        return \"?\", \"?\", \"?\", \"?\"\n",
        "\n",
        "def _created_string(path: Path) -> str:\n",
        "    \"\"\"Obt√©m uma string de 'M√≠dia criada' (informativa).\"\"\"\n",
        "    # 1) EXIF/QuickTime\n",
        "    if _have(\"exiftool\"):\n",
        "        try:\n",
        "            p = subprocess.run(\n",
        "                [\"exiftool\",\"-s\",\"-s\",\"-s\",\n",
        "                 \"-QuickTime:CreateDate\",\"-MediaCreateDate\",\"-CreateDate\",\n",
        "                 \"-TrackCreateDate\",\"-DateTimeOriginal\",\n",
        "                 str(path)],\n",
        "                capture_output=True, text=True\n",
        "            )\n",
        "            for line in (p.stdout or \"\").splitlines():\n",
        "                s = line.strip()\n",
        "                if s:\n",
        "                    return s\n",
        "        except Exception:\n",
        "            pass\n",
        "    # 2) ffprobe tags\n",
        "    try:\n",
        "        p = subprocess.run(\n",
        "            [\"ffprobe\",\"-v\",\"error\",\"-show_format\",\"-print_format\",\"json\",str(path)],\n",
        "            capture_output=True, text=True\n",
        "        )\n",
        "        data = json.loads(p.stdout) if p.stdout else {}\n",
        "        tags = (data.get(\"format\") or {}).get(\"tags\") or {}\n",
        "        for k in (\"com.apple.quicktime.creationdate\",\"creation_time\",\"DATE\"):\n",
        "            if tags.get(k): return tags[k]\n",
        "    except Exception:\n",
        "        pass\n",
        "    return \"-\"  # n√£o encontrado\n",
        "\n",
        "# --- listar (ORDENA√á√ÉO = NOME) ------------------------------------------------\n",
        "p = Path(DIR)\n",
        "if not p.exists():\n",
        "    raise FileNotFoundError(f\"Pasta n√£o encontrada: {DIR}\")\n",
        "\n",
        "# coleta conforme FILE_GLOBS e ignora arquivos de tamanho zero\n",
        "files = []\n",
        "for pat in FILE_GLOBS:\n",
        "    files.extend(p.glob(pat))\n",
        "files = [f for f in files if f.is_file() and f.stat().st_size > 0]\n",
        "\n",
        "# ordem estrita por NOME (case-insensitive)\n",
        "files = sorted(files, key=lambda x: x.name.lower())\n",
        "\n",
        "if not files:\n",
        "    raise SystemExit(f\"Nenhum arquivo compat√≠vel encontrado em {DIR} (padr√µes: {', '.join(FILE_GLOBS)})\")\n",
        "\n",
        "rows = []\n",
        "for f in files:\n",
        "    dur, fps, codec, res = _ffprobe_info(f)\n",
        "    created = _created_string(f)  # informativo\n",
        "    rows.append({\n",
        "        \"arquivo\": f.name,\n",
        "        \"tamanho_MB\": round(f.stat().st_size / (1024*1024), 2),\n",
        "        \"duracao\": dur,\n",
        "        \"fps\": fps,              # FPS nominal\n",
        "        \"codec\": codec,\n",
        "        \"resolucao\": res,\n",
        "        \"midia_criada\": created  # s√≥ informativo\n",
        "    })\n",
        "\n",
        "# --- sa√≠da --------------------------------------------------------------------\n",
        "print(f\"üìÇ Listando v√≠deos (ordem: NOME) ‚Äî pasta: {DIR}\")\n",
        "print(f\"{'Arquivo':<40} {'Tamanho':>9} {'Dura√ß√£o':>9} {'FPS':>7} {'Codec':>8} {'Resolu√ß√£o':>10}  {'M√≠dia Criada (info)'}\")\n",
        "print(\"-\"*160)\n",
        "for r in rows:\n",
        "    print(f\"{r['arquivo']:<40} {r['tamanho_MB']:>7} MB {r['duracao']:>9} {r['fps']:>7} {r['codec']:>8} {r['resolucao']:>10}  {r['midia_criada']}\")\n",
        "\n",
        "# CSV (opcional)\n",
        "if EXPORT_CSV:\n",
        "    with open(EXPORT_CSV, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
        "        w = csv.DictWriter(f, fieldnames=[\"arquivo\",\"tamanho_MB\",\"duracao\",\"fps\",\"codec\",\"resolucao\",\"midia_criada\"])\n",
        "        w.writeheader()\n",
        "        for r in rows:\n",
        "            w.writerow({k:r[k] for k in w.fieldnames})\n",
        "    print(\"üíæ CSV salvo em:\", EXPORT_CSV)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFN1kcpHKuKE"
      },
      "source": [
        "# Mesclar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQayGpcGKw3d",
        "outputId": "25348f99-50cd-4047-ef82-95b6a4a2b0a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üß≠ Ordem (por nome):\n",
            "  01 GX016562.MP4\n",
            "  02 GX016563.MP4\n",
            "  03 GX016564.MP4\n",
            "  04 GX016565.MP4\n",
            "  05 GX016566.MP4\n",
            "  06 GX016567.MP4\n",
            "  07 GX016568.MP4\n",
            "  08 GX016569.MP4\n",
            "  09 GX016570.MP4\n",
            "  10 GX016571.MP4\n",
            "  11 GX016574.MP4\n",
            "  12 GX016575.MP4\n",
            "  13 GX016576.MP4\n",
            "  14 GX016577.MP4\n",
            "  15 GX016578.MP4\n",
            "  16 GX016579.MP4\n",
            "  17 GX016580.MP4\n",
            "  18 GX016581.MP4\n",
            "  19 GX016582.MP4\n",
            "  20 GX016583.MP4\n",
            "  21 GX016584.MP4\n",
            "  22 GX016585.MP4\n",
            "  23 GX016586.MP4\n",
            "  24 GX016587.MP4\n",
            "  25 GX016588.MP4\n",
            "  26 GX016589.MP4\n",
            "  27 GX016590.MP4\n",
            "  28 GX016591.MP4\n",
            "  29 GX016592.MP4\n",
            "  30 GX016593.MP4\n",
            "  31 GX016594.MP4\n",
            "  32 GX016595.MP4\n",
            "  33 GX016596.MP4\n",
            "  34 GX016597.MP4\n",
            "  35 GX016598.MP4\n",
            "  36 GX016599.MP4\n",
            "  37 GX016600.MP4\n",
            "  38 GX016601.MP4\n",
            "  39 GX016602.MP4\n",
            "  40 GX016603.MP4\n",
            "  41 GX016604.MP4\n",
            "  42 GX016605.MP4\n",
            "  43 GX016606.MP4\n",
            "  44 GX016607.MP4\n",
            "  45 GX016608.MP4\n",
            "  46 GX016609.MP4\n",
            "  47 GX016610.MP4\n",
            "  48 GX016611.MP4\n",
            "  49 GX016612.MP4\n",
            "  50 GX016613.MP4\n",
            "  51 GX016614.MP4\n",
            "  52 GX016615.MP4\n",
            "  53 GX016616.MP4\n",
            "  54 GX016617.MP4\n",
            "  55 GX016618.MP4\n",
            "  56 GX016619.MP4\n",
            "  57 GX016620.MP4\n",
            "  58 GX016621.MP4\n",
            "  59 GX016622.MP4\n",
            "  60 GX016623.MP4\n",
            "  61 GX016624.MP4\n",
            "  62 GX016625.MP4\n",
            "  63 GX016626.MP4\n",
            "  64 GX016627.MP4\n",
            "  65 GX016628.MP4\n",
            "  66 GX016629.MP4\n",
            "  67 GX016630.MP4\n",
            "  68 GX016631.MP4\n",
            "  69 GX016632.MP4\n",
            "  70 GX016633.MP4\n",
            "  71 GX016634.MP4\n",
            "  72 GX016635.MP4\n",
            "  73 GX016636.MP4\n",
            "  74 GX016637.MP4\n",
            "  75 GX016638.MP4\n",
            "  76 GX016639.MP4\n",
            "  77 GX016640.MP4\n",
            "  78 GX016641.MP4\n",
            "  79 GX016642.MP4\n",
            "  80 GX016643.MP4\n",
            "  81 GX016644.MP4\n",
            "  82 GX016645.MP4\n",
            "  83 GX016646.MP4\n",
            "  84 GX016647.MP4\n",
            "  85 GX016648.MP4\n",
            "  86 GX016649.MP4\n",
            "  87 GX016650.MP4\n",
            "  88 GX016651.MP4\n",
            "  89 GX016652.MP4\n",
            "  90 GX016653.MP4\n",
            "  91 GX016654.MP4\n",
            "  92 GX016655.MP4\n",
            "  93 GX016656.MP4\n",
            "  94 GX016657.MP4\n",
            "   ‚Ä¢ GX016562.MP4: KFstart=2.002s  KFend=48.048s  Œî=46.046s  [A+V]\n",
            "   ‚Ä¢ GX016563.MP4: KFstart=2.002s  KFend=26.026s  Œî=24.024s  [A+V]\n",
            "   ‚Ä¢ GX016564.MP4: KFstart=2.002s  KFend=34.034s  Œî=32.032s  [A+V]\n",
            "   ‚Ä¢ GX016565.MP4: KFstart=2.002s  KFend=40.040s  Œî=38.038s  [A+V]\n",
            "   ‚Ä¢ GX016566.MP4: KFstart=2.002s  KFend=52.052s  Œî=50.050s  [A+V]\n",
            "   ‚Ä¢ GX016567.MP4: KFstart=2.002s  KFend=34.034s  Œî=32.032s  [A+V]\n",
            "   ‚Ä¢ GX016568.MP4: KFstart=2.002s  KFend=18.018s  Œî=16.016s  [A+V]\n",
            "   ‚Ä¢ GX016569.MP4: KFstart=2.002s  KFend=46.046s  Œî=44.044s  [A+V]\n",
            "   ‚Ä¢ GX016570.MP4: KFstart=2.002s  KFend=34.034s  Œî=32.032s  [A+V]\n",
            "   ‚Ä¢ GX016571.MP4: KFstart=2.002s  KFend=10.010s  Œî=8.008s  [A+V]\n",
            "   ‚Ä¢ GX016574.MP4: KFstart=2.002s  KFend=18.018s  Œî=16.016s  [A+V]\n",
            "   ‚Ä¢ GX016575.MP4: KFstart=2.002s  KFend=26.026s  Œî=24.024s  [A+V]\n",
            "   ‚Ä¢ GX016576.MP4: KFstart=2.002s  KFend=78.078s  Œî=76.076s  [A+V]\n",
            "   ‚Ä¢ GX016577.MP4: KFstart=2.002s  KFend=54.054s  Œî=52.052s  [A+V]\n",
            "   ‚Ä¢ GX016578.MP4: KFstart=2.002s  KFend=32.032s  Œî=30.030s  [A+V]\n",
            "   ‚Ä¢ GX016579.MP4: KFstart=2.002s  KFend=30.030s  Œî=28.028s  [A+V]\n",
            "   ‚Ä¢ GX016580.MP4: KFstart=2.002s  KFend=34.034s  Œî=32.032s  [A+V]\n",
            "   ‚Ä¢ GX016581.MP4: KFstart=2.002s  KFend=50.050s  Œî=48.048s  [A+V]\n",
            "   ‚Ä¢ GX016582.MP4: KFstart=2.002s  KFend=30.030s  Œî=28.028s  [A+V]\n",
            "   ‚Ä¢ GX016583.MP4: KFstart=2.002s  KFend=12.012s  Œî=10.010s  [A+V]\n",
            "   ‚Ä¢ GX016584.MP4: KFstart=2.002s  KFend=18.018s  Œî=16.016s  [A+V]\n",
            "   ‚Ä¢ GX016585.MP4: KFstart=2.002s  KFend=30.030s  Œî=28.028s  [A+V]\n",
            "   ‚Ä¢ GX016586.MP4: KFstart=2.002s  KFend=42.042s  Œî=40.040s  [A+V]\n",
            "   ‚Ä¢ GX016587.MP4: KFstart=2.002s  KFend=22.022s  Œî=20.020s  [A+V]\n",
            "   ‚Ä¢ GX016588.MP4: KFstart=2.002s  KFend=76.076s  Œî=74.074s  [A+V]\n",
            "   ‚Ä¢ GX016589.MP4: KFstart=2.002s  KFend=42.042s  Œî=40.040s  [A+V]\n",
            "   ‚Ä¢ GX016590.MP4: KFstart=2.002s  KFend=52.052s  Œî=50.050s  [A+V]\n",
            "   ‚Ä¢ GX016591.MP4: KFstart=2.002s  KFend=36.036s  Œî=34.034s  [A+V]\n",
            "   ‚Ä¢ GX016592.MP4: KFstart=2.002s  KFend=20.020s  Œî=18.018s  [A+V]\n",
            "   ‚Ä¢ GX016593.MP4: KFstart=2.002s  KFend=24.024s  Œî=22.022s  [A+V]\n",
            "   ‚Ä¢ GX016594.MP4: KFstart=2.002s  KFend=74.074s  Œî=72.072s  [A+V]\n",
            "   ‚Ä¢ GX016595.MP4: KFstart=2.002s  KFend=48.048s  Œî=46.046s  [A+V]\n",
            "   ‚Ä¢ GX016596.MP4: KFstart=2.002s  KFend=38.038s  Œî=36.036s  [A+V]\n",
            "   ‚Ä¢ GX016597.MP4: KFstart=2.002s  KFend=62.062s  Œî=60.060s  [A+V]\n",
            "   ‚Ä¢ GX016598.MP4: KFstart=2.002s  KFend=36.036s  Œî=34.034s  [A+V]\n",
            "   ‚Ä¢ GX016599.MP4: KFstart=2.002s  KFend=48.048s  Œî=46.046s  [A+V]\n",
            "   ‚Ä¢ GX016600.MP4: KFstart=2.002s  KFend=42.042s  Œî=40.040s  [A+V]\n",
            "   ‚Ä¢ GX016601.MP4: KFstart=2.002s  KFend=64.064s  Œî=62.062s  [A+V]\n",
            "   ‚Ä¢ GX016602.MP4: KFstart=2.002s  KFend=60.060s  Œî=58.058s  [A+V]\n",
            "   ‚Ä¢ GX016603.MP4: KFstart=2.002s  KFend=74.074s  Œî=72.072s  [A+V]\n",
            "   ‚Ä¢ GX016604.MP4: KFstart=2.002s  KFend=40.040s  Œî=38.038s  [A+V]\n",
            "   ‚Ä¢ GX016605.MP4: KFstart=2.002s  KFend=72.072s  Œî=70.070s  [A+V]\n",
            "   ‚Ä¢ GX016606.MP4: KFstart=2.002s  KFend=40.040s  Œî=38.038s  [A+V]\n",
            "   ‚Ä¢ GX016607.MP4: KFstart=2.002s  KFend=48.048s  Œî=46.046s  [A+V]\n",
            "   ‚Ä¢ GX016608.MP4: KFstart=2.002s  KFend=26.026s  Œî=24.024s  [A+V]\n",
            "   ‚Ä¢ GX016609.MP4: KFstart=2.002s  KFend=36.036s  Œî=34.034s  [A+V]\n",
            "   ‚Ä¢ GX016610.MP4: KFstart=2.002s  KFend=60.060s  Œî=58.058s  [A+V]\n",
            "   ‚Ä¢ GX016611.MP4: KFstart=2.002s  KFend=26.026s  Œî=24.024s  [A+V]\n",
            "   ‚Ä¢ GX016612.MP4: KFstart=2.002s  KFend=24.024s  Œî=22.022s  [A+V]\n",
            "   ‚Ä¢ GX016613.MP4: KFstart=2.002s  KFend=28.028s  Œî=26.026s  [A+V]\n",
            "   ‚Ä¢ GX016614.MP4: KFstart=2.002s  KFend=80.080s  Œî=78.078s  [A+V]\n",
            "   ‚Ä¢ GX016615.MP4: KFstart=2.002s  KFend=46.046s  Œî=44.044s  [A+V]\n",
            "   ‚Ä¢ GX016616.MP4: KFstart=2.002s  KFend=16.016s  Œî=14.014s  [A+V]\n",
            "   ‚Ä¢ GX016617.MP4: KFstart=2.002s  KFend=30.030s  Œî=28.028s  [A+V]\n",
            "   ‚Ä¢ GX016618.MP4: KFstart=2.002s  KFend=20.020s  Œî=18.018s  [A+V]\n",
            "   ‚Ä¢ GX016619.MP4: KFstart=2.002s  KFend=44.044s  Œî=42.042s  [A+V]\n",
            "   ‚Ä¢ GX016620.MP4: KFstart=2.002s  KFend=30.030s  Œî=28.028s  [A+V]\n",
            "   ‚Ä¢ GX016621.MP4: KFstart=2.002s  KFend=40.040s  Œî=38.038s  [A+V]\n",
            "   ‚Ä¢ GX016622.MP4: KFstart=0.000s  KFend=0.100s  Œî=0.100s  [A+V]\n",
            "   ‚Ä¢ GX016623.MP4: KFstart=2.002s  KFend=22.022s  Œî=20.020s  [A+V]\n",
            "   ‚Ä¢ GX016624.MP4: KFstart=2.002s  KFend=16.016s  Œî=14.014s  [A+V]\n",
            "   ‚Ä¢ GX016625.MP4: KFstart=2.002s  KFend=40.040s  Œî=38.038s  [A+V]\n",
            "   ‚Ä¢ GX016626.MP4: KFstart=2.002s  KFend=42.042s  Œî=40.040s  [A+V]\n",
            "   ‚Ä¢ GX016627.MP4: KFstart=2.002s  KFend=8.008s  Œî=6.006s  [A+V]\n",
            "   ‚Ä¢ GX016628.MP4: KFstart=2.002s  KFend=80.080s  Œî=78.078s  [A+V]\n",
            "   ‚Ä¢ GX016629.MP4: KFstart=2.002s  KFend=60.060s  Œî=58.058s  [A+V]\n",
            "   ‚Ä¢ GX016630.MP4: KFstart=2.002s  KFend=168.168s  Œî=166.166s  [A+V]\n",
            "   ‚Ä¢ GX016631.MP4: KFstart=2.002s  KFend=36.036s  Œî=34.034s  [A+V]\n",
            "   ‚Ä¢ GX016632.MP4: KFstart=2.002s  KFend=46.046s  Œî=44.044s  [A+V]\n",
            "   ‚Ä¢ GX016633.MP4: KFstart=2.002s  KFend=24.024s  Œî=22.022s  [A+V]\n",
            "   ‚Ä¢ GX016634.MP4: KFstart=2.002s  KFend=24.024s  Œî=22.022s  [A+V]\n",
            "   ‚Ä¢ GX016635.MP4: KFstart=2.002s  KFend=84.084s  Œî=82.082s  [A+V]\n",
            "   ‚Ä¢ GX016636.MP4: KFstart=2.002s  KFend=8.008s  Œî=6.006s  [A+V]\n",
            "   ‚Ä¢ GX016637.MP4: KFstart=2.002s  KFend=18.018s  Œî=16.016s  [A+V]\n",
            "   ‚Ä¢ GX016638.MP4: KFstart=2.002s  KFend=32.032s  Œî=30.030s  [A+V]\n",
            "   ‚Ä¢ GX016639.MP4: KFstart=2.002s  KFend=26.026s  Œî=24.024s  [A+V]\n",
            "   ‚Ä¢ GX016640.MP4: KFstart=2.002s  KFend=44.044s  Œî=42.042s  [A+V]\n",
            "   ‚Ä¢ GX016641.MP4: KFstart=2.002s  KFend=16.016s  Œî=14.014s  [A+V]\n",
            "   ‚Ä¢ GX016642.MP4: KFstart=2.002s  KFend=72.072s  Œî=70.070s  [A+V]\n",
            "   ‚Ä¢ GX016643.MP4: KFstart=2.002s  KFend=34.034s  Œî=32.032s  [A+V]\n",
            "   ‚Ä¢ GX016644.MP4: KFstart=2.002s  KFend=24.024s  Œî=22.022s  [A+V]\n",
            "   ‚Ä¢ GX016645.MP4: KFstart=2.002s  KFend=62.062s  Œî=60.060s  [A+V]\n",
            "   ‚Ä¢ GX016646.MP4: KFstart=2.002s  KFend=14.014s  Œî=12.012s  [A+V]\n",
            "   ‚Ä¢ GX016647.MP4: KFstart=2.002s  KFend=12.012s  Œî=10.010s  [A+V]\n",
            "   ‚Ä¢ GX016648.MP4: KFstart=2.002s  KFend=14.014s  Œî=12.012s  [A+V]\n",
            "   ‚Ä¢ GX016649.MP4: KFstart=2.002s  KFend=48.048s  Œî=46.046s  [A+V]\n",
            "   ‚Ä¢ GX016650.MP4: KFstart=2.002s  KFend=8.008s  Œî=6.006s  [A+V]\n",
            "   ‚Ä¢ GX016651.MP4: KFstart=2.002s  KFend=22.022s  Œî=20.020s  [A+V]\n",
            "   ‚Ä¢ GX016652.MP4: KFstart=2.002s  KFend=24.024s  Œî=22.022s  [A+V]\n",
            "   ‚Ä¢ GX016653.MP4: KFstart=2.002s  KFend=24.024s  Œî=22.022s  [A+V]\n",
            "   ‚Ä¢ GX016654.MP4: KFstart=2.002s  KFend=66.066s  Œî=64.064s  [A+V]\n",
            "   ‚Ä¢ GX016655.MP4: KFstart=2.002s  KFend=56.056s  Œî=54.054s  [A+V]\n",
            "   ‚Ä¢ GX016656.MP4: KFstart=2.002s  KFend=190.190s  Œî=188.188s  [A+V]\n",
            "   ‚Ä¢ GX016657.MP4: KFstart=2.002s  KFend=246.246s  Œî=244.244s  [A+V]\n",
            "\n",
            "‚úÖ Mesclagem conclu√≠da: /content/02 - Mesclado/20251117_133921_mesclado.mp4\n",
            "   FPS 1¬∫ input: 29.97  |  FPS sa√≠da: 29.97\n",
            "   (Tempor√°rios limpos.)\n"
          ]
        }
      ],
      "source": [
        "# === MESCLAR (copy puro; 1¬∫ KF >= 1s e √∫ltimo KF <= d-1s; sem freeze) =========\n",
        "# Usa as pastas da c√©lula 01:\n",
        "#   IN_DIR  = os.environ[\"DIR_DOWNLOAD\"]  (ex.: /content/01 - Downloads)\n",
        "#   OUT_DIR = os.environ[\"DIR_MESCLADO\"]  (ex.: /content/02 - Mesclado)\n",
        "\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "import subprocess, json, shutil, tempfile, re, os\n",
        "\n",
        "# --------- CONFIG ---------\n",
        "IN_DIR   = os.environ.get(\"DIR_DOWNLOAD\", \"/content/01 - Downloads\")\n",
        "OUT_DIR  = os.environ.get(\"DIR_MESCLADO\", \"/content/02 - Mesclado\")\n",
        "HEAD_SEC = float(os.environ.get(\"HEAD_SEC\", \"1.0\"))  # in√≠cio: 1¬∫ KF >= HEAD_SEC\n",
        "TAIL_SEC = float(os.environ.get(\"TAIL_SEC\", \"1.0\"))  # fim:    √∫ltimo KF <= dur - TAIL_SEC\n",
        "LIMIT    = int(os.environ.get(\"LIMIT\", \"0\"))         # 0 = todos; >0 usa s√≥ N primeiros (ordenados por nome)\n",
        "\n",
        "MIN_WIN  = 0.10  # janela m√≠nima por seguran√ßa\n",
        "KF_EPS   = 1e-6\n",
        "\n",
        "def _have(cmd: str) -> bool:\n",
        "    return shutil.which(cmd) is not None\n",
        "\n",
        "def run(cmd):\n",
        "    return subprocess.run(cmd, capture_output=True, text=True)\n",
        "\n",
        "def duration(p: Path) -> float:\n",
        "    r = run([\"ffprobe\",\"-v\",\"error\",\"-show_entries\",\"format=duration\",\n",
        "             \"-of\",\"default=nw=1:nk=1\", str(p)])\n",
        "    try: return float((r.stdout or \"0\").strip())\n",
        "    except: return 0.0\n",
        "\n",
        "def has_audio(p: Path) -> bool:\n",
        "    r = run([\"ffprobe\",\"-v\",\"error\",\"-select_streams\",\"a:0\",\n",
        "             \"-show_entries\",\"stream=index\",\"-of\",\"csv=p=0\", str(p)])\n",
        "    return bool((r.stdout or \"\").strip())\n",
        "\n",
        "def keyframes(p: Path):\n",
        "    \"\"\"Retorna tempos (s) de keyframes; usa pkt_pts_time (melhor p/ HEVC).\"\"\"\n",
        "    r = run([\n",
        "        \"ffprobe\",\"-v\",\"error\",\"-select_streams\",\"v:0\",\n",
        "        \"-skip_frame\",\"nokey\",\n",
        "        \"-show_frames\",\"-show_entries\",\"frame=pkt_pts_time\",\n",
        "        \"-of\",\"csv=p=0\", str(p)\n",
        "    ])\n",
        "    out = []\n",
        "    for line in (r.stdout or \"\").splitlines():\n",
        "        s = line.strip()\n",
        "        if not s: continue\n",
        "        try: out.append(float(s))\n",
        "        except: pass\n",
        "    # saneamento b√°sico\n",
        "    out = sorted(set([t for t in out if t >= 0.0]))\n",
        "    return out\n",
        "\n",
        "def fps_of(p: Path) -> str:\n",
        "    # tenta r_frame_rate, cai pra avg_frame_rate\n",
        "    r = run([\"ffprobe\",\"-v\",\"error\",\"-select_streams\",\"v:0\",\n",
        "             \"-show_entries\",\"stream=r_frame_rate,avg_frame_rate\",\n",
        "             \"-of\",\"json\", str(p)])\n",
        "    try:\n",
        "        j = json.loads(r.stdout) if r.stdout else {}\n",
        "        v = (j.get(\"streams\") or [{}])[0]\n",
        "        rate = v.get(\"r_frame_rate\") or v.get(\"avg_frame_rate\") or \"\"\n",
        "        if \"/\" in rate:\n",
        "            n,d = rate.split(\"/\",1)\n",
        "            n = float(n); d = float(d) if float(d) != 0 else 1.0\n",
        "            return f\"{n/d:.2f}\"\n",
        "        return f\"{float(rate):.2f}\" if rate else \"?\"\n",
        "    except:\n",
        "        return \"?\"\n",
        "\n",
        "# ---------- checks ----------\n",
        "if not _have(\"ffmpeg\") or not _have(\"ffprobe\"):\n",
        "    raise SystemExit(\"‚ùå FFmpeg/ffprobe n√£o encontrados. Rode a c√©lula de configura√ß√£o primeiro.\")\n",
        "\n",
        "in_dir  = Path(IN_DIR)\n",
        "out_dir = Path(OUT_DIR); out_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# aceita .MP4 e .mp4; ignora size=0\n",
        "files = [*in_dir.glob(\"*.MP4\"), *in_dir.glob(\"*.mp4\")]\n",
        "files = [f for f in files if f.is_file() and f.stat().st_size > 0]\n",
        "files = sorted(files, key=lambda x: x.name.lower())\n",
        "if LIMIT and LIMIT > 0:\n",
        "    files = files[:LIMIT]\n",
        "assert files, f\"Nenhum MP4 v√°lido em {IN_DIR}\"\n",
        "\n",
        "# consist√™ncia de √°udio (concat copy exige mesmo layout em todos os segmentos)\n",
        "audio_flags = [has_audio(f) for f in files]\n",
        "all_audio   = all(audio_flags)\n",
        "none_audio  = not any(audio_flags)\n",
        "include_audio = all_audio  # se misturado, desliga √°udio para todos\n",
        "if not (all_audio or none_audio):\n",
        "    print(\"‚ö†Ô∏è Mix de arquivos com/sem √°udio detectado ‚Äî removendo √°udio no mesclado (copy puro compat√≠vel).\")\n",
        "    include_audio = False\n",
        "\n",
        "print(\"üß≠ Ordem (por nome):\")\n",
        "for i,f in enumerate(files,1):\n",
        "    print(f\"  {i:02d} {f.name}\")\n",
        "\n",
        "with tempfile.TemporaryDirectory(prefix=\"mesclar_kf_\") as workdir:\n",
        "    work = Path(workdir)\n",
        "    segs = []\n",
        "\n",
        "    for idx, f in enumerate(files, 1):\n",
        "        d   = duration(f)\n",
        "        if d <= (HEAD_SEC + TAIL_SEC + MIN_WIN):\n",
        "            print(f\"‚ö†Ô∏è {f.name}: dura√ß√£o muito curta ({d:.2f}s). Ajustando janelas...\")\n",
        "        kfs = keyframes(f)\n",
        "\n",
        "        # garante presen√ßa de 0.0 e d como guard rails (mesmo que n√£o sejam KFs reais)\n",
        "        if not kfs or kfs[0] > 0.0 + KF_EPS:\n",
        "            kfs = [0.0] + (kfs or [])\n",
        "        if not kfs or kfs[-1] < d - KF_EPS:\n",
        "            kfs = kfs + [d]\n",
        "\n",
        "        start_target = max(0.0, HEAD_SEC)\n",
        "        end_target   = max(MIN_WIN, d - TAIL_SEC)\n",
        "\n",
        "        # IN√çCIO: 1¬∫ KF >= HEAD_SEC\n",
        "        kf_start = next((t for t in kfs if t + KF_EPS >= start_target), kfs[-1])\n",
        "        # FIM: √∫ltimo KF <= (d - TAIL_SEC)\n",
        "        kf_end   = next((t for t in reversed(kfs) if t <= end_target + KF_EPS), kfs[0])\n",
        "\n",
        "        # janela v√°lida m√≠nima\n",
        "        if (kf_end - kf_start) < MIN_WIN:\n",
        "            # tenta recuar in√≠cio para KF anterior ao fim\n",
        "            prev_start = next((t for t in reversed(kfs) if t + KF_EPS < kf_end), kfs[0])\n",
        "            kf_start = min(prev_start, kf_start)\n",
        "            if (kf_end - kf_start) < MIN_WIN:\n",
        "                kf_end = min(d, kf_start + MIN_WIN)\n",
        "\n",
        "        T = max(MIN_WIN, kf_end - kf_start)\n",
        "\n",
        "        dst  = work / f\"seg_{idx:03d}.mp4\"\n",
        "        maps = [\"-map\",\"0:v:0\"]\n",
        "        if include_audio:\n",
        "            maps += [\"-map\",\"0:a:0\"]\n",
        "\n",
        "        # Corte alinhado em keyframes: -ss ANTES do -i e -t como dura√ß√£o ‚Üí copy puro, sem freeze\n",
        "        cmd = [\"ffmpeg\",\"-y\",\"-hide_banner\",\"-loglevel\",\"error\",\n",
        "               \"-ss\", f\"{kf_start:.6f}\", \"-t\", f\"{T:.6f}\", \"-i\", str(f),\n",
        "               *maps, \"-c\",\"copy\", \"-movflags\",\"+faststart\", str(dst)]\n",
        "        p = run(cmd)\n",
        "        if p.returncode != 0 or not dst.exists() or dst.stat().st_size == 0:\n",
        "            raise RuntimeError(f\"Corte falhou em {f.name}:\\n{p.stderr}\")\n",
        "\n",
        "        segs.append(dst)\n",
        "        print(f\"   ‚Ä¢ {f.name}: KFstart={kf_start:.3f}s  KFend={kf_end:.3f}s  Œî={T:.3f}s  {'[A+V]' if include_audio else '[V]'}\")\n",
        "\n",
        "    # concat (copy puro)\n",
        "    lst = work / \"list.txt\"\n",
        "    with open(lst, \"w\", encoding=\"utf-8\") as fp:\n",
        "        for s in segs:\n",
        "            fp.write(f\"file '{s.as_posix()}'\\n\")\n",
        "\n",
        "    inter = work / \"concat.mp4\"\n",
        "    p = run([\"ffmpeg\",\"-y\",\"-hide_banner\",\"-loglevel\",\"error\",\n",
        "             \"-f\",\"concat\",\"-safe\",\"0\",\"-i\",str(lst),\n",
        "             \"-c\",\"copy\",\"-movflags\",\"+faststart\", str(inter)])\n",
        "    if p.returncode != 0 or not inter.exists() or inter.stat().st_size == 0:\n",
        "        raise RuntimeError(f\"Concat falhou:\\n{p.stderr}\")\n",
        "\n",
        "    # nome final: timestamp atual (YYYYMMDD_HHMMSS_mesclado.mp4)\n",
        "    stamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    out_path = out_dir / f\"{stamp}_mesclado.mp4\"\n",
        "    if out_path.exists():\n",
        "        out_path.unlink()\n",
        "\n",
        "    # remux final (copy) e move\n",
        "    tmp = work / \"final.mp4\"\n",
        "    p = run([\"ffmpeg\",\"-y\",\"-hide_banner\",\"-loglevel\",\"error\",\n",
        "             \"-i\",str(inter),\"-c\",\"copy\",\"-movflags\",\"+faststart\", str(tmp)])\n",
        "    shutil.move(str((tmp if p.returncode==0 and tmp.exists() else inter)), str(out_path))\n",
        "\n",
        "print(f\"\\n‚úÖ Mesclagem conclu√≠da: {out_path}\")\n",
        "print(f\"   FPS 1¬∫ input: {fps_of(files[0])}  |  FPS sa√≠da: {fps_of(out_path)}\")\n",
        "print(\"   (Tempor√°rios limpos.)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hpwaBZTrz91"
      },
      "source": [
        "# Teaser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1mK-84_tr2Ma",
        "outputId": "66ef846e-5fcd-4931-a8b7-c59315bd02c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìπ V√≠deo base: 20251117_133921_mesclado.mp4\n",
            "üé§ Transcrevendo (dur: 3863s) ‚Ä¶\n",
            "   üîÑ Modo chunks: 10 min\n",
            "   ‚úÖ Chunk 1: 0s‚Äì600s\n",
            "   ‚úÖ Chunk 2: 600s‚Äì1200s\n",
            "   ‚úÖ Chunk 3: 1200s‚Äì1800s\n",
            "   ‚úÖ Chunk 4: 1800s‚Äì2400s\n",
            "   ‚úÖ Chunk 5: 2400s‚Äì3000s\n",
            "   ‚úÖ Chunk 6: 3000s‚Äì3600s\n",
            "   ‚úÖ Chunk 7: 3600s‚Äì3863s\n",
            "üíæ Cache salvo: 20251117_133921_mesclado_transcript.json\n",
            "‚úÖ Transcri√ß√£o OK em 244 s ‚Äî segmentos: 1372\n",
            "üéØ Selecionados 12 segmentos (total ~63.0s)\n",
            "üíæ Sele√ß√£o GPT salva: 20251117_134418_teaser_openai.json\n",
            "\n",
            "üìã Segmentos escolhidos (antes do alinhamento):\n",
            "  01. 0.00s ‚Üí 8.00s  (8.00s)  | Fala galera, bom dia, aproximadamente 5 e meia da manh√£ e voltamos aos aeroporto‚Ä¶\n",
            "  02. 437.00s ‚Üí 442.00s  (5.00s)  | a sa√≠da‚Ä¶\n",
            "  03. 736.00s ‚Üí 741.00s  (5.00s)  | Vamos l√°.‚Ä¶\n",
            "  04. 952.00s ‚Üí 957.00s  (5.00s)  | Vamos dar uma corridinha.‚Ä¶\n",
            "  05. 1283.00s ‚Üí 1288.00s  (5.00s)  | N√£o compete com o caf√© nordestino, com o cuscuzinho.‚Ä¶\n",
            "  06. 1583.50s ‚Üí 1588.50s  (5.00s)  | Caramba, eu n√£o sabia do que eu ia fazer.‚Ä¶\n",
            "  07. 1910.00s ‚Üí 1915.00s  (5.00s)  | exato‚Ä¶\n",
            "  08. 2185.50s ‚Üí 2190.50s  (5.00s)  | no final de semana‚Ä¶\n",
            "  09. 2531.94s ‚Üí 2536.94s  (5.00s)  | S√≥ que da√≠ ela n√£o t√° aqui.‚Ä¶\n",
            "  10. 3054.50s ‚Üí 3059.50s  (5.00s)  | depois‚Ä¶\n",
            "  11. 3314.50s ‚Üí 3319.50s  (5.00s)  | do restaurante‚Ä¶\n",
            "  12. 3578.50s ‚Üí 3583.50s  (5.00s)  | que cheirinho‚Ä¶\n",
            "\n",
            "‚úÖ TEASER pronto: /content/03 - Teasers/20251117_134418_teaser.mp4\n"
          ]
        }
      ],
      "source": [
        "# ================= ETAPA 2 ‚Äî TEASER (copy + keyframes + ‚Äúrespiro‚Äù) =================\n",
        "# Usa as pastas definidas na C√©lula 01 (envs):\n",
        "#   IN_DIR  = os.environ[\"DIR_MESCLADO\"]   (ex.: /content/02 - Mesclado)\n",
        "#   OUT_DIR = os.environ[\"DIR_TEASERS\"]    (ex.: /content/03 - Teasers)\n",
        "#\n",
        "# Diferen√ßas-chave desta vers√£o:\n",
        "# - Alinha cortes a keyframes com ‚Äúrespiro‚Äù:\n",
        "#     start -> √∫ltimo KF <= (start - PRE_ROLL_S)\n",
        "#     end   -> 1¬∫ KF     >= (end   + POST_ROLL_S)\n",
        "# - Copy puro (-c copy) em todos os cortes/concat, sem reencode.\n",
        "\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "import subprocess, json, shutil, tempfile, re, os, time, requests\n",
        "\n",
        "# ---------- CONFIG ----------\n",
        "IN_DIR            = os.environ.get(\"DIR_MESCLADO\", \"/content/02 - Mesclado\")\n",
        "OUT_DIR           = os.environ.get(\"DIR_TEASERS\",   \"/content/03 - Teasers\")\n",
        "LANGUAGE          = \"pt\"\n",
        "USE_CHUNKS_MINS   = 10\n",
        "CACHE_TRANSCR     = True\n",
        "\n",
        "TARGET_TEASER_S   = 120.0\n",
        "MIN_CLIP_S        = 5.0\n",
        "MAX_CLIP_S        = 8.0\n",
        "MIN_GAP_S         = 5.0\n",
        "\n",
        "# ‚Äúrespiro‚Äù (ajuste fino nos cortes, sempre respeitando keyframes)\n",
        "PRE_ROLL_S        = 0.25   # come√ßa ~0.25s antes do in√≠cio pedido (se poss√≠vel)\n",
        "POST_ROLL_S       = 0.60   # termina ~0.60s depois do fim pedido (se poss√≠vel)\n",
        "MIN_SEG_S         = 0.10   # seguran√ßa: m√≠nimo de 100ms\n",
        "\n",
        "API_KEY = os.getenv(\"OPENAI_API_KEY\", \"\").strip()\n",
        "assert API_KEY, \"Defina OPENAI_API_KEY\"\n",
        "\n",
        "Path(OUT_DIR).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# ---------- helpers ----------\n",
        "def run(cmd):\n",
        "    return subprocess.run(cmd, capture_output=True, text=True)\n",
        "\n",
        "def duration_of(p: Path) -> float:\n",
        "    r = run([\"ffprobe\",\"-v\",\"error\",\"-show_entries\",\"format=duration\",\n",
        "             \"-of\",\"default=nw=1:nk=1\",str(p)])\n",
        "    try: return float((r.stdout or \"0\").strip())\n",
        "    except: return 0.0\n",
        "\n",
        "def has_audio(p: Path) -> bool:\n",
        "    r = run([\"ffprobe\",\"-v\",\"error\",\"-select_streams\",\"a:0\",\n",
        "             \"-show_entries\",\"stream=index\",\"-of\",\"csv=p=0\", str(p)])\n",
        "    return bool((r.stdout or \"\").strip())\n",
        "\n",
        "def latest_mesclado(in_dir: str) -> Path:\n",
        "    files = sorted(Path(in_dir).glob(\"*_mesclado.mp4\"), key=lambda x: x.stat().st_mtime, reverse=True)\n",
        "    if not files:\n",
        "        files = sorted(Path(in_dir).glob(\"*.mp4\"), key=lambda x: x.stat().st_mtime, reverse=True)\n",
        "    assert files, f\"Nenhum mp4 encontrado em {in_dir}\"\n",
        "    print(\"üìπ V√≠deo base:\", files[0].name)\n",
        "    return files[0]\n",
        "\n",
        "def cache_path_for(video: Path) -> Path:\n",
        "    return Path(OUT_DIR) / (video.stem + \"_transcript.json\")\n",
        "\n",
        "def extract_audio_16k_mono(src: Path) -> Path:\n",
        "    tmp = Path(tempfile.mkstemp(suffix=\".mp3\")[1])\n",
        "    cmd = [\"ffmpeg\",\"-y\",\"-i\",str(src),\"-vn\",\"-acodec\",\"mp3\",\"-ar\",\"16000\",\"-ac\",\"1\",\"-b:a\",\"64k\",str(tmp)]\n",
        "    if run(cmd).returncode != 0:\n",
        "        raise RuntimeError(\"Falha ao extrair √°udio\")\n",
        "    return tmp\n",
        "\n",
        "def whisper_api(audio_path: Path) -> dict:\n",
        "    url = \"https://api.openai.com/v1/audio/transcriptions\"\n",
        "    headers = {\"Authorization\": f\"Bearer {API_KEY}\"}\n",
        "    with open(audio_path, \"rb\") as f:\n",
        "        files = {\n",
        "            \"file\": (audio_path.name, f, \"audio/mpeg\"),\n",
        "            \"model\": (None, OPENAI_WHISPER),\n",
        "            \"language\": (None, LANGUAGE),\n",
        "            \"response_format\": (None, \"verbose_json\"),\n",
        "            \"timestamp_granularities\": (None, \"segment\"),\n",
        "        }\n",
        "        r = requests.post(url, headers=headers, files=files, timeout=300)\n",
        "        r.raise_for_status()\n",
        "        return r.json()\n",
        "\n",
        "def split_in_chunks(video: Path, minutes: int):\n",
        "    dur = duration_of(video)\n",
        "    chunk_s = minutes * 60\n",
        "    chunks, start, idx = [], 0.0, 1\n",
        "    while start < dur - 0.1:\n",
        "        end = min(dur, start + chunk_s)\n",
        "        out = Path(OUT_DIR) / f\"chunk_{idx:02d}_{int(start)}s-{int(end)}s.mp4\"\n",
        "        if run([\"ffmpeg\",\"-y\",\"-ss\",f\"{start}\",\"-i\",str(video),\"-t\",f\"{end-start}\",\"-c\",\"copy\",str(out)]).returncode == 0:\n",
        "            chunks.append(dict(path=out, start=start, end=end, idx=idx))\n",
        "            print(f\"   ‚úÖ Chunk {idx}: {int(start)}s‚Äì{int(end)}s\")\n",
        "        else:\n",
        "            print(f\"   ‚ùå Chunk {idx} falhou\")\n",
        "        idx += 1\n",
        "        start = end\n",
        "    return chunks\n",
        "\n",
        "def transcribe(video: Path) -> dict:\n",
        "    t0 = time.time()\n",
        "    cache = cache_path_for(video)\n",
        "    if CACHE_TRANSCR and cache.exists():\n",
        "        print(\"üíæ Usando transcri√ß√£o em cache:\", cache.name)\n",
        "        return json.loads(cache.read_text(encoding=\"utf-8\"))\n",
        "\n",
        "    dur = duration_of(video)\n",
        "    print(f\"üé§ Transcrevendo (dur: {int(dur)}s) ‚Ä¶\")\n",
        "    all_segments, full_text = [], \"\"\n",
        "\n",
        "    if dur > USE_CHUNKS_MINS * 60:\n",
        "        print(f\"   üîÑ Modo chunks: {USE_CHUNKS_MINS} min\")\n",
        "        chunks = split_in_chunks(video, USE_CHUNKS_MINS)\n",
        "        for ch in chunks:\n",
        "            au = extract_audio_16k_mono(Path(ch[\"path\"]))\n",
        "            try:\n",
        "                data = whisper_api(au)\n",
        "            finally:\n",
        "                try: os.remove(au)\n",
        "                except: pass\n",
        "            for s in data.get(\"segments\", []):\n",
        "                all_segments.append(dict(\n",
        "                    start=s[\"start\"] + ch[\"start\"],\n",
        "                    end=s[\"end\"] + ch[\"start\"],\n",
        "                    text=s.get(\"text\",\"\").strip()\n",
        "                ))\n",
        "            full_text += (data.get(\"text\",\"\") + \" \")\n",
        "            try: os.remove(ch[\"path\"])\n",
        "            except: pass\n",
        "    else:\n",
        "        au = extract_audio_16k_mono(video)\n",
        "        try:\n",
        "            data = whisper_api(au)\n",
        "        finally:\n",
        "            try: os.remove(au)\n",
        "            except: pass\n",
        "        for s in data.get(\"segments\", []):\n",
        "            all_segments.append(dict(start=s[\"start\"], end=s[\"end\"], text=s.get(\"text\",\"\").strip()))\n",
        "        full_text = data.get(\"text\",\"\")\n",
        "\n",
        "    result = {\"text\": full_text.strip(), \"segments\": all_segments, \"language\": LANGUAGE}\n",
        "    if CACHE_TRANSCR:\n",
        "        cache.write_text(json.dumps(result, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
        "        print(\"üíæ Cache salvo:\", cache.name)\n",
        "    print(\"‚úÖ Transcri√ß√£o OK em\", int(time.time()-t0), \"s ‚Äî segmentos:\", len(all_segments))\n",
        "    return result\n",
        "\n",
        "# NEW: fun√ß√£o utilit√°ria para salvar a sele√ß√£o feita pela OpenAI em JSON\n",
        "def save_openai_selection_json(out_dir: str, stamp: str, base_video: Path,\n",
        "                               model_name: str, raw_response_text: str,\n",
        "                               selected_ids: list, picked_segments: list, all_segments: list):\n",
        "    out_json = Path(out_dir) / f\"{stamp}_teaser_openai.json\"\n",
        "    payload = {\n",
        "        \"created_at\": stamp,\n",
        "        \"video_base\": base_video.name,\n",
        "        \"model\": model_name,\n",
        "        \"target_teaser_s\": TARGET_TEASER_S,\n",
        "        \"min_clip_s\": MIN_CLIP_S,\n",
        "        \"max_clip_s\": MAX_CLIP_S,\n",
        "        \"min_gap_s\": MIN_GAP_S,\n",
        "        \"response_text\": (raw_response_text or \"\").strip(),\n",
        "        \"selected_ids\": selected_ids,\n",
        "        # trechos ANTES do alinhamento em keyframe (o que a OpenAI escolheu de fato)\n",
        "        \"selected_segments\": [\n",
        "            {\n",
        "                \"id\": s.get(\"id\"),\n",
        "                \"start\": round(float(s[\"start\"]), 3),\n",
        "                \"end\": round(float(s[\"end\"]), 3),\n",
        "                \"duration\": round(float(s[\"end\"] - s[\"start\"]), 3),\n",
        "                \"text\": s.get(\"text\", \"\")\n",
        "            }\n",
        "            for s in picked_segments\n",
        "        ],\n",
        "        # opcional: refer√™ncia r√°pida da lista completa (√∫til para auditoria)\n",
        "        \"segments_count_full\": len(all_segments)\n",
        "    }\n",
        "    out_json.write_text(json.dumps(payload, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
        "    print(\"üíæ Sele√ß√£o GPT salva:\", out_json.name)\n",
        "    return out_json\n",
        "\n",
        "def choose_segments_with_gpt(segments: list):\n",
        "    \"\"\"\n",
        "    NEW: passa a retornar (picked, raw_response_text, parsed_ids)\n",
        "    - picked: lista de segmentos (antes do alinhamento), j√° normalizados para MIN/MAX_CLIP_S e com campo 'id'\n",
        "    - raw_response_text: conte√∫do textual retornado pela OpenAI (para auditoria)\n",
        "    - parsed_ids: IDs inteiros interpretados a partir da resposta\n",
        "    \"\"\"\n",
        "    url = \"https://api.openai.com/v1/chat/completions\"\n",
        "    headers = {\"Authorization\": f\"Bearer {API_KEY}\", \"Content-Type\": \"application/json\"}\n",
        "\n",
        "    lines = [f\"ID {i}: {s['start']:.1f}-{s['end']:.1f} {s['text'][:80]}‚Ä¶\" for i,s in enumerate(segments)]\n",
        "    prompt = f\"\"\"\n",
        "Analise os segmentos abaixo e selecione IDs que formem um teaser (~{int(TARGET_TEASER_S)}s).\n",
        "- Distribua do come√ßo ao fim do v√≠deo\n",
        "- Cada segmento entre {int(MIN_CLIP_S)} e {int(MAX_CLIP_S)} s\n",
        "- Responda APENAS com IDs separados por v√≠rgula em ordem.\n",
        "\n",
        "SEGMENTOS:\n",
        "{chr(10).join(lines)}\n",
        "\"\"\".strip()\n",
        "\n",
        "    data = {\"model\": OPENAI_GPT, \"messages\":[{\"role\":\"user\",\"content\":prompt}], \"temperature\":0.1, \"max_tokens\":200}\n",
        "    raw_text = \"\"\n",
        "    try:\n",
        "        r = requests.post(url, headers=headers, json=data, timeout=60)\n",
        "        r.raise_for_status()\n",
        "        raw_text = r.json()[\"choices\"][0][\"message\"][\"content\"]\n",
        "        ids = [int(x) for x in re.findall(r\"\\d+\", raw_text)]\n",
        "        ids = [i for i in ids if 0 <= i < len(segments)]\n",
        "        if not ids: raise ValueError(\"Sem IDs\")\n",
        "    except Exception:\n",
        "        # fallback heur√≠stico\n",
        "        step = max(1, len(segments)//12)\n",
        "        ids = list(range(0, len(segments), step))[:12]\n",
        "        if not raw_text:\n",
        "            raw_text = \"[fallback_heuristico] IDs gerados automaticamente.\"\n",
        "\n",
        "    picked = []\n",
        "    for i in ids:\n",
        "        s = dict(segments[i])\n",
        "        s[\"id\"] = i  # NEW: preservar ID original\n",
        "        dur = s[\"end\"] - s[\"start\"]\n",
        "        if dur < MIN_CLIP_S:\n",
        "            pad = (MIN_CLIP_S - dur)/2\n",
        "            s[\"start\"] = max(0.0, s[\"start\"] - pad); s[\"end\"] = s[\"start\"] + MIN_CLIP_S\n",
        "        elif dur > MAX_CLIP_S:\n",
        "            s[\"end\"] = s[\"start\"] + MAX_CLIP_S\n",
        "        ok = True\n",
        "        for t in picked:\n",
        "            overlap = (s[\"start\"] < t[\"end\"] and s[\"end\"] > t[\"start\"])\n",
        "            near    = min(abs(s[\"start\"]-t[\"end\"]), abs(t[\"start\"]-s[\"end\"])) < MIN_GAP_S\n",
        "            if overlap or near: ok=False; break\n",
        "        if ok: picked.append(s)\n",
        "        if sum(x[\"end\"]-x[\"start\"] for x in picked) >= TARGET_TEASER_S*0.9: break\n",
        "\n",
        "    picked.sort(key=lambda x: x[\"start\"])\n",
        "    print(f\"üéØ Selecionados {len(picked)} segmentos (total ~{sum(x['end']-x['start'] for x in picked):.1f}s)\")\n",
        "    return picked, raw_text, ids  # NEW\n",
        "\n",
        "# ---------- keyframes + alinhamento com ‚Äúrespiro‚Äù ----------\n",
        "def list_keyframes(src: Path):\n",
        "    r = run([\"ffprobe\",\"-v\",\"error\",\"-select_streams\",\"v:0\",\n",
        "             \"-skip_frame\",\"nokey\",\"-show_frames\",\n",
        "             \"-show_entries\",\"frame=best_effort_timestamp_time\",\n",
        "             \"-of\",\"csv=p=0\", str(src)])\n",
        "    kfs = []\n",
        "    for line in (r.stdout or \"\").splitlines():\n",
        "        try: kfs.append(float(line.strip()))\n",
        "        except: pass\n",
        "    return kfs\n",
        "\n",
        "def align_to_kf_with_breath(kfs, start, end, dur):\n",
        "    want_start = max(0.0, start - PRE_ROLL_S)\n",
        "    want_end   = min(dur, end + POST_ROLL_S)\n",
        "\n",
        "    kf_start = max([t for t in kfs if t <= want_start] or [0.0])\n",
        "    kf_end   = next((t for t in kfs if t >= want_end), dur)\n",
        "\n",
        "    if kf_end - kf_start < MIN_SEG_S:\n",
        "        nxt = next((t for t in kfs if t > kf_start), kf_start + MIN_SEG_S)\n",
        "        kf_end = max(kf_end, min(dur, nxt))\n",
        "    return kf_start, kf_end\n",
        "\n",
        "def cut_copy_keyaligned(src: Path, dst: Path, start: float, end: float, kfs, dur: float) -> bool:\n",
        "    kf_start, kf_end = align_to_kf_with_breath(kfs, start, end, dur)\n",
        "    T = max(MIN_SEG_S, kf_end - kf_start)\n",
        "    maps = [\"-map\",\"0:v:0\"]\n",
        "    if has_audio(src): maps += [\"-map\",\"0:a:0\"]\n",
        "    cmd = [\"ffmpeg\",\"-y\",\n",
        "           \"-ss\", f\"{kf_start:.6f}\", \"-t\", f\"{T:.6f}\", \"-i\", str(src),\n",
        "           *maps, \"-c\",\"copy\",\"-movflags\",\"+faststart\", str(dst)]\n",
        "    return run(cmd).returncode == 0\n",
        "\n",
        "def concat_copy(list_file: Path, dst: Path) -> bool:\n",
        "    return run([\"ffmpeg\",\"-y\",\"-f\",\"concat\",\"-safe\",\"0\",\"-i\",str(list_file),\n",
        "                \"-c\",\"copy\",\"-movflags\",\"+faststart\", str(dst)]).returncode == 0\n",
        "\n",
        "# --------------------------------- PIPELINE -----------------------------------\n",
        "base   = latest_mesclado(IN_DIR)\n",
        "trans  = transcribe(base)\n",
        "\n",
        "# NEW: gerar o stamp ANTES, para reutilizar no JSON e no MP4\n",
        "stamp  = datetime.now().strftime(\"%Y%m%d_%H%M%S\")  # NEW\n",
        "\n",
        "# NEW: capturar tamb√©m o texto bruto da OpenAI e os IDs\n",
        "segs, gpt_raw_text, gpt_ids = choose_segments_with_gpt(trans.get(\"segments\", []))  # NEW\n",
        "assert segs, \"Nenhum segmento selecionado.\"\n",
        "\n",
        "# NEW: salvar JSON com a resposta da OpenAI e os trechos escolhidos (pr√©-alinhamento)\n",
        "save_openai_selection_json(\n",
        "    out_dir=OUT_DIR,\n",
        "    stamp=stamp,\n",
        "    base_video=base,\n",
        "    model_name=OPENAI_GPT,\n",
        "    raw_response_text=gpt_raw_text,\n",
        "    selected_ids=gpt_ids,\n",
        "    picked_segments=segs,\n",
        "    all_segments=trans.get(\"segments\", [])\n",
        ")  # NEW\n",
        "\n",
        "print(\"\\nüìã Segmentos escolhidos (antes do alinhamento):\")\n",
        "for i,s in enumerate(segs,1):\n",
        "    print(f\"  {i:02d}. {s['start']:.2f}s ‚Üí {s['end']:.2f}s  ({s['end']-s['start']:.2f}s)  | {s['text'][:80]}‚Ä¶\")\n",
        "\n",
        "kfs_base = list_keyframes(base)\n",
        "dur_base = duration_of(base)\n",
        "\n",
        "work = Path(tempfile.mkdtemp(prefix=\"teaser_kf_breath_\"))\n",
        "clips = []\n",
        "try:\n",
        "    for i,s in enumerate(segs,1):\n",
        "        out = work/f\"seg_{i:03d}.mp4\"\n",
        "        ok = cut_copy_keyaligned(base, out, s[\"start\"], s[\"end\"], kfs_base, dur_base)\n",
        "        if not ok: raise RuntimeError(f\"Falha no corte do clipe {i}\")\n",
        "        clips.append(out)\n",
        "\n",
        "    lst = work/\"list.txt\"\n",
        "    with lst.open(\"w\", encoding=\"utf-8\") as fp:\n",
        "        for c in clips: fp.write(f\"file '{c.as_posix()}'\\n\")\n",
        "\n",
        "    outp  = Path(OUT_DIR)/f\"{stamp}_teaser.mp4\"   # usa o mesmo stamp do JSON\n",
        "    if outp.exists(): outp.unlink()\n",
        "    assert concat_copy(lst, outp), \"Concat falhou.\"\n",
        "    print(\"\\n‚úÖ TEASER pronto:\", outp)\n",
        "\n",
        "finally:\n",
        "    shutil.rmtree(work, ignore_errors=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g1I1m9ocJOqH"
      },
      "source": [
        "# BMG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SRWt9rp7vPPZ",
        "outputId": "30fe380a-ada5-4984-8fdd-d0ebc4fd410a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìπ Base: 20251117_134418_teaser.mp4\n",
            "‚è±Ô∏è  Dura√ß√£o do teaser: 98.37s\n",
            "üé∂ BGM escolhida no Drive: 03.04 - IntroducÃßaÃÉo e Shorts (Remix) (21).wav (110.0s) [alvo=98.4s]\n",
            "\n",
            "‚úÖ TEASER + BGM gerado com sucesso!\n",
            "üéß BGM: 03.04 - IntroducÃßaÃÉo e Shorts (Remix) (21).wav\n",
            "üì¶ Sa√≠da: /content/03 - Teasers/20251117_134604_teaser_bgm.mp4\n"
          ]
        }
      ],
      "source": [
        "# === ETAPA 3 ‚Äî BGM direto do Google Drive (sem copiar tudo) ==================\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "import subprocess, json, shutil, os, tempfile\n",
        "\n",
        "# ---------- CONFIG (respeita envs da C√©lula 01) ----------\n",
        "TEASERS_DIR = os.environ.get(\"DIR_TEASERS\", \"/content/03 - Teasers\")\n",
        "ASSETS_TMP  = os.environ.get(\"DIR_ASSETS\",  \"/content/04 - Assets\")\n",
        "\n",
        "# Caminho RELATIVO dentro do MyDrive onde est√£o os √°udios\n",
        "DRIVE_ASSETS_SUBDIR = os.environ.get(\n",
        "    \"DRIVE_ASSETS_SUBDIR\",\n",
        "    \"01 - Alpha Centauri/04 - Diretoria de Projetos/05 - V√≠deos/03 - Fontes/assets\"\n",
        ")\n",
        "\n",
        "BGM_VOLUME_DB = -5.0   # ganho da BGM no mix\n",
        "FADE_OUT_S    = 2.0    # fade-out na BGM no final\n",
        "MAX_EXTRA_S   = 20.0   # aceita BGM at√© +20s acima da dura√ß√£o do v√≠deo\n",
        "AUDIO_CODECS  = (\".mp3\", \".m4a\", \".aac\", \".wav\", \".flac\", \".ogg\")\n",
        "\n",
        "# ---------- helpers ----------\n",
        "def run(cmd):\n",
        "    return subprocess.run(cmd, capture_output=True, text=True)\n",
        "\n",
        "def ffprobe_duration(p: Path) -> float:\n",
        "    r = run([\"ffprobe\",\"-v\",\"error\",\"-show_entries\",\"format=duration\",\n",
        "             \"-of\",\"default=nw=1:nk=1\", str(p)])\n",
        "    try:\n",
        "        return float((r.stdout or \"0\").strip())\n",
        "    except:\n",
        "        return 0.0\n",
        "\n",
        "def latest_teaser() -> Path:\n",
        "    base = Path(TEASERS_DIR)\n",
        "    files = sorted(base.glob(\"*_teaser.mp4\"), key=lambda x: x.stat().st_mtime, reverse=True)\n",
        "    assert files, f\"Nenhum teaser em {TEASERS_DIR}\"\n",
        "    print(\"üìπ Base:\", files[0].name)\n",
        "    return files[0]\n",
        "\n",
        "def ensure_drive():\n",
        "    \"\"\"\n",
        "    Monta o Drive em /content/99-Drive (C√©lula 01) se ainda n√£o estiver montado.\n",
        "    Se j√° existir /content/drive, tamb√©m aceita como fallback.\n",
        "    \"\"\"\n",
        "    root_99 = Path(\"/content/99-Drive\")\n",
        "    root_colab = Path(\"/content/drive\")\n",
        "    if root_99.exists() and (root_99 / \"MyDrive\").exists():\n",
        "        return  # j√° montado no local ‚Äúoficial‚Äù deste notebook\n",
        "    if root_colab.exists() and (root_colab / \"MyDrive\").exists():\n",
        "        return  # montado no caminho padr√£o do Colab; usaremos como fallback\n",
        "    # tenta montar agora\n",
        "    try:\n",
        "        from google.colab import drive\n",
        "        root_99.mkdir(parents=True, exist_ok=True)\n",
        "        drive.mount(str(root_99), force_remount=True)\n",
        "        print(f\"üîê Drive montado em: {root_99}\")\n",
        "    except Exception as e:\n",
        "        raise SystemExit(f\"‚ùå N√£o consegui montar o Drive automaticamente: {e}\")\n",
        "\n",
        "def drive_mydrive_root() -> Path:\n",
        "    \"\"\"Retorna o Path do MyDrive, preferindo /content/99-Drive/MyDrive.\"\"\"\n",
        "    p1 = Path(\"/content/99-Drive/MyDrive\")\n",
        "    p2 = Path(\"/content/drive/MyDrive\")\n",
        "    if p1.exists():\n",
        "        return p1\n",
        "    if p2.exists():\n",
        "        return p2\n",
        "    raise FileNotFoundError(\"MyDrive n√£o encontrado. Monte o Drive na C√©lula 01 ou rode ensure_drive().\")\n",
        "\n",
        "def choose_bgm_in_drive(target_s: float) -> Path:\n",
        "    \"\"\"Escolhe UMA faixa no Drive lendo **dura√ß√£o via ffprobe** (sem copiar).\"\"\"\n",
        "    base = drive_mydrive_root() / DRIVE_ASSETS_SUBDIR\n",
        "    assert base.exists(), f\"Pasta n√£o existe no Drive: {base}\"\n",
        "\n",
        "    # lista SOMENTE esta pasta (sem recurs√£o)\n",
        "    candidates = [p for p in base.glob(\"*\") if p.suffix.lower() in AUDIO_CODECS]\n",
        "    assert candidates, f\"Nenhum √°udio encontrado em {base}\"\n",
        "\n",
        "    scored = []\n",
        "    for p in candidates:\n",
        "        d = ffprobe_duration(p)\n",
        "        if d <= 0:\n",
        "            continue\n",
        "        # 1¬∫ grupo: >= target e <= target+MAX_EXTRA_S (quanto MENOR acima do target, melhor)\n",
        "        # 2¬∫ grupo: sobras (mais pr√≥ximo poss√≠vel)\n",
        "        if d >= target_s and d <= target_s + MAX_EXTRA_S:\n",
        "            score = (0, d - target_s)\n",
        "        else:\n",
        "            score = (1, abs(d - target_s))\n",
        "        scored.append((score, p, d))\n",
        "\n",
        "    assert scored, \"N√£o foi poss√≠vel medir dura√ß√£o de nenhum √°udio.\"\n",
        "    scored.sort(key=lambda x: x[0])\n",
        "    _, pick, dur = scored[0]\n",
        "    print(f\"üé∂ BGM escolhida no Drive: {pick.name} ({dur:.1f}s) [alvo={target_s:.1f}s]\")\n",
        "    return pick\n",
        "\n",
        "def make_bgm_exact(src_drive_path: Path, exact_s: float, fade_out_s: float, out_path: Path) -> Path:\n",
        "    \"\"\"Gera uma BGM com dura√ß√£o exata (loop/trim + fade-out) **sem copiar original**.\"\"\"\n",
        "    out_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "    st = max(0.0, exact_s - fade_out_s)\n",
        "    af = f\"atrim=0:{exact_s},asetpts=N/SR/TB,afade=t=out:st={st}:d={fade_out_s}\"\n",
        "    cmd = [\n",
        "        \"ffmpeg\",\"-y\",\n",
        "        \"-stream_loop\",\"-1\",\"-i\", str(src_drive_path),\n",
        "        \"-t\", f\"{exact_s}\",\n",
        "        \"-af\", af,\n",
        "        \"-c:a\",\"aac\",\"-b:a\",\"192k\",\n",
        "        str(out_path)\n",
        "    ]\n",
        "    r = run(cmd)\n",
        "    if r.returncode != 0:\n",
        "        raise RuntimeError(\"Falha ao preparar BGM exata:\\n\" + r.stderr)\n",
        "    return out_path\n",
        "\n",
        "def mix_audio(video_in: Path, bgm_in: Path, out_path: Path, bgm_db: float):\n",
        "    \"\"\"Mix: v√≠deo copy, √°udio mix (voz + bgm).\"\"\"\n",
        "    f = f\"[1:a]volume={bgm_db}dB[bgm];[0:a][bgm]amix=inputs=2:duration=first:dropout_transition=0[aout]\"\n",
        "    cmd = [\n",
        "        \"ffmpeg\",\"-y\",\n",
        "        \"-i\", str(video_in), \"-i\", str(bgm_in),\n",
        "        \"-filter_complex\", f,\n",
        "        \"-map\",\"0:v:0\",\"-c:v\",\"copy\",\n",
        "        \"-map\",\"[aout]\",\"-c:a\",\"aac\",\"-b:a\",\"192k\",\n",
        "        \"-movflags\",\"+faststart\",\n",
        "        str(out_path)\n",
        "    ]\n",
        "    r = run(cmd)\n",
        "    if r.returncode != 0:\n",
        "        raise RuntimeError(\"Falha no mix:\\n\" + r.stderr)\n",
        "\n",
        "# ---------- pipeline ----------\n",
        "# 1) v√≠deo base\n",
        "base = latest_teaser()\n",
        "base_dur = ffprobe_duration(base)\n",
        "print(f\"‚è±Ô∏è  Dura√ß√£o do teaser: {base_dur:.2f}s\")\n",
        "\n",
        "# 2) monta drive (se necess√°rio) e escolhe UMA BGM por dura√ß√£o (metadado direto no Drive)\n",
        "ensure_drive()\n",
        "bgm_drive = choose_bgm_in_drive(base_dur)\n",
        "\n",
        "# 3) cria/limpa pasta de assets tempor√°rios e gera BGM exata\n",
        "shutil.rmtree(ASSETS_TMP, ignore_errors=True)\n",
        "Path(ASSETS_TMP).mkdir(parents=True, exist_ok=True)\n",
        "bgm_exact = Path(ASSETS_TMP) / \"bgm_exact.m4a\"\n",
        "make_bgm_exact(bgm_drive, base_dur, FADE_OUT_S, bgm_exact)\n",
        "\n",
        "# 4) sa√≠da final (em 03 - Teasers)\n",
        "ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "out_path = Path(TEASERS_DIR) / f\"{ts}_teaser_bgm.mp4\"\n",
        "mix_audio(base, bgm_exact, out_path, BGM_VOLUME_DB)\n",
        "\n",
        "# 5) limpeza: remove o arquivo tempor√°rio gerado em 04 - Assets\n",
        "try:\n",
        "    bgm_exact.unlink(missing_ok=True)\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "print(f\"\\n‚úÖ TEASER + BGM gerado com sucesso!\")\n",
        "print(f\"üéß BGM: {bgm_drive.name}\")\n",
        "print(f\"üì¶ Sa√≠da: {out_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PANDC5A_QKVt"
      },
      "source": [
        "# Final"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FE6evZNAQOPF",
        "outputId": "9ebc880a-4e19-4aac-eeb1-1b7d4648c3c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üé¨ Fontes:\n",
            "  ‚Ä¢ Teaser         : 20251117_134604_teaser_bgm.mp4\n",
            "  ‚Ä¢ V√≠deo completo : 20251117_133921_mesclado.mp4\n",
            "\n",
            "üîç Propriedades de v√≠deo:\n",
            "  Teaser: codec=hevc  1280x720  fps‚âà29.97\n",
            "  Full  : codec=hevc  1280x720  fps‚âà29.97\n",
            "  ‚úÖ Compat√≠vel para concat(copy)\n",
            "\n",
            "‚è±Ô∏è  Dura√ß√µes:\n",
            "  Teaser: 00:01:38  (98.4s)\n",
            "  Full  : 01:04:23  (3863.7s)\n",
            "  Esperado final ‚âà 01:06:02\n",
            "\n",
            "üîß FFmpeg: ffmpeg -y -f concat -safe 0 -i /tmp/final_concat_7kystxlt/list.txt -c copy -movflags +faststart /content/05 - Final/20251117_134644_FINAL.mp4\n",
            "\n",
            "‚úÖ FINAL gerado: /content/05 - Final/20251117_134644_FINAL.mp4\n",
            "   Dura√ß√£o real: 01:06:02 (3962.1s)\n",
            "   ‚úÖ Dura√ß√£o ok.\n",
            "\n",
            "Pronto! (copy puro, sem reencode)  üìÅ /content/05 - Final/20251117_134644_FINAL.mp4\n"
          ]
        }
      ],
      "source": [
        "# === ETAPA 4 ‚Äî FINAL (copy puro) =============================================\n",
        "# Junta: [teaser + BGM] + [v√≠deo mesclado completo] ‚Üí 05 - Final/<ts>_FINAL.mp4\n",
        "# - Concat demuxer em -c copy (sem reencode)\n",
        "# - Checagem r√°pida de compatibilidade (codec / resolu√ß√£o / FPS) ‚Äî aviso apenas\n",
        "\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "import subprocess, json, os, tempfile\n",
        "\n",
        "TEASERS_DIR = os.environ.get(\"DIR_TEASERS\",  \"/content/03 - Teasers\")\n",
        "FULL_DIR    = os.environ.get(\"DIR_MESCLADO\", \"/content/02 - Mesclado\")\n",
        "FINAL_DIR   = os.environ.get(\"DIR_FINAL\",    \"/content/05 - Final\")\n",
        "\n",
        "TEASER_PATTERNS = [\"*_teaser_bgm.mp4\", \"*_teaser_with_bgm.mp4\", \"*_teaser.mp4\"]\n",
        "FULL_PATTERNS   = [\"*_mesclado.mp4\", \"*_concatenated*.mp4\"]\n",
        "\n",
        "def run(cmd):\n",
        "    return subprocess.run(cmd, capture_output=True, text=True)\n",
        "\n",
        "def latest_by_patterns(folder: str, patterns):\n",
        "    folder = Path(folder)\n",
        "    paths = []\n",
        "    for pat in patterns:\n",
        "        paths += list(folder.glob(pat))\n",
        "    if not paths:\n",
        "        raise FileNotFoundError(f\"Nenhum arquivo encontrado em {folder} com padr√µes {patterns}\")\n",
        "    return max(paths, key=lambda x: x.stat().st_mtime)\n",
        "\n",
        "def ffprobe_props(path: Path) -> dict:\n",
        "    r = run([\"ffprobe\",\"-v\",\"error\",\"-show_streams\",\"-show_format\",\"-print_format\",\"json\",str(path)])\n",
        "    return json.loads(r.stdout) if r.stdout else {}\n",
        "\n",
        "def vid_stream(props: dict) -> dict:\n",
        "    for s in props.get(\"streams\", []):\n",
        "        if s.get(\"codec_type\") == \"video\":\n",
        "            return s\n",
        "    return {}\n",
        "\n",
        "def duration(path: Path) -> float:\n",
        "    r = run([\"ffprobe\",\"-v\",\"error\",\"-show_entries\",\"format=duration\",\"-of\",\"default=nw=1:nk=1\", str(path)])\n",
        "    try: return float((r.stdout or \"0\").strip())\n",
        "    except: return 0.0\n",
        "\n",
        "def fps_str(vs: dict) -> str:\n",
        "    fr = vs.get(\"r_frame_rate\") or vs.get(\"avg_frame_rate\") or \"\"\n",
        "    if \"/\" in fr:\n",
        "        n, d = fr.split(\"/\", 1)\n",
        "        try: return f\"{round(float(n)/float(d), 2)}\"\n",
        "        except: pass\n",
        "    return fr or \"?\"\n",
        "\n",
        "def human_dur(s: float) -> str:\n",
        "    m, s = divmod(int(s), 60)\n",
        "    h, m = divmod(m, 60)\n",
        "    return f\"{h:02d}:{m:02d}:{s:02d}\"\n",
        "\n",
        "# --- localizar fontes\n",
        "teaser = latest_by_patterns(TEASERS_DIR, TEASER_PATTERNS)\n",
        "full   = latest_by_patterns(FULL_DIR,    FULL_PATTERNS)\n",
        "Path(FINAL_DIR).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(\"üé¨ Fontes:\")\n",
        "print(\"  ‚Ä¢ Teaser         :\", teaser.name)\n",
        "print(\"  ‚Ä¢ V√≠deo completo :\", full.name)\n",
        "\n",
        "# --- checagem de compatibilidade (aviso)\n",
        "tp, fp = ffprobe_props(teaser), ffprobe_props(full)\n",
        "ts, fs = vid_stream(tp), vid_stream(fp)\n",
        "\n",
        "print(\"\\nüîç Propriedades de v√≠deo:\")\n",
        "print(f\"  Teaser: codec={ts.get('codec_name','?')}  {ts.get('width','?')}x{ts.get('height','?')}  fps‚âà{fps_str(ts)}\")\n",
        "print(f\"  Full  : codec={fs.get('codec_name','?')}  {fs.get('width','?')}x{fs.get('height','?')}  fps‚âà{fps_str(fs)}\")\n",
        "\n",
        "compatible = (\n",
        "    ts.get(\"codec_name\") == fs.get(\"codec_name\") and\n",
        "    ts.get(\"width\")      == fs.get(\"width\")      and\n",
        "    ts.get(\"height\")     == fs.get(\"height\")     and\n",
        "    (ts.get(\"r_frame_rate\") == fs.get(\"r_frame_rate\") or ts.get(\"avg_frame_rate\") == fs.get(\"avg_frame_rate\"))\n",
        ")\n",
        "print(\"  ‚úÖ Compat√≠vel para concat(copy)\" if compatible else \"  ‚ö†Ô∏è Propriedades diferentes ‚Äî concat(copy) pode falhar.\")\n",
        "\n",
        "# --- dura√ß√µes\n",
        "td, fd = duration(teaser), duration(full)\n",
        "print(\"\\n‚è±Ô∏è  Dura√ß√µes:\")\n",
        "print(f\"  Teaser: {human_dur(td)}  ({td:.1f}s)\")\n",
        "print(f\"  Full  : {human_dur(fd)}  ({fd:.1f}s)\")\n",
        "print(f\"  Esperado final ‚âà {human_dur(td+fd)}\")\n",
        "\n",
        "# --- concat (copy puro)\n",
        "tstamp   = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "out_path = Path(FINAL_DIR) / f\"{tstamp}_FINAL.mp4\"\n",
        "\n",
        "with tempfile.TemporaryDirectory(prefix=\"final_concat_\") as workdir:\n",
        "    lst = Path(workdir) / \"list.txt\"\n",
        "    lst.write_text(\n",
        "        f\"file '{Path(teaser).resolve()}'\\nfile '{Path(full).resolve()}'\\n\",\n",
        "        encoding=\"utf-8\"\n",
        "    )\n",
        "\n",
        "    cmd = [\"ffmpeg\",\"-y\",\"-f\",\"concat\",\"-safe\",\"0\",\"-i\",str(lst),\n",
        "           \"-c\",\"copy\",\"-movflags\",\"+faststart\", str(out_path)]\n",
        "    print(\"\\nüîß FFmpeg:\", \" \".join(cmd))\n",
        "    r = run(cmd)\n",
        "    if r.returncode != 0:\n",
        "        print(\"‚ùå Erro na concatena√ß√£o:\\n\", r.stderr)\n",
        "        raise SystemExit(1)\n",
        "\n",
        "# --- verifica√ß√£o final\n",
        "final_dur = duration(out_path)\n",
        "print(\"\\n‚úÖ FINAL gerado:\", out_path)\n",
        "print(f\"   Dura√ß√£o real: {human_dur(final_dur)} ({final_dur:.1f}s)\")\n",
        "if abs(final_dur - (td+fd)) > 1.0:\n",
        "    print(\"   ‚ö†Ô∏è Observa√ß√£o: dura√ß√£o diferente da esperada (varia√ß√£o > 1s).\")\n",
        "else:\n",
        "    print(\"   ‚úÖ Dura√ß√£o ok.\")\n",
        "\n",
        "print(\"\\nPronto! (copy puro, sem reencode)  üìÅ\", out_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQDGCuZoysLZ"
      },
      "source": [
        "# Thumbnail"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aWTZrMr9yvCJ",
        "outputId": "ecaee9f3-224d-4634-a047-d49ec499006b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìÑ JSON: /content/03 - Teasers/20251117_134418_teaser_openai.json\n",
            "üìπ Base: 20251117_133921_mesclado.mp4\n",
            "üß≠ Carregando keyframes‚Ä¶\n",
            "   ‚Üí 2005 keyframes mapeados.\n",
            "‚úÖ [01] t=0.000s ‚Üí 20251117_134418_frame_001_id000_00000.000s.jpg\n",
            "‚úÖ [02] t=437.000s ‚Üí 20251117_134418_frame_002_id114_00437.000s.jpg\n",
            "‚úÖ [03] t=736.000s ‚Üí 20251117_134418_frame_003_id228_00736.000s.jpg\n",
            "‚úÖ [04] t=952.000s ‚Üí 20251117_134418_frame_004_id342_00952.000s.jpg\n",
            "‚úÖ [05] t=1283.000s ‚Üí 20251117_134418_frame_005_id456_01283.000s.jpg\n",
            "‚úÖ [06] t=1583.500s ‚Üí 20251117_134418_frame_006_id570_01583.500s.jpg\n",
            "‚úÖ [07] t=1910.000s ‚Üí 20251117_134418_frame_007_id684_01910.000s.jpg\n",
            "‚úÖ [08] t=2185.500s ‚Üí 20251117_134418_frame_008_id798_02185.500s.jpg\n",
            "‚úÖ [09] t=2531.940s ‚Üí 20251117_134418_frame_009_id912_02531.940s.jpg\n",
            "‚úÖ [10] t=3054.500s ‚Üí 20251117_134418_frame_010_id1026_03054.500s.jpg\n",
            "‚úÖ [11] t=3314.500s ‚Üí 20251117_134418_frame_011_id1140_03314.500s.jpg\n",
            "‚úÖ [12] t=3578.500s ‚Üí 20251117_134418_frame_012_id1254_03578.500s.jpg\n",
            "üóÇÔ∏è Manifest: 20251117_134418_frames_manifest.json\n"
          ]
        }
      ],
      "source": [
        "# =============== ETAPA 6 ‚Äî FRAMES (r√°pido + exato com 2 est√°gios) ===============\n",
        "# L√™ o JSON *_teaser_openai.json, localiza o v√≠deo base e salva 1 frame em cada in√≠cio.\n",
        "# Estrat√©gia 2-step seek:\n",
        "#   1) -ss <keyframe_anterior> antes do -i  (r√°pido)\n",
        "#   2) -ss <delta> depois do -i             (preciso, decodando s√≥ o necess√°rio)\n",
        "# -------------------------------------------------------------------------------\n",
        "\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "import subprocess, json, os, re, math\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "\n",
        "# --- Pastas / Config ---\n",
        "IN_DIR       = os.environ.get(\"DIR_MESCLADO\", \"/content/02 - Mesclado\")\n",
        "TEASERS_DIR  = os.environ.get(\"DIR_TEASERS\",  \"/content/03 - Teasers\")\n",
        "FRAMES_DIR   = os.environ.get(\"DIR_FRAMES\",   \"/content/06 - Frames\")\n",
        "JSON_PATH    = os.environ.get(\"TEASER_OPENAI_JSON\", \"\").strip()\n",
        "\n",
        "FRAME_EXT    = \".jpg\"     # \".png\" se preferir sem perdas\n",
        "JPG_QSCALE   = \"2\"        # 1..31 (menor = melhor)\n",
        "MAX_WORKERS  = max(2, (os.cpu_count() or 4)//2)  # paralelismo controlado\n",
        "KF_EPS       = 1e-6       # epsilon p/ compara√ß√£o de tempos\n",
        "\n",
        "def run(cmd:list):\n",
        "    return subprocess.run(cmd, capture_output=True, text=True)\n",
        "\n",
        "def find_latest_openai_json(teasers_dir: str) -> Path:\n",
        "    cands = sorted(Path(teasers_dir).glob(\"*_teaser_openai.json\"), key=lambda p: p.stat().st_mtime, reverse=True)\n",
        "    if not cands:\n",
        "        raise FileNotFoundError(f\"Nenhum *_teaser_openai.json em {teasers_dir}.\")\n",
        "    return cands[0]\n",
        "\n",
        "def load_selection(json_path: Path) -> dict:\n",
        "    data = json.loads(json_path.read_text(encoding=\"utf-8\"))\n",
        "    assert data.get(\"selected_segments\"), \"JSON sem 'selected_segments'.\"\n",
        "    assert data.get(\"video_base\"), \"JSON sem 'video_base'.\"\n",
        "    assert data.get(\"created_at\"), \"JSON sem 'created_at'.\"\n",
        "    return data\n",
        "\n",
        "def locate_base_video(in_dir: str, video_name: str) -> Path:\n",
        "    cand = Path(in_dir) / video_name\n",
        "    if cand.exists():\n",
        "        return cand\n",
        "    stem = Path(video_name).stem\n",
        "    globs = list(Path(in_dir).glob(f\"*{stem}*.mp4\"))\n",
        "    if globs:\n",
        "        return sorted(globs, key=lambda p: p.stat().st_mtime, reverse=True)[0]\n",
        "    raise FileNotFoundError(f\"V√≠deo base n√£o encontrado: {video_name} (em {in_dir}).\")\n",
        "\n",
        "def ensure_dir(d: str):\n",
        "    Path(d).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def format_stamp_safe(stamp: str) -> str:\n",
        "    return re.sub(r\"[^0-9_]\", \"\", stamp)\n",
        "\n",
        "def list_keyframes(src: Path):\n",
        "    # Lista keyframes uma vez. R√°pido gra√ßas ao -skip_frame nokey.\n",
        "    r = run([\n",
        "        \"ffprobe\",\"-v\",\"error\",\n",
        "        \"-select_streams\",\"v:0\",\n",
        "        \"-skip_frame\",\"nokey\",\n",
        "        \"-show_frames\",\n",
        "        \"-show_entries\",\"frame=best_effort_timestamp_time\",\n",
        "        \"-of\",\"csv=p=0\",\n",
        "        str(src)\n",
        "    ])\n",
        "    kf = []\n",
        "    for line in (r.stdout or \"\").splitlines():\n",
        "        try:\n",
        "            kf.append(float(line.strip()))\n",
        "        except:\n",
        "            pass\n",
        "    if not kf or kf[0] > 0.0 + KF_EPS:\n",
        "        kf = [0.0] + kf  # garante 0.0\n",
        "    return kf\n",
        "\n",
        "def prev_keyframe(kfs, t: float) -> float:\n",
        "    # √∫ltimo keyframe <= t\n",
        "    lo, hi = 0, len(kfs)-1\n",
        "    ans = 0.0\n",
        "    while lo <= hi:\n",
        "        mid = (lo+hi)//2\n",
        "        if kfs[mid] <= t + KF_EPS:\n",
        "            ans = kfs[mid]\n",
        "            lo = mid + 1\n",
        "        else:\n",
        "            hi = mid - 1\n",
        "    return ans\n",
        "\n",
        "def extract_frame_two_step(video: Path, t_seconds: float, out_path: Path, kfs) -> bool:\n",
        "    t_seconds = max(0.0, float(t_seconds))\n",
        "    k0 = prev_keyframe(kfs, t_seconds)\n",
        "    delta = max(0.0, t_seconds - k0)\n",
        "    # Passo 1: -ss k0 antes do -i (r√°pido) | Passo 2: -ss delta depois do -i (preciso)\n",
        "    cmd = [\n",
        "        \"ffmpeg\",\"-hide_banner\",\"-loglevel\",\"error\",\"-nostdin\",\"-y\",\n",
        "        \"-ss\", f\"{k0:.6f}\",\n",
        "        \"-i\", str(video),\n",
        "        \"-ss\", f\"{delta:.6f}\",\n",
        "        \"-an\",\n",
        "        \"-frames:v\",\"1\"\n",
        "    ]\n",
        "    if out_path.suffix.lower() == \".jpg\":\n",
        "        cmd += [\"-q:v\", JPG_QSCALE]\n",
        "    cmd += [str(out_path)]\n",
        "    r = run(cmd)\n",
        "    if r.returncode != 0:\n",
        "        print(\"ffmpeg erro:\", r.stderr.strip()[:400])\n",
        "    return r.returncode == 0\n",
        "\n",
        "# ------------------------ Pipeline ------------------------\n",
        "try:\n",
        "    json_file = Path(JSON_PATH) if JSON_PATH else find_latest_openai_json(TEASERS_DIR)\n",
        "    print(\"üìÑ JSON:\", json_file)\n",
        "\n",
        "    data   = load_selection(json_file)\n",
        "    stamp  = format_stamp_safe(data[\"created_at\"])\n",
        "    base   = locate_base_video(IN_DIR, data[\"video_base\"])\n",
        "    segs   = sorted(data[\"selected_segments\"], key=lambda s: float(s[\"start\"]))\n",
        "    ensure_dir(FRAMES_DIR)\n",
        "\n",
        "    print(\"üìπ Base:\", base.name)\n",
        "    print(\"üß≠ Carregando keyframes‚Ä¶\")\n",
        "    kfs = list_keyframes(base)\n",
        "    print(f\"   ‚Üí {len(kfs)} keyframes mapeados.\")\n",
        "\n",
        "    # Dispara em paralelo controlado\n",
        "    futures = []\n",
        "    results = []\n",
        "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as ex:\n",
        "        for idx, s in enumerate(segs, 1):\n",
        "            t0  = float(s[\"start\"])\n",
        "            sid = int(s.get(\"id\", idx))\n",
        "            out_name = f\"{stamp}_frame_{idx:03d}_id{sid:03d}_{t0:09.3f}s{FRAME_EXT}\"\n",
        "            out_path = Path(FRAMES_DIR) / out_name\n",
        "            futures.append(ex.submit(extract_frame_two_step, base, t0, out_path, kfs))\n",
        "\n",
        "        # Coleta (mantendo ordem de envio p/ logs mais limpos)\n",
        "        for i, f in enumerate(futures, 1):\n",
        "            ok = f.result()\n",
        "            status = \"‚úÖ\" if ok else \"‚ùå\"\n",
        "            s = segs[i-1]\n",
        "            print(f\"{status} [{i:02d}] t={float(s['start']):.3f}s ‚Üí {stamp}_frame_{i:03d}_id{int(s.get('id',i)):03d}_{float(s['start']):09.3f}s{FRAME_EXT}\")\n",
        "\n",
        "    # Manifesto simples\n",
        "    manifest = Path(FRAMES_DIR) / f\"{stamp}_frames_manifest.json\"\n",
        "    items = []\n",
        "    for idx, s in enumerate(segs, 1):\n",
        "        t0  = float(s[\"start\"])\n",
        "        sid = int(s.get(\"id\", idx))\n",
        "        items.append({\n",
        "            \"index\": idx,\n",
        "            \"id\": sid,\n",
        "            \"start\": round(t0, 3),\n",
        "            \"file\": f\"{stamp}_frame_{idx:03d}_id{sid:03d}_{t0:09.3f}s{FRAME_EXT}\"\n",
        "        })\n",
        "    manifest.write_text(json.dumps({\n",
        "        \"created_at\": stamp,\n",
        "        \"video_base\": base.name,\n",
        "        \"frames_dir\": str(Path(FRAMES_DIR)),\n",
        "        \"count\": len(items),\n",
        "        \"items\": items\n",
        "    }, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
        "    print(\"üóÇÔ∏è Manifest:\", manifest.name)\n",
        "\n",
        "except Exception as e:\n",
        "    print(\"‚ùå Erro:\", e)\n",
        "    raise\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LwauXBcj2q2U",
        "outputId": "12024313-4e33-4b04-da5d-fad49a8cf0ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Plano gerado: /content/07 - Thumbnails/20251117_134418_thumbs_right_plan.json\n",
            "   Frames: 12\n",
            "   Sa√≠das:\n",
            "   /content/07 - Thumbnails/20251117_134418_thumb_01_right.jpg\n",
            "   /content/07 - Thumbnails/20251117_134418_thumb_02_right.jpg\n",
            "   /content/07 - Thumbnails/20251117_134418_thumb_03_right.jpg\n"
          ]
        }
      ],
      "source": [
        "# === CELL 1: PLANO / PAR√ÇMETROS -> salva *_thumbs_right_plan.json ===============\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "import os, json, re, shutil, requests\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "\n",
        "# ---------------- PATHS / VARS -------------------------------------------------\n",
        "DIR_FRAMES  = Path(os.environ.get(\"DIR_FRAMES\", \"/content/06 - Frames\"))\n",
        "DIR_THUMBS  = Path(os.environ.get(\"DIR_THUMBS\", \"/content/07 - Thumbnails\"))\n",
        "DIR_TEASERS = Path(os.environ.get(\"DIR_TEASERS\", \"/content/03 - Teasers\"))\n",
        "DIR_THUMBS.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "API_KEY   = (os.getenv(\"OPENAI_API_KEY\") or \"\").strip()\n",
        "GPT_MODEL = os.environ.get(\"OPENAI_GPT\", \"gpt-4o-mini\")\n",
        "assert API_KEY, \"Defina OPENAI_API_KEY\"\n",
        "\n",
        "ORANGE_HEX = \"#ff9900\"\n",
        "SCALE = 2\n",
        "CHECKER_H_FRAC = 0.035\n",
        "PIN_R = 28  # raio base do pin (antes do SCALE)\n",
        "\n",
        "# Minis (propor√ß√µes da √ÅREA INTERNA; borda pequena que acompanha o tamanho)\n",
        "MINI_INNER_W_FRAC = 0.44\n",
        "MINI_INNER_H_FRAC = 0.26\n",
        "MINI_BORDER_FRAC  = 0.06      # borda = 6% do menor lado da √°rea interna (pequena)\n",
        "MINI_BORDER_MIN   = 6*SCALE   # piso\n",
        "MINI_BORDER_MAX   = 28*SCALE  # teto\n",
        "\n",
        "# ---------------- HELPERS ------------------------------------------------------\n",
        "def clear_dir(d: Path):\n",
        "    d.mkdir(parents=True, exist_ok=True)\n",
        "    for p in d.glob(\"*\"):\n",
        "        try:\n",
        "            p.unlink() if p.is_file() or p.is_symlink() else shutil.rmtree(p, ignore_errors=True)\n",
        "        except: pass\n",
        "\n",
        "def latest_manifest(frames_dir: Path) -> Path:\n",
        "    cands = sorted(frames_dir.glob(\"*_frames_manifest.json\"), key=lambda p: p.stat().st_mtime, reverse=True)\n",
        "    if not cands: raise FileNotFoundError(f\"Nenhum *_frames_manifest.json em {frames_dir}\")\n",
        "    return cands[0]\n",
        "\n",
        "def load_frames_names(manifest_path: Path):\n",
        "    data  = json.loads(manifest_path.read_text(encoding=\"utf-8\"))\n",
        "    names = [it[\"file\"] for it in data.get(\"items\", []) if \"file\" in it]\n",
        "    if not names: raise RuntimeError(\"Manifest sem itens.\")\n",
        "    return names, data\n",
        "\n",
        "def latest_transcript_json(teasers_dir: Path) -> Path | None:\n",
        "    cands = sorted(teasers_dir.glob(\"*_mesclado_transcript.json\"), key=lambda p: p.stat().st_mtime, reverse=True)\n",
        "    return cands[0] if cands else None\n",
        "\n",
        "def load_calistoga(size:int)->ImageFont.FreeTypeFont:\n",
        "    font_dir=Path(\"/content/_fonts\"); font_dir.mkdir(parents=True, exist_ok=True)\n",
        "    ttf = font_dir/\"Calistoga-Regular.ttf\"\n",
        "    if not ttf.exists():\n",
        "        u=\"https://github.com/google/fonts/raw/main/ofl/calistoga/Calistoga-Regular.ttf\"\n",
        "        r=requests.get(u,timeout=30); r.raise_for_status(); ttf.write_bytes(r.content)\n",
        "    return ImageFont.truetype(str(ttf), size)\n",
        "\n",
        "def gpt_three_variants(transc: dict, model:str, api_key:str):\n",
        "    segs = transc.get(\"segments\", [])\n",
        "    text = \" \".join((s.get(\"text\",\"\") or \"\").strip() for s in segs)[:6000]\n",
        "    url=\"https://api.openai.com/v1/chat/completions\"\n",
        "    headers={\"Authorization\":f\"Bearer {api_key}\",\"Content-Type\":\"application/json\"}\n",
        "    sys = {\"role\":\"system\",\"content\":\n",
        "           \"Voc√™ cria 3 alternativas curtas e objetivas para thumbnails do YouTube. \"\n",
        "           \"Responda APENAS JSON (lista de 3 objetos) com: \"\n",
        "           \"location_title (<=22), location_subtitle (<=28), \"\n",
        "           \"head_top (<=28), head_bottom (<=28). PT-BR, sem emojis.\"}\n",
        "    usr = {\"role\":\"user\",\"content\": f\"Resumo da transcri√ß√£o:\\n{text}\\nGere as 3 alternativas nos limites acima.\"}\n",
        "    data = {\"model\": model, \"messages\":[sys,usr], \"temperature\":0.5, \"max_tokens\":220}\n",
        "    try:\n",
        "        r=requests.post(url,headers=headers,json=data,timeout=90); r.raise_for_status()\n",
        "        content=r.json()[\"choices\"][0][\"message\"][\"content\"]\n",
        "        m=re.search(r\"\\[.*\\]\", content, flags=re.S)\n",
        "        arr=json.loads(m.group(0) if m else content)\n",
        "        def norm(it):\n",
        "            return {\n",
        "                \"location_title\": (it.get(\"location_title\",\"S√ÉO PAULO\") or \"\")[:22],\n",
        "                \"location_subtitle\": (it.get(\"location_subtitle\",\"PARQUE DO TROTE\") or \"\")[:28],\n",
        "                \"head_top\": (it.get(\"head_top\",\"ALMO√áO E CULTURA\") or \"\")[:28],\n",
        "                \"head_bottom\": (it.get(\"head_bottom\",\"O QUE FAZER EM 2025?\") or \"\")[:28],\n",
        "            }\n",
        "        out=[norm(x) for x in arr[:3]]\n",
        "        while len(out)<3: out.append(out[-1])\n",
        "        return out[:3]\n",
        "    except Exception:\n",
        "        return [\n",
        "            {\"location_title\":\"S√ÉO PAULO\",\"location_subtitle\":\"PARQUE DO TROTE\",\n",
        "             \"head_top\":\"ALMO√áO E CULTURA\",\"head_bottom\":\"O QUE FAZER EM 2025?\"},\n",
        "            {\"location_title\":\"S√ÉO PAULO\",\"location_subtitle\":\"EXPERI√äNCIA √öNICA\",\n",
        "             \"head_top\":\"CLIMA E DIVERS√ÉO\",\"head_bottom\":\"SABOR E TRADI√á√ÉO\"},\n",
        "            {\"location_title\":\"S√ÉO PAULO\",\"location_subtitle\":\"REVELANDO 2025\",\n",
        "             \"head_top\":\"PASSEIO IMPERD√çVEL!\",\"head_bottom\":\"CULTURA & SABORES\"},\n",
        "        ]\n",
        "\n",
        "def text_fit_sizes(variants, W0, H0):\n",
        "    \"\"\"Calcula tamanhos de fontes CONSISTENTES que cabem em todas as 3 vers√µes.\"\"\"\n",
        "    from PIL import Image, ImageDraw\n",
        "    W, H = W0*SCALE, H0*SCALE\n",
        "    draw = ImageDraw.Draw(Image.new(\"RGB\",(10,10)))\n",
        "\n",
        "    def fits_all(size, texts, maxw):\n",
        "        f=load_calistoga(size)\n",
        "        return all(draw.textlength((t or \"\").upper(), font=f) <= maxw for t in texts)\n",
        "\n",
        "    max_w_loc = int(W*0.42) - ((PIN_R+16)*SCALE + 20*SCALE)   # √°rea √∫til ao lado do pin\n",
        "    pad_x = 26*SCALE\n",
        "    max_w_head = int(W*0.56) - 2*pad_x\n",
        "\n",
        "    size_loc_title = int(0.10 * H0) * SCALE\n",
        "    size_loc_sub   = int(0.06 * H0) * SCALE\n",
        "    size_head_top  = int(0.10 * H0) * SCALE\n",
        "    size_head_bot  = int(0.10 * H0) * SCALE\n",
        "\n",
        "    loc_titles = [v[\"location_title\"] for v in variants]\n",
        "    loc_subs   = [v[\"location_subtitle\"] for v in variants]\n",
        "    heads_top  = [v[\"head_top\"] for v in variants]\n",
        "    heads_bot  = [v[\"head_bottom\"] for v in variants]\n",
        "\n",
        "    while size_loc_title > 24*SCALE and not fits_all(size_loc_title, loc_titles, max_w_loc):\n",
        "        size_loc_title -= 2*SCALE\n",
        "    while size_loc_sub > 20*SCALE and not fits_all(size_loc_sub, loc_subs, max_w_loc):\n",
        "        size_loc_sub -= 2*SCALE\n",
        "    while size_head_top > 24*SCALE and not fits_all(size_head_top, heads_top, max_w_head):\n",
        "        size_head_top -= 2*SCALE\n",
        "    while size_head_bot > 24*SCALE and not fits_all(size_head_bot, heads_bot, max_w_head):\n",
        "        size_head_bot -= 2*SCALE\n",
        "\n",
        "    return {\n",
        "        \"location_title\": size_loc_title,\n",
        "        \"location_sub\":   size_loc_sub,\n",
        "        \"head_top\":       size_head_top,\n",
        "        \"head_bottom\":    size_head_bot\n",
        "    }\n",
        "\n",
        "def ensure_unique_fg(n, bg, a, b):\n",
        "    \"\"\"Garante que minis n√£o repitam o fundo nem entre si.\"\"\"\n",
        "    used = {bg}\n",
        "    if n <= 1: return bg, bg\n",
        "    if a in used:\n",
        "        a = (a + 1) % n\n",
        "        if a in used: a = (a + 1) % n\n",
        "    used.add(a)\n",
        "    if b in used:\n",
        "        b = (b + 1) % n\n",
        "        if b in used: b = (b + 1) % n\n",
        "        if b in used and n >= 3:\n",
        "            b = (b + 1) % n\n",
        "    if a == b and n >= 3:\n",
        "        b = (b + 1) % n\n",
        "        if b in used: b = (b + 1) % n\n",
        "    return a, b\n",
        "\n",
        "# ---------------- PIPELINE (PLANO) --------------------------------------------\n",
        "# Limpa a pasta de thumbs para produzir tudo do zero\n",
        "clear_dir(DIR_THUMBS)\n",
        "\n",
        "# Frames\n",
        "manifest_path = latest_manifest(DIR_FRAMES)\n",
        "frame_names, frames_meta = load_frames_names(manifest_path)\n",
        "stamp = frames_meta.get(\"created_at\") or datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "# Transcript -> textos\n",
        "trp = latest_transcript_json(DIR_TEASERS)\n",
        "transc = json.loads(trp.read_text(encoding=\"utf-8\")) if trp else {\"segments\":[]}\n",
        "variants_texts = gpt_three_variants(transc, GPT_MODEL, API_KEY)\n",
        "\n",
        "# Dimens√£o base (usa o 1¬∫ frame p/ refer√™ncia) ‚Äî apenas leitura do size\n",
        "tmp_img_path = DIR_FRAMES / frame_names[0]\n",
        "from PIL import Image\n",
        "W0,H0 = Image.open(tmp_img_path).size\n",
        "\n",
        "# Fontes consistentes (apenas tamanhos; a c√©lula 2 carrega a Calistoga)\n",
        "font_sizes = text_fit_sizes(variants_texts, W0, H0)\n",
        "\n",
        "# Tr√≠ades (bg, mini1, mini2) cobrindo come√ßo/meio/fim, com unicidade\n",
        "n=len(frame_names)\n",
        "triples=[]\n",
        "bg_list=[0, max(1,n//2), n-1]\n",
        "for b in bg_list:\n",
        "    m1 = min(max(1, b + max(1,n//6)), n-2 if n>=2 else n-1)\n",
        "    m2 = min(max(m1+1, b + max(2,n//4)), n-1)\n",
        "    m1, m2 = ensure_unique_fg(n, b, m1, m2)\n",
        "    triples.append({\"bg\":b, \"mini1\":m1, \"mini2\":m2})\n",
        "\n",
        "# PLANO JSON (nenhum desenho aqui)\n",
        "plan = {\n",
        "    \"created_at\": stamp,\n",
        "    \"source_frames_manifest\": Path(manifest_path).name,\n",
        "    \"frame_names\": frame_names,\n",
        "    \"variants_texts\": variants_texts,\n",
        "    \"dimensions\": {\"W0\": W0, \"H0\": H0, \"scale\": SCALE},\n",
        "    \"style\":{\n",
        "        \"font\":\"Calistoga\",\n",
        "        \"orange\":ORANGE_HEX,\n",
        "        \"layout\":\"right\",\n",
        "        \"checker_h_frac\": CHECKER_H_FRAC,\n",
        "        \"pin_r\": PIN_R,\n",
        "        \"mini\":{\n",
        "            \"inner_w_frac\": MINI_INNER_W_FRAC,\n",
        "            \"inner_h_frac\": MINI_INNER_H_FRAC,\n",
        "            \"border_frac\":  MINI_BORDER_FRAC,\n",
        "            \"border_min_px\": MINI_BORDER_MIN,\n",
        "            \"border_max_px\": MINI_BORDER_MAX\n",
        "        },\n",
        "        \"font_sizes\": font_sizes\n",
        "    },\n",
        "    \"triples\": triples,\n",
        "    \"outputs\":[str(DIR_THUMBS / f\"{stamp}_thumb_{i:02d}_right.jpg\") for i in range(1,4)]\n",
        "}\n",
        "plan_path = DIR_THUMBS / f\"{stamp}_thumbs_right_plan.json\"\n",
        "plan_path.write_text(json.dumps(plan, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
        "\n",
        "print(\"‚úÖ Plano gerado:\", plan_path)\n",
        "print(\"   Frames:\", len(frame_names))\n",
        "print(\"   Sa√≠das:\", *plan[\"outputs\"], sep=\"\\n   \")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SpTrQtivk4vq",
        "outputId": "c6482464-e7dc-4b49-ff22-7c4a3684e64a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Thumbnails renderizadas (layout e PIN fixos nas 3 vers√µes):\n",
            "  - /content/07 - Thumbnails/20251117_134418_thumb_01_right.jpg\n",
            "  - /content/07 - Thumbnails/20251117_134418_thumb_02_right.jpg\n",
            "  - /content/07 - Thumbnails/20251117_134418_thumb_03_right.jpg\n"
          ]
        }
      ],
      "source": [
        "# === CELL 2: DESENHO -> l√™ *_thumbs_right_plan.json e renderiza =================\n",
        "from pathlib import Path\n",
        "import os, json, glob\n",
        "from PIL import Image, ImageDraw, ImageFont, ImageFilter, ImageEnhance\n",
        "\n",
        "# ---------------- PATHS --------------------------------------------------------\n",
        "DIR_FRAMES  = Path(os.environ.get(\"DIR_FRAMES\", \"/content/06 - Frames\"))\n",
        "DIR_THUMBS  = Path(os.environ.get(\"DIR_THUMBS\", \"/content/07 - Thumbnails\"))\n",
        "\n",
        "# ---------------- CORES --------------------------------------------------------\n",
        "def hex_to_rgb(h): return tuple(int(h[i:i+2],16) for i in (1,3,5))\n",
        "BLACK=(0,0,0); WHITE=(255,255,255)\n",
        "\n",
        "# ---------------- LOAD PLAN ----------------------------------------------------\n",
        "def latest_plan_json(thumbs_dir: Path) -> Path:\n",
        "    cands = sorted(thumbs_dir.glob(\"*_thumbs_right_plan.json\"), key=lambda p: p.stat().st_mtime, reverse=True)\n",
        "    if not cands: raise FileNotFoundError(\"Nenhum *_thumbs_right_plan.json encontrado.\")\n",
        "    return cands[0]\n",
        "\n",
        "plan_path = latest_plan_json(DIR_THUMBS)\n",
        "plan = json.loads(plan_path.read_text(encoding=\"utf-8\"))\n",
        "\n",
        "# Params do plano\n",
        "SCALE           = plan[\"dimensions\"][\"scale\"]\n",
        "CHECKER_H_FRAC  = plan[\"style\"][\"checker_h_frac\"]\n",
        "PIN_R_BASE      = plan[\"style\"][\"pin_r\"]\n",
        "ORANGE_HEX      = plan[\"style\"][\"orange\"]\n",
        "ORANGE_RGB      = hex_to_rgb(ORANGE_HEX)\n",
        "\n",
        "# Limites e bordas dos minis (vindos do plano)\n",
        "MAX_W_FRAC = plan[\"style\"][\"mini\"][\"inner_w_frac\"]\n",
        "MAX_H_FRAC = plan[\"style\"][\"mini\"][\"inner_h_frac\"]\n",
        "BORDER_FRAC  = plan[\"style\"][\"mini\"][\"border_frac\"]\n",
        "BORDER_MIN   = plan[\"style\"][\"mini\"][\"border_min_px\"]\n",
        "BORDER_MAX   = plan[\"style\"][\"mini\"][\"border_max_px\"]\n",
        "\n",
        "# ---------------- HELPERS DE DESENHO ------------------------------------------\n",
        "def fit_center_crop(img: Image.Image, w: int, h: int) -> Image.Image:\n",
        "    iw, ih = img.size; tr=w/h; ir=iw/ih\n",
        "    if ir>tr:\n",
        "        nw=int(ih*tr); x0=(iw-nw)//2; img=img.crop((x0,0,x0+nw,ih))\n",
        "    else:\n",
        "        nh=int(iw/tr); y0=(ih-nh)//2; img=img.crop((0,y0,iw,y0+nh))\n",
        "    return img.resize((w,h), Image.LANCZOS)\n",
        "\n",
        "def load_calistoga(size:int)->ImageFont.FreeTypeFont:\n",
        "    font_dir=Path(\"/content/_fonts\"); font_dir.mkdir(parents=True, exist_ok=True)\n",
        "    ttf = font_dir/\"Calistoga-Regular.ttf\"\n",
        "    if not ttf.exists():\n",
        "        import requests\n",
        "        u=\"https://github.com/google/fonts/raw/main/ofl/calistoga/Calistoga-Regular.ttf\"\n",
        "        r=requests.get(u,timeout=30); r.raise_for_status(); ttf.write_bytes(r.content)\n",
        "    return ImageFont.truetype(str(ttf), size)\n",
        "\n",
        "def text_size(draw, txt, font):\n",
        "    x0,y0,x1,y1 = draw.textbbox((0,0), txt, font=font)\n",
        "    return (x1-x0, y1-y0)\n",
        "\n",
        "def draw_checker_bar(img: Image.Image, h:int, tile_w:int):\n",
        "    bar = Image.new(\"RGB\",(img.width,h), BLACK)\n",
        "    d=ImageDraw.Draw(bar)\n",
        "    x=0; alt=False\n",
        "    while x<img.width:\n",
        "        if alt: d.rectangle([x,0,min(x+tile_w,img.width),h], fill=ORANGE_RGB)\n",
        "        alt=not alt; x+=tile_w\n",
        "    img.paste(bar,(0,img.height-h)); return img\n",
        "\n",
        "def thumb_card_border_hug(photo: Image.Image, max_w:int, max_h:int):\n",
        "    \"\"\"\n",
        "    Mini cuja borda gruda na foto (sem folga):\n",
        "    - S√≥ faz downscale se a foto exceder (max_w,max_h). Nunca estica.\n",
        "    - Card final: (foto_w + 2*border, foto_h + 2*border).\n",
        "    \"\"\"\n",
        "    r = min(max_w / photo.width, max_h / photo.height, 1.0)\n",
        "    img = photo.resize((max(1,int(photo.width*r)), max(1,int(photo.height*r))), Image.LANCZOS) if r < 1.0 else photo.copy()\n",
        "\n",
        "    base = min(img.width, img.height)\n",
        "    border = int(base * BORDER_FRAC)\n",
        "    border = max(BORDER_MIN, min(BORDER_MAX, border))\n",
        "\n",
        "    outer_w, outer_h = img.width + 2*border, img.height + 2*border\n",
        "\n",
        "    card = Image.new(\"RGBA\",(outer_w, outer_h),(0,0,0,0))\n",
        "    d=ImageDraw.Draw(card)\n",
        "    outer_radius = int(min(border * 0.6, min(outer_w, outer_h) * 0.08))\n",
        "    inner_radius = max(1, outer_radius - 2*SCALE)\n",
        "\n",
        "    shadow = Image.new(\"RGBA\",(outer_w, outer_h),(0,0,0,0))\n",
        "    ds = ImageDraw.Draw(shadow)\n",
        "    ds.rounded_rectangle([0,0,outer_w,outer_h], radius=outer_radius, fill=(0,0,0,140))\n",
        "    shadow = shadow.filter(ImageFilter.GaussianBlur(5*SCALE))\n",
        "\n",
        "    d.rounded_rectangle([0,0,outer_w,outer_h], radius=outer_radius, fill=WHITE)\n",
        "\n",
        "    mask = Image.new(\"L\",(outer_w, outer_h),0)\n",
        "    dm = ImageDraw.Draw(mask)\n",
        "    dm.rounded_rectangle([border, border, outer_w-border, outer_h-border], radius=inner_radius, fill=255)\n",
        "\n",
        "    slot = Image.new(\"RGBA\",(outer_w, outer_h),(0,0,0,0))\n",
        "    slot.paste(img,(border, border))\n",
        "\n",
        "    out = Image.new(\"RGBA\",(outer_w, outer_h),(0,0,0,0))\n",
        "    out.alpha_composite(shadow,(0,0))\n",
        "    out.alpha_composite(card,(0,0))\n",
        "    out = Image.composite(slot, out, mask)\n",
        "    return out\n",
        "\n",
        "def rotate_and_place(canvas: Image.Image, card: Image.Image, angle:float, center_xy, margin:int):\n",
        "    rot = card.rotate(angle, expand=True, resample=Image.BICUBIC)\n",
        "    W,H = canvas.size\n",
        "    x = int(center_xy[0] - rot.width/2)\n",
        "    y = int(center_xy[1] - rot.height/2)\n",
        "    x = max(margin, min(x, W-rot.width - margin))\n",
        "    y = max(margin, min(y, H-rot.height - margin))\n",
        "    canvas.alpha_composite(rot,(x,y))\n",
        "\n",
        "# --------- helper p/ centralizar texto no ret√¢ngulo (sem depender de 'anchor') -\n",
        "def draw_text_centered(d: ImageDraw.ImageDraw, box, text, font, fill):\n",
        "    x0, y0, x1, y1 = d.textbbox((0,0), text, font=font)  # bbox real do texto\n",
        "    w, h = (x1 - x0), (y1 - y0)\n",
        "    bx, by, bx2, by2 = box\n",
        "    cx = bx + (bx2 - bx) / 2\n",
        "    cy = by + (by2 - by) / 2\n",
        "    draw_x = cx - w / 2 - x0\n",
        "    draw_y = cy - h / 2 - y0\n",
        "    d.text((draw_x, draw_y), text, font=font, fill=fill)\n",
        "\n",
        "# ---------------- LAYOUT FIXO (repete para as 3 thumbs) ------------------------\n",
        "# Calcula TODOS os posicionamentos e tamanhos apenas com base na THUMB 1.\n",
        "W0, H0 = plan[\"dimensions\"][\"W0\"], plan[\"dimensions\"][\"H0\"]\n",
        "W, H   = W0*SCALE, H0*SCALE\n",
        "\n",
        "# Headlines (usa a 1¬™ variante para definir o BG comum a todas)\n",
        "pad_x = 26*SCALE\n",
        "pad_y = 16*SCALE\n",
        "left  = int(24*SCALE)\n",
        "top1  = int(H*0.60)\n",
        "gap   = 10*SCALE\n",
        "max_w_head = int(W*0.56)\n",
        "\n",
        "common_head_size = min(plan[\"style\"][\"font_sizes\"][\"head_top\"],\n",
        "                       plan[\"style\"][\"font_sizes\"][\"head_bottom\"])\n",
        "_f_tmp = load_calistoga(common_head_size)\n",
        "_d_tmp = ImageDraw.Draw(Image.new(\"RGB\",(10,10)))\n",
        "\n",
        "t1_ref = (plan[\"variants_texts\"][0][\"head_top\"] or \"\").upper()\n",
        "t2_ref = (plan[\"variants_texts\"][0][\"head_bottom\"] or \"\").upper()\n",
        "w1r, h1r = text_size(_d_tmp, t1_ref, _f_tmp)\n",
        "w2r, h2r = text_size(_d_tmp, t2_ref, _f_tmp)\n",
        "line_h_ref = max(h1r, h2r)\n",
        "box_w_fixed = min(max(w1r, w2r) + 2*pad_x, max_w_head)\n",
        "box_h_fixed = line_h_ref + 2*pad_y\n",
        "\n",
        "# Minis (mesmos centros/√¢ngulos para todas; +20% e leve shift p/ esquerda)\n",
        "growth  = 1.20\n",
        "mini_max_w = int(W * MAX_W_FRAC * growth)\n",
        "mini_max_h = int(H * MAX_H_FRAC * growth)\n",
        "shift_x = int(W * 0.04)\n",
        "centers_fixed = [(int(W*0.78) - shift_x, int(H*0.30)),\n",
        "                 (int(W*0.84) - shift_x, int(H*0.64))]\n",
        "angles_fixed  = [-6.0, 6.0]\n",
        "\n",
        "# --- PIN E TEXTOS DE LOCAL: posi√ß√£o 100% fixa entre as 3 thumbs ----------------\n",
        "loc_size_title = plan[\"style\"][\"font_sizes\"][\"location_title\"]\n",
        "loc_size_sub   = plan[\"style\"][\"font_sizes\"][\"location_sub\"]\n",
        "_f_loc_title   = load_calistoga(loc_size_title)\n",
        "_f_loc_sub     = load_calistoga(loc_size_sub)\n",
        "_d_loc         = ImageDraw.Draw(Image.new(\"RGB\",(10,10)))\n",
        "# usa a 1¬™ variante como refer√™ncia (apenas para medir alturas)\n",
        "loc_t1_ref = (plan[\"variants_texts\"][0][\"location_title\"] or \"\").upper()\n",
        "loc_t2_ref = (plan[\"variants_texts\"][0][\"location_subtitle\"] or \"\").upper()\n",
        "_, h_loc1  = text_size(_d_loc, loc_t1_ref, _f_loc_title)\n",
        "_, h_loc2  = text_size(_d_loc, loc_t2_ref, _f_loc_sub)\n",
        "loc_gap    = 6*SCALE\n",
        "block_h_loc = h_loc1 + loc_gap + h_loc2\n",
        "\n",
        "pin_top_y  = int(16*SCALE)\n",
        "pin_cx     = int(52*SCALE)\n",
        "pin_cy     = pin_top_y + block_h_loc//2\n",
        "pin_leftpad= 20*SCALE\n",
        "pin_pr     = int(PIN_R_BASE * SCALE)\n",
        "\n",
        "LAYOUT = {\n",
        "    \"pad_x\": pad_x, \"pad_y\": pad_y,\n",
        "    \"left\": left, \"top1\": top1, \"gap\": gap,\n",
        "    \"head_font_size\": common_head_size,\n",
        "    \"box_w\": box_w_fixed, \"box_h\": box_h_fixed,\n",
        "    \"mini_max_w\": mini_max_w, \"mini_max_h\": mini_max_h,\n",
        "    \"centers\": centers_fixed, \"angles\": angles_fixed,\n",
        "    # PIN / LOCAL fixed\n",
        "    \"pin_top_y\": pin_top_y, \"pin_cx\": pin_cx, \"pin_cy\": pin_cy,\n",
        "    \"pin_leftpad\": pin_leftpad, \"pin_pr\": pin_pr,\n",
        "    \"loc_h1\": h_loc1, \"loc_gap\": loc_gap\n",
        "}\n",
        "\n",
        "def draw_map_pin_with_text_FIXED(canvas, t_loc, t_sub, f_loc, f_sub, layout):\n",
        "    \"\"\"Mesma posi√ß√£o do pin e dos textos nas 3 thumbs.\"\"\"\n",
        "    d   = ImageDraw.Draw(canvas)\n",
        "    pr  = layout[\"pin_pr\"]\n",
        "    cx  = layout[\"pin_cx\"]\n",
        "    cy  = layout[\"pin_cy\"]\n",
        "    top = layout[\"pin_top_y\"]\n",
        "    tx  = cx + pr + layout[\"pin_leftpad\"]\n",
        "\n",
        "    # PIN com contorno branco\n",
        "    pin = Image.new(\"RGBA\",(4*pr,5*pr),(0,0,0,0))\n",
        "    pd  = ImageDraw.Draw(pin)\n",
        "    cxp, cyp = 2*pr, 2*pr\n",
        "    pd.ellipse([cxp-pr, cyp-pr, cxp+pr, cyp+pr], fill=ORANGE_RGB)\n",
        "    pd.polygon([(cxp, cyp+pr), (cxp-0.95*pr, cyp-0.1*pr), (cxp+0.95*pr, cyp-0.1*pr)], fill=ORANGE_RGB)\n",
        "    pd.ellipse([cxp-0.42*pr, cyp-0.42*pr, cxp+0.42*pr, cyp+0.42*pr], fill=WHITE)\n",
        "    blur = pin.filter(ImageFilter.GaussianBlur(2*SCALE))\n",
        "    r,g,b,a = blur.split(); a = a.point(lambda v: 255 if v>0 else 0)\n",
        "    white = Image.new(\"L\", a.size, 255)\n",
        "    outline = Image.merge(\"RGBA\",(white,white,white,a))\n",
        "    canvas.alpha_composite(outline,(cx-2*pr, cy-2*pr))\n",
        "    canvas.alpha_composite(pin,    (cx-2*pr, cy-2*pr))\n",
        "\n",
        "    # TEXTOS (posi√ß√µes baseadas na mesma m√©trica para todas)\n",
        "    t1 = (t_loc or \"\").upper()\n",
        "    t2 = (t_sub or \"\").upper()\n",
        "\n",
        "    def soft(x,y,txt,font,fill):\n",
        "        layer=Image.new(\"RGBA\",canvas.size,(0,0,0,0)); ld=ImageDraw.Draw(layer)\n",
        "        ld.text((x+2*SCALE,y+2*SCALE), txt, font=font, fill=(0,0,0,120))\n",
        "        layer=layer.filter(ImageFilter.GaussianBlur(0.8*SCALE))\n",
        "        canvas.alpha_composite(layer)\n",
        "        d.text((x,y), txt, font=font, fill=fill)\n",
        "\n",
        "    soft(tx, top, t1, f_loc, WHITE)\n",
        "    # usa a ALTURA REF para manter o mesmo espa√ßamento nas 3 thumbs\n",
        "    y2 = top + LAYOUT[\"loc_h1\"] + LAYOUT[\"loc_gap\"]\n",
        "    soft(tx, y2, t2, f_sub, WHITE)\n",
        "\n",
        "# ---------------- RENDER -------------------------------------------------------\n",
        "def render_right_variant(frames, bg_idx, fg_idxs, texts, out_path: Path,\n",
        "                         sizes, style, layout):\n",
        "    W0,H0 = sizes[\"W0\"], sizes[\"H0\"]\n",
        "    W,H = W0*SCALE, H0*SCALE\n",
        "\n",
        "    # fontes\n",
        "    f_loc_title = load_calistoga(style[\"font_sizes\"][\"location_title\"])\n",
        "    f_loc_sub   = load_calistoga(style[\"font_sizes\"][\"location_sub\"])\n",
        "    f_head      = load_calistoga(layout[\"head_font_size\"])\n",
        "\n",
        "    # Fundo\n",
        "    bg = fit_center_crop(frames[bg_idx], W, H)\n",
        "    bg = ImageEnhance.Contrast(bg).enhance(1.04)\n",
        "    bg = ImageEnhance.Sharpness(bg).enhance(1.05)\n",
        "    vignette = Image.new(\"L\",(W,H),0)\n",
        "    vd = ImageDraw.Draw(vignette)\n",
        "    vd.ellipse([int(-0.1*W), int(-0.2*H), int(1.1*W), int(1.3*H)], fill=255)\n",
        "    vignette = vignette.filter(ImageFilter.GaussianBlur(90*SCALE))\n",
        "    bg = Image.composite(bg.point(lambda v: int(v*0.94)), bg, vignette)\n",
        "    canvas = bg.convert(\"RGBA\")\n",
        "\n",
        "    # Pin + localiza√ß√£o (posi√ß√£o FIXA vinda do layout)\n",
        "    draw_map_pin_with_text_FIXED(canvas, texts[\"location_title\"], texts[\"location_subtitle\"],\n",
        "                                 f_loc_title, f_loc_sub, layout)\n",
        "\n",
        "    # Minis (sempre os mesmos tamanhos/posi√ß√µes)\n",
        "    for fg_i, center, ang in zip(fg_idxs, layout[\"centers\"], layout[\"angles\"]):\n",
        "        card = thumb_card_border_hug(frames[fg_i], layout[\"mini_max_w\"], layout[\"mini_max_h\"])\n",
        "        rotate_and_place(canvas, card, ang, center, margin=14*SCALE)\n",
        "\n",
        "    # HEADLINES (mesma fonte e mesmo BG para todas as thumbs)\n",
        "    d = ImageDraw.Draw(canvas)\n",
        "    box_w = layout[\"box_w\"]; box_h = layout[\"box_h\"]\n",
        "    left  = layout[\"left\"];  top1  = layout[\"top1\"]; gap = layout[\"gap\"]\n",
        "\n",
        "    box1 = (left, top1,             left + box_w, top1 + box_h)\n",
        "    box2 = (left, top1 + box_h+gap, left + box_w, top1 + box_h + gap + box_h)\n",
        "\n",
        "    d.rounded_rectangle(box1, radius=14*SCALE, fill=WHITE)\n",
        "    d.rounded_rectangle(box2, radius=14*SCALE, fill=WHITE)\n",
        "\n",
        "    t1 = (texts[\"head_top\"] or \"\").upper()\n",
        "    t2 = (texts[\"head_bottom\"] or \"\").upper()\n",
        "    draw_text_centered(d, box1, t1, f_head, BLACK)\n",
        "    draw_text_centered(d, box2, t2, f_head, ORANGE_RGB)\n",
        "\n",
        "    # Barra xadrez\n",
        "    out = canvas.convert(\"RGB\")\n",
        "    checker_h = max(10*SCALE, int(H * CHECKER_H_FRAC))\n",
        "    tile_w    = int(W * 0.055)\n",
        "    out = draw_checker_bar(out, checker_h, tile_w)\n",
        "\n",
        "    # Downscale\n",
        "    out = out.resize((W0,H0), Image.LANCZOS)\n",
        "    out.save(out_path, \"JPEG\", quality=96, optimize=True, progressive=True)\n",
        "    return str(out_path)\n",
        "\n",
        "# ---------- Limpa thumbs antigas antes de renderizar ---------------------------\n",
        "for p in list(DIR_THUMBS.glob(\"*_thumb_*_right.jpg\")):\n",
        "    try: p.unlink()\n",
        "    except: pass\n",
        "\n",
        "# ---------- L√™ frames a partir do manifest referenciado no plano ---------------\n",
        "def load_frames_by_manifest(dir_frames: Path, manifest_name: str):\n",
        "    mp = dir_frames / manifest_name\n",
        "    data  = json.loads(mp.read_text(encoding=\"utf-8\"))\n",
        "    imgs, names = [], []\n",
        "    for it in data.get(\"items\", []):\n",
        "        p = dir_frames / it[\"file\"]\n",
        "        if p.exists() and p.stat().st_size>0:\n",
        "            try:\n",
        "                imgs.append(Image.open(p).convert(\"RGB\")); names.append(it[\"file\"])\n",
        "            except: pass\n",
        "    if not imgs: raise RuntimeError(\"Nenhum frame v√°lido do manifest.\")\n",
        "    return imgs, names\n",
        "\n",
        "frames, names = load_frames_by_manifest(DIR_FRAMES, plan[\"source_frames_manifest\"])\n",
        "\n",
        "# ---------- Render para cada variante (2 e 3 seguem exatamente a 1) -----------\n",
        "outs=[]\n",
        "for i, tri in enumerate(plan[\"triples\"], start=1):\n",
        "    bg, m1, m2 = tri[\"bg\"], tri[\"mini1\"], tri[\"mini2\"]\n",
        "    texts = plan[\"variants_texts\"][i-1]\n",
        "    outp  = Path(plan[\"outputs\"][i-1])\n",
        "    outs.append(\n",
        "        render_right_variant(frames, bg, (m1,m2), texts, outp,\n",
        "                             sizes=plan[\"dimensions\"], style=plan[\"style\"], layout=LAYOUT)\n",
        "    )\n",
        "\n",
        "# ---------- Salva MANIFEST final (com sa√≠das) ----------------------------------\n",
        "manifest = dict(plan)\n",
        "manifest[\"outputs\"] = outs\n",
        "(DIR_THUMBS / f'{plan[\"created_at\"]}_thumbs_right_manifest.json').write_text(\n",
        "    json.dumps(manifest, ensure_ascii=False, indent=2), encoding=\"utf-8\"\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Thumbnails renderizadas (layout e PIN fixos nas 3 vers√µes):\")\n",
        "for p in outs: print(\"  -\", p)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_IM0N_IQw4qV"
      },
      "source": [
        "# SEO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fT-2CwYzw6Ks",
        "outputId": "1da5bef9-3637-4568-9a94-ec92807349a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìÑ Manifesto: /content/07 - Thumbnails/20251117_134418_thumbs_right_manifest.json\n",
            "üóíÔ∏è Transcri√ß√£o: /content/03 - Teasers/20251117_133921_mesclado_transcript.json\n",
            "üñºÔ∏è Thumbs detectadas: 3\n",
            "  01. /content/07 - Thumbnails/20251117_134418_thumb_01_right.jpg  |  variant: {'location_title': 'Aeroporto de Congonhas', 'location_subtitle': 'Rumo a Curitiba', 'head_top': 'Voo Tranquilo', 'head_bottom': 'Aventura em Curitiba'}\n",
            "  02. /content/07 - Thumbnails/20251117_134418_thumb_02_right.jpg  |  variant: {'location_title': 'Curitiba Chegando', 'location_subtitle': 'Explorando a Cidade', 'head_top': 'Viagem de Motorhome', 'head_bottom': 'Novidades na Expo'}\n",
            "  03. /content/07 - Thumbnails/20251117_134418_thumb_03_right.jpg  |  variant: {'location_title': 'Descobrindo Curitiba', 'location_subtitle': 'Aeroporto e Transfer', 'head_top': 'Aventura de Avi√£o', 'head_bottom': 'Capivaras e Moda'}\n",
            "üíæ Sa√≠da SEO: /content/08 - SEO/20251117_134418_thumbs_right_seo.json\n",
            "\n",
            "üìä Total para processar: 3 | Modelo: gpt-4o-mini\n",
            "\n",
            "üîÑ [1/3] Gerando SEO para: /content/07 - Thumbnails/20251117_134418_thumb_01_right.jpg\n",
            "   ‚úÖ JSON ok\n",
            "\n",
            "üîÑ [2/3] Gerando SEO para: /content/07 - Thumbnails/20251117_134418_thumb_02_right.jpg\n",
            "   ‚úÖ JSON ok\n",
            "\n",
            "üîÑ [3/3] Gerando SEO para: /content/07 - Thumbnails/20251117_134418_thumb_03_right.jpg\n",
            "   ‚úÖ JSON ok\n",
            "\n",
            "üìå RESUMO\n",
            "   ‚úÖ Sucesso: 3\n",
            "   ‚ùå Erros: 0\n",
            "   üíæ Arquivo salvo: /content/08 - SEO/20251117_134418_thumbs_right_seo.json\n"
          ]
        }
      ],
      "source": [
        "# ==============================================\n",
        "# üöÄ Colab ‚Äî SEO a partir das thumbs (descrever.py adaptado c/ TRANSCRI√á√ÉO)\n",
        "# Requisitos:\n",
        "#   pip install --quiet openai>=1.30\n",
        "#   Defina OPENAI_API_KEY no ambiente OU crie /content/api-openai/api_key.json {\"api_key\": \"...\"}\n",
        "# ==============================================\n",
        "!pip -q install openai>=1.30.0\n",
        "\n",
        "import os, json, time, re\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "from typing import Tuple, Dict, Any, List, Optional\n",
        "from openai import OpenAI\n",
        "\n",
        "# ---------- Configs principais ----------\n",
        "THUMBS_DIR = Path(\"/content/07 - Thumbnails\")\n",
        "SEO_DIR    = Path(\"/content/08 - SEO\")\n",
        "SEO_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# ==============================================\n",
        "# Entradas vari√°veis deste job\n",
        "MANIFEST_BASENAME   = \"20251117_134418_thumbs_right_manifest.json\"\n",
        "TRANSCRIPT_BASENAME = \"20251117_133921_mesclado_transcript.json\"\n",
        "# ==============================================\n",
        "\n",
        "# Locais prov√°veis dos arquivos\n",
        "MANIFEST_PATHS = [\n",
        "    THUMBS_DIR / MANIFEST_BASENAME,\n",
        "    Path(\"/content\") / MANIFEST_BASENAME,\n",
        "    Path(\"/mnt/data\") / MANIFEST_BASENAME,\n",
        "]\n",
        "\n",
        "# Inclui 03 - Teasers conforme pedido\n",
        "TRANSCRIPT_PATHS = [\n",
        "    Path(\"/content/03 - Teasers\") / TRANSCRIPT_BASENAME,\n",
        "    Path(\"/content/05 - Transcricoes\") / TRANSCRIPT_BASENAME,\n",
        "    Path(\"/content\") / TRANSCRIPT_BASENAME,\n",
        "    Path(\"/mnt/data\") / TRANSCRIPT_BASENAME,\n",
        "]\n",
        "\n",
        "# ---------- Descobrir manifest ----------\n",
        "manifest_path = next((p for p in MANIFEST_PATHS if p.exists()), None)\n",
        "if manifest_path is None:\n",
        "    raise FileNotFoundError(\n",
        "        \"Manifesto n√£o encontrado. Procurei em:\\n\" + \"\\n\".join(str(p) for p in MANIFEST_PATHS)\n",
        "    )\n",
        "print(f\"üìÑ Manifesto: {manifest_path}\")\n",
        "\n",
        "# ---------- Descobrir transcri√ß√£o ----------\n",
        "transcript_path = next((p for p in TRANSCRIPT_PATHS if p.exists()), None)\n",
        "\n",
        "# Fallback extra: busca recursiva pelo basename dentro de /content se ainda n√£o achar\n",
        "if transcript_path is None:\n",
        "    try:\n",
        "        candidates = list(Path(\"/content\").rglob(TRANSCRIPT_BASENAME))\n",
        "        if candidates:\n",
        "            transcript_path = candidates[0]\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "if transcript_path is None:\n",
        "    raise FileNotFoundError(\n",
        "        \"Transcri√ß√£o n√£o encontrada. Procurei em:\\n\" + \"\\n\".join(str(p) for p in TRANSCRIPT_PATHS) +\n",
        "        \"\\n(e tamb√©m busquei recursivamente em /content)\"\n",
        "    )\n",
        "print(f\"üóíÔ∏è Transcri√ß√£o: {transcript_path}\")\n",
        "\n",
        "# ---------- Carregar manifesto ----------\n",
        "with open(manifest_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    manifest = json.load(f)\n",
        "\n",
        "# Espera-se:\n",
        "#   manifest['outputs'] -> lista de caminhos de thumbs (3 thumbs)\n",
        "#   manifest['variants_texts'] -> mesma quantidade e ordem das thumbs\n",
        "outputs: List[str] = manifest.get(\"outputs\", [])\n",
        "variants_texts: List[Dict[str, str]] = manifest.get(\"variants_texts\", [])\n",
        "\n",
        "if not outputs:\n",
        "    raise ValueError(\"O manifesto n√£o cont√©m 'outputs'.\")\n",
        "if not variants_texts:\n",
        "    print(\"‚ö†Ô∏è  'variants_texts' ausente no manifesto. Vou repetir o primeiro texto para todos.\")\n",
        "    variants_texts = [variants_texts[0] if variants_texts else {}] * len(outputs)\n",
        "\n",
        "# Em caso de tamanhos diferentes, emparelhar pela menor contagem:\n",
        "pair_count = min(len(outputs), len(variants_texts))\n",
        "records = [{\"thumb_path\": outputs[i], \"variant\": variants_texts[i] if i < len(variants_texts) else {}} for i in range(pair_count)]\n",
        "\n",
        "print(f\"üñºÔ∏è Thumbs detectadas: {len(records)}\")\n",
        "for i, r in enumerate(records, 1):\n",
        "    print(f\"  {i:02d}. {r['thumb_path']}  |  variant: {r['variant']}\")\n",
        "\n",
        "# ---------- Carregar transcri√ß√£o (texto base) ----------\n",
        "def extract_text_from_transcript(data: Any) -> str:\n",
        "    # formatos comuns: {\"text\": \"...\"} | {\"segments\": [{\"text\": \"...\"}]} | {\"chunks\":[{\"text\":...}]}\n",
        "    if isinstance(data, dict):\n",
        "        if isinstance(data.get(\"text\"), str) and data[\"text\"].strip():\n",
        "            return data[\"text\"]\n",
        "        for key in (\"segments\", \"chunks\", \"results\", \"monologues\", \"elements\"):\n",
        "            if isinstance(data.get(key), list) and data[key]:\n",
        "                parts = []\n",
        "                for item in data[key]:\n",
        "                    if isinstance(item, dict):\n",
        "                        for k in (\"text\", \"content\", \"alternatives\", \"transcript\"):\n",
        "                            if k in item and isinstance(item[k], str):\n",
        "                                parts.append(item[k])\n",
        "                            elif k in item and isinstance(item[k], list):\n",
        "                                for sub in item[k]:\n",
        "                                    if isinstance(sub, dict) and isinstance(sub.get(\"text\"), str):\n",
        "                                        parts.append(sub[\"text\"])\n",
        "                    elif isinstance(item, str):\n",
        "                        parts.append(item)\n",
        "                if parts:\n",
        "                    return \" \".join(parts)\n",
        "        return json.dumps(data, ensure_ascii=False)\n",
        "    elif isinstance(data, list):\n",
        "        return \" \".join([extract_text_from_transcript(x) for x in data])\n",
        "    return str(data)\n",
        "\n",
        "with open(transcript_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    transcript_raw = json.load(f)\n",
        "\n",
        "def sanitize_whitespace(s: str) -> str:\n",
        "    return re.sub(r\"\\s+\", \" \", s).strip()\n",
        "\n",
        "def excerpt(s: str, max_chars: int = 4000) -> str:\n",
        "    s = sanitize_whitespace(s)\n",
        "    return s[:max_chars]\n",
        "\n",
        "transcript_text = sanitize_whitespace(extract_text_from_transcript(transcript_raw))\n",
        "TRANSCRIPT_EXCERPT = excerpt(transcript_text, 4000)\n",
        "\n",
        "# ---------- Sa√≠da ----------\n",
        "base_name = manifest_path.stem.replace(\"_manifest\", \"\")\n",
        "seo_out_path = SEO_DIR / f\"{base_name}_seo.json\"\n",
        "print(f\"üíæ Sa√≠da SEO: {seo_out_path}\")\n",
        "\n",
        "# ---------- Chave da OpenAI ----------\n",
        "api_key = os.environ.get(\"OPENAI_API_KEY\", \"\").strip()\n",
        "if not api_key:\n",
        "    secret_file = Path(\"/content/api-openai/api_key.json\")\n",
        "    if secret_file.exists():\n",
        "        with open(secret_file, \"r\", encoding=\"utf-8\") as f:\n",
        "            api_key = json.load(f).get(\"api_key\", \"\").strip()\n",
        "if not api_key:\n",
        "    raise RuntimeError(\"OPENAI_API_KEY n√£o encontrado. Defina como vari√°vel de ambiente OU crie /content/api-openai/api_key.json com {'api_key': '...'}.\")\n",
        "\n",
        "client = OpenAI(api_key=api_key)\n",
        "modelo = OPENAI_GPT\n",
        "\n",
        "# ---------- Utilit√°rios ----------\n",
        "def validar_resposta_openai(resposta: str) -> Tuple[bool, str]:\n",
        "    try:\n",
        "        dados = json.loads(resposta.strip())\n",
        "        chaves = ['descricao', 'hashtags', 'titulo', 'tags']  # 'categoria' √© opcional\n",
        "        for c in chaves:\n",
        "            if c not in dados:\n",
        "                return False, f\"Chave '{c}' n√£o encontrada no JSON\"\n",
        "        if not isinstance(dados['descricao'], str): return False, \"Campo 'descricao' deve ser string\"\n",
        "        if not isinstance(dados['hashtags'], list): return False, \"Campo 'hashtags' deve ser lista\"\n",
        "        if not isinstance(dados['titulo'], str):    return False, \"Campo 'titulo' deve ser string\"\n",
        "        if not isinstance(dados['tags'], str):      return False, \"Campo 'tags' deve ser string\"\n",
        "        return True, \"OK\"\n",
        "    except json.JSONDecodeError as e:\n",
        "        return False, f\"JSON inv√°lido: {e}\"\n",
        "    except Exception as e:\n",
        "        return False, f\"Erro ao validar JSON: {e}\"\n",
        "\n",
        "def montar_prompt(transcript_excerpt: str, variant: Dict[str, str], thumb_path: str, titulos_anteriores: List[str]) -> str:\n",
        "    var_loc_title = variant.get(\"location_title\", \"\")\n",
        "    var_loc_sub   = variant.get(\"location_subtitle\", \"\")\n",
        "    var_head_top  = variant.get(\"head_top\", \"\")\n",
        "    var_head_bot  = variant.get(\"head_bottom\", \"\")\n",
        "\n",
        "    titulos_passados = \"\\n\".join(f\"- {t}\" for t in titulos_anteriores[-10:]) if titulos_anteriores else \"(nenhum)\"\n",
        "\n",
        "    return f\"\"\"\n",
        "Voc√™ √© um assistente de SEO para YouTube. Gere metadados em pt-BR APENAS como JSON.\n",
        "\n",
        "# TEXTO BASE (trecho da transcri√ß√£o):\n",
        "{transcript_excerpt}\n",
        "\n",
        "# DADOS DA THUMB (manifest):\n",
        "- thumb_path: {thumb_path}\n",
        "- location_title: {var_loc_title}\n",
        "- location_subtitle: {var_loc_sub}\n",
        "- head_top: {var_head_top}\n",
        "- head_bottom: {var_head_bot}\n",
        "\n",
        "# REGRAS PARA A DESCRI√á√ÉO:\n",
        "- Utilize o texto base de apoio e a transcri√ß√£o do v√≠deo para constru√ß√£o da descri√ß√£o;\n",
        "- Escreva a descri√ß√£o do v√≠deo em tr√™s par√°grafos;\n",
        "- Adicione curiosidades no meio do texto;\n",
        "- Escreva a descri√ß√£o em primeira pessoa do plural ou singular e sem erros de portugu√™s.\n",
        "\n",
        "# REGRAS PARA AS HASHTAGS:\n",
        "- Escreva uma lista com dez #hashtags.\n",
        "\n",
        "# REGRAS PARA O T√çTULO:\n",
        "- Escreva o t√≠tulo objetivo com at√© 100 caracteres, contando #hashtags nele;\n",
        "- Escreva somente os substantivos, os lugares e as marca em letras maiusculas;\n",
        "- N√£o escreve o t√≠tulo todo em ‚ÄúCAIXA ALTA‚Äù (maiusculas) nem todo em ‚Äúcaixa baixa‚Äù (min√∫sculas);\n",
        "- Escreva um t√≠tulo diferente do t√≠tulo anterior, caso exista e seja coerente modificar;\n",
        "- Relacione o t√≠tulo com a descri√ß√£o para correla√ß√£o curiosa;\n",
        "- Escreva um √∫nico emoji diferente antes do t√≠tulo;\n",
        "- Escreva sempre um emoji diferente do anterior para evitar repeti√ß√µes;\n",
        "- Escreva, ap√≥s o t√≠tulo, #hashtags de marcas e lugares.\n",
        "\n",
        "# REGRAS PARA AS TAGS:\n",
        "- Escreva at√© 500 caracteres de tags baseadas no t√≠tulo;\n",
        "- Escreva aproximadamente 20 tags;\n",
        "- Escreva tags que sejam √∫teis para diferentes pesquisas do t√≠tulo;\n",
        "- Escreva tags em um mesmo par√°grafo, sem \"#\" e separadas por v√≠rgula;\n",
        "- Sempre escreva de 2 a 4 palavras por tags;\n",
        "- As tags podem ser √∫teis caso as pessoas escrevam errado ao pesquisar o conte√∫do do seu v√≠deo.\n",
        "- Caso contr√°rio, a contribui√ß√£o das tags na descoberta do v√≠deo ser√° pequena.\n",
        "\n",
        "# T√çTULOS J√Å USADOS NESTA RODADA (evitar repetir sentido):\n",
        "{titulos_passados}\n",
        "\n",
        "# FORMATO DE RESPOSTA OBRIGAT√ìRIO (apenas JSON, sem explica√ß√µes):\n",
        "{{\n",
        "  \"descricao\": \"Tr√™s par√°grafos...\",\n",
        "  \"hashtags\": [\"#Exemplo1\", \"#Exemplo2\", \"... (total 10)\"],\n",
        "  \"titulo\": \"üåÜ T√çTULO EXEMPLO EM MAI√öSCULAS\",\n",
        "  \"tags\": \"tag exemplo 1, tag exemplo 2, ...\",\n",
        "  \"categoria\": \"19\"\n",
        "}}\n",
        "\"\"\".strip()\n",
        "\n",
        "# ---------- Execu√ß√£o ----------\n",
        "resultados = []\n",
        "titulos_gerados = []\n",
        "erros = []\n",
        "\n",
        "print(f\"\\nüìä Total para processar: {len(records)} | Modelo: {modelo}\")\n",
        "\n",
        "for i, rec in enumerate(records, start=1):\n",
        "    thumb_path = rec[\"thumb_path\"]\n",
        "    variant    = rec.get(\"variant\", {})\n",
        "\n",
        "    print(f\"\\nüîÑ [{i}/{len(records)}] Gerando SEO para: {thumb_path}\")\n",
        "    prompt = montar_prompt(TRANSCRIPT_EXCERPT, variant, thumb_path, titulos_gerados)\n",
        "\n",
        "    max_tentativas = 3\n",
        "    conteudo_valido: Optional[Dict[str, Any]] = None\n",
        "\n",
        "    for tentativa in range(1, max_tentativas + 1):\n",
        "        try:\n",
        "            resp = client.chat.completions.create(\n",
        "                model=modelo,\n",
        "                messages=[\n",
        "                    {\"role\": \"system\", \"content\": \"Voc√™ √© um assistente especializado em criar metadados para v√≠deos do YouTube. Responda APENAS com JSON v√°lido.\"},\n",
        "                    {\"role\": \"user\", \"content\": prompt},\n",
        "                ],\n",
        "                temperature=0.35,\n",
        "                response_format={\"type\": \"json_object\"}\n",
        "            )\n",
        "            raw = resp.choices[0].message.content\n",
        "            ok, msg = validar_resposta_openai(raw)\n",
        "            if ok:\n",
        "                dados = json.loads(raw.strip())\n",
        "                conteudo_valido = dados\n",
        "                print(\"   ‚úÖ JSON ok\")\n",
        "                break\n",
        "            else:\n",
        "                print(f\"   ‚ö†Ô∏è Resposta inv√°lida (tentativa {tentativa}/{max_tentativas}): {msg}\")\n",
        "        except Exception as e:\n",
        "            print(f\"   ‚ùå Erro API (tentativa {tentativa}/{max_tentativas}): {e}\")\n",
        "\n",
        "        if tentativa < max_tentativas:\n",
        "            print(\"   ‚è≥ Aguardando 3s para nova tentativa...\")\n",
        "            time.sleep(3)\n",
        "\n",
        "    if not conteudo_valido:\n",
        "        print(\"   ‚ùå Falha definitiva; registrando entrada vazia.\")\n",
        "        erros.append({\"thumb_path\": thumb_path, \"erro\": \"N√£o foi poss√≠vel obter JSON v√°lido\"})\n",
        "        resultados.append({\n",
        "            \"thumb_path\": thumb_path,\n",
        "            \"titulo\": \"\",\n",
        "            \"descricao\": \"\",\n",
        "            \"hashtags\": [],\n",
        "            \"tags\": \"\",\n",
        "            \"categoria\": \"\"\n",
        "        })\n",
        "        continue\n",
        "\n",
        "    titulo = conteudo_valido.get(\"titulo\", \"\").strip()\n",
        "    titulos_gerados.append(titulo)\n",
        "\n",
        "    resultados.append({\n",
        "        \"thumb_path\": thumb_path,\n",
        "        \"titulo\": titulo,\n",
        "        \"descricao\": conteudo_valido.get(\"descricao\", \"\").strip(),\n",
        "        \"hashtags\": conteudo_valido.get(\"hashtags\", []),\n",
        "        \"tags\": conteudo_valido.get(\"tags\", \"\").strip(),\n",
        "        \"categoria\": str(conteudo_valido.get(\"categoria\", \"\")).strip()\n",
        "    })\n",
        "\n",
        "    if i < len(records):\n",
        "        time.sleep(2)\n",
        "\n",
        "# ---------- Salvar ----------\n",
        "seo_payload = {\n",
        "    \"created_from_manifest\": str(manifest_path),\n",
        "    \"created_from_transcript\": str(transcript_path),\n",
        "    \"created_at\": datetime.now().strftime(\"%Y%m%d_%H%M%S\"),\n",
        "    \"items\": resultados\n",
        "}\n",
        "\n",
        "with open(seo_out_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(seo_payload, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "print(\"\\nüìå RESUMO\")\n",
        "ok_count = sum(1 for r in resultados if r.get(\"titulo\"))\n",
        "print(f\"   ‚úÖ Sucesso: {ok_count}\")\n",
        "print(f\"   ‚ùå Erros: {len(erros)}\")\n",
        "print(f\"   üíæ Arquivo salvo: {seo_out_path}\")\n",
        "\n",
        "if erros:\n",
        "    print(\"\\nüö® Itens com erro:\")\n",
        "    for e in erros:\n",
        "        print(f\"   - {e['thumb_path']}: {e['erro']}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RtL4zSS92zXN",
        "outputId": "4e295507-b1eb-49a5-ff6a-b16f0f878181"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üì• Lendo SEO: /content/08 - SEO/20251117_134418_thumbs_right_seo.json\n",
            "üìä Itens carregados: 3\n",
            "\n",
            "üîÑ FORMATANDO...\n",
            "------------------------------------------------------------\n",
            "   ‚úÖ T01_20251117_134418_thumb_01_right: OK\n",
            "      üìù T√≠tulo: 68 chars\n",
            "      üìÑ Descri√ß√£o: 1853 chars\n",
            "      üè∑Ô∏è  Tags: 372 chars\n",
            "      üìÇ Categoria: 19 (Travel & Events)\n",
            "   ‚úÖ T02_20251117_134418_thumb_02_right: OK\n",
            "      üìù T√≠tulo: 65 chars\n",
            "      üìÑ Descri√ß√£o: 1774 chars\n",
            "      üè∑Ô∏è  Tags: 366 chars\n",
            "      üìÇ Categoria: 19 (Travel & Events)\n",
            "   ‚úÖ T03_20251117_134418_thumb_03_right: OK\n",
            "      üìù T√≠tulo: 72 chars\n",
            "      üìÑ Descri√ß√£o: 1925 chars\n",
            "      üè∑Ô∏è  Tags: 365 chars\n",
            "      üìÇ Categoria: 19 (Travel & Events)\n",
            "\n",
            "üìå RESUMO\n",
            "   ‚úÖ Processados: 3\n",
            "   ‚ùå Com erros:   0\n",
            "   üíæ Arquivo salvo: /content/08 - SEO/20251117_134418_thumbs_right_seo_formatados.json\n"
          ]
        }
      ],
      "source": [
        "# ==============================================\n",
        "# üß© Colab ‚Äî C√©lula de apoio de FORMATA√á√ÉO (baseada em formatar.py)\n",
        "# L√™:  /content/08 - SEO/<base>_thumbs_right_seo.json\n",
        "# Grava: /content/08 - SEO/<base>_thumbs_right_seo_formatados.json\n",
        "# ==============================================\n",
        "import json, re, glob\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "\n",
        "SEO_DIR = Path(\"/content/08 - SEO\")\n",
        "SEO_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# ==============================================\n",
        "# Prefer√™ncia: usar o mesmo basename do job\n",
        "PREFERRED_BASENAME = \"20251117_134418_thumbs_right_seo.json\"\n",
        "# ==============================================\n",
        "\n",
        "# Descobre o arquivo de entrada\n",
        "candidates = []\n",
        "pref = SEO_DIR / PREFERRED_BASENAME\n",
        "if pref.exists():\n",
        "    candidates = [pref]\n",
        "else:\n",
        "    candidates = sorted(SEO_DIR.glob(\"*_thumbs_right_seo.json\"), key=lambda p: p.stat().st_mtime, reverse=True)\n",
        "\n",
        "if not candidates:\n",
        "    raise FileNotFoundError(\"Nenhum arquivo '*_thumbs_right_seo.json' encontrado em /content/08 - SEO\")\n",
        "\n",
        "seo_in_path = candidates[0]\n",
        "base_name = seo_in_path.stem  # ex.: 20251005_190946_thumbs_right_seo\n",
        "seo_out_path = seo_in_path.with_name(base_name + \"_formatados.json\")\n",
        "\n",
        "print(f\"üì• Lendo SEO: {seo_in_path}\")\n",
        "with open(seo_in_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    payload = json.load(f)\n",
        "\n",
        "items = payload.get(\"items\", [])\n",
        "print(f\"üìä Itens carregados: {len(items)}\")\n",
        "\n",
        "# --------- Utilit√°rios (baseados no formatar.py) ---------\n",
        "def limitar_titulo(titulo: str) -> str:\n",
        "    titulo = (titulo or \"\").strip()\n",
        "    if len(titulo) <= 100:\n",
        "        return titulo\n",
        "    # remove sufixos ap√≥s \"#\" at√© caber\n",
        "    t = titulo\n",
        "    while len(t) > 100 and \"#\" in t:\n",
        "        partes = t.rsplit(\"#\", 1)\n",
        "        t = partes[0].strip()\n",
        "    return t[:100]\n",
        "\n",
        "def limitar_tags(tags: str) -> str:\n",
        "    tags = (tags or \"\").strip()\n",
        "    if len(tags) <= 450:\n",
        "        return tags\n",
        "    lista = [t.strip() for t in tags.split(\",\") if t.strip()]\n",
        "    tags_final = []\n",
        "    total = 0\n",
        "    for t in lista:\n",
        "        t_len = len(t) + 2  # v√≠rgula + espa√ßo\n",
        "        if total + t_len > 450:\n",
        "            break\n",
        "        tags_final.append(t)\n",
        "        total += t_len\n",
        "    return \", \".join(tags_final)\n",
        "\n",
        "def obter_nome_categoria(categoria_id: str) -> str:\n",
        "    categorias = {\n",
        "        \"1\": \"Film & Animation\", \"2\": \"Autos & Vehicles\", \"10\": \"Music\",\n",
        "        \"15\": \"Pets & Animals\", \"17\": \"Sports\", \"18\": \"Short Movies\",\n",
        "        \"19\": \"Travel & Events\", \"20\": \"Gaming\", \"21\": \"Videoblogging\",\n",
        "        \"22\": \"People & Blogs\", \"23\": \"Comedy\", \"24\": \"Entertainment\",\n",
        "        \"25\": \"News & Politics\", \"26\": \"Howto & Style\", \"27\": \"Education\",\n",
        "        \"28\": \"Science & Technology\", \"29\": \"Nonprofits & Activism\",\n",
        "    }\n",
        "    return categorias.get(str(categoria_id), \"Unknown Category\")\n",
        "\n",
        "def obter_links_canal(titulo_video: str):\n",
        "    # Heur√≠stica do seu formatar.py\n",
        "    if \"BATALHA DE MITOS\" in (titulo_video or \"\").upper():\n",
        "        return {\n",
        "            \"hashtag\": \"#BatalhaDeMitos\",\n",
        "            \"youtube\": \"https://www.youtube.com/@batalhademitos\",\n",
        "            \"music\": \"https://music.youtube.com/channel/UCCMpetDDPRoqWamD_U8NWJA\",\n",
        "            \"facebook\": \"https://www.facebook.com/batalhademitos\",\n",
        "            \"instagram\": \"https://www.instagram.com/batalhademitos\"\n",
        "        }\n",
        "    else:\n",
        "        return {\n",
        "            \"hashtag\": \"#RamonSantos\",\n",
        "            \"youtube\": \"https://www.youtube.com/@ramon.santos\",\n",
        "            \"music\": \"https://music.youtube.com/@ramon.santos\",\n",
        "            \"facebook\": \"https://www.facebook.com/RamonSantanaSantos\",\n",
        "            \"instagram\": \"https://www.instagram.com/ramonhardcall\"\n",
        "        }\n",
        "\n",
        "def join_hashtags(ht):\n",
        "    # Entrada pode ser lista ou string; devolve string\n",
        "    if isinstance(ht, list):\n",
        "        # mant√©m # e junta com espa√ßo\n",
        "        return \" \".join([h.strip() for h in ht if h and isinstance(h, str)])\n",
        "    return str(ht or \"\").strip()\n",
        "\n",
        "def normalize_tags_field(tags_field):\n",
        "    # Entrada pode ser string com v√≠rgulas ou lista; devolve string com v√≠rgulas\n",
        "    if isinstance(tags_field, list):\n",
        "        return \", \".join([t.strip() for t in tags_field if isinstance(t, str) and t.strip()])\n",
        "    return str(tags_field or \"\").strip()\n",
        "\n",
        "def ensure_three_paragraphs(desc: str) -> str:\n",
        "    # Opcional: ajusta quebras de linha para n√£o virar um bloco gigante\n",
        "    if not desc:\n",
        "        return \"\"\n",
        "    # normaliza espa√ßos\n",
        "    desc = re.sub(r\"\\s+\\n\", \"\\n\", desc)\n",
        "    desc = re.sub(r\"\\n\\s+\", \"\\n\", desc)\n",
        "    desc = re.sub(r\"\\r\\n\", \"\\n\", desc)\n",
        "    # garante no m√≠nimo duas quebras entre par√°grafos\n",
        "    parts = [p.strip() for p in re.split(r\"\\n{2,}\", desc) if p.strip()]\n",
        "    return \"\\n\\n\".join(parts)\n",
        "\n",
        "# --------- Processamento ---------\n",
        "formatados = []\n",
        "erros = []\n",
        "\n",
        "print(\"\\nüîÑ FORMATANDO...\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "for i, it in enumerate(items, 1):\n",
        "    thumb_path = it.get(\"thumb_path\", \"\")\n",
        "    titulo     = limitar_titulo(it.get(\"titulo\", \"\"))\n",
        "    descricao  = ensure_three_paragraphs(it.get(\"descricao\", \"\"))\n",
        "    hashtags_s = join_hashtags(it.get(\"hashtags\", []))\n",
        "    tags_s     = normalize_tags_field(it.get(\"tags\", \"\"))\n",
        "    categoria  = str(it.get(\"categoria\", \"19\")).strip() or \"19\"\n",
        "\n",
        "    # C√≥digo amig√°vel para rastrear (usa filename da thumb)\n",
        "    stem = Path(thumb_path).stem if thumb_path else f\"thumb_{i:02d}\"\n",
        "    codigo = f\"T{i:02d}_{stem}\"\n",
        "\n",
        "    if not titulo:\n",
        "        erros.append({\"codigo\": codigo, \"erro\": \"T√≠tulo vazio\"})\n",
        "        print(f\"   ‚ùå {codigo}: T√≠tulo vazio\")\n",
        "        continue\n",
        "\n",
        "    if not tags_s:\n",
        "        erros.append({\"codigo\": codigo, \"erro\": \"Tags vazias\"})\n",
        "        print(f\"   ‚ùå {codigo}: Tags vazias\")\n",
        "        continue\n",
        "\n",
        "    # Limites\n",
        "    tags_s = limitar_tags(tags_s)\n",
        "\n",
        "    # Links do canal + bloco final (mesma l√≥gica do seu script)\n",
        "    links_canal = obter_links_canal(titulo)\n",
        "    padrao_envio = (\n",
        "        f\"\\n{links_canal['hashtag']}\\n\\n\"\n",
        "        f\"{links_canal['youtube']}\\n\"\n",
        "        f\"{links_canal['music']}\\n\"\n",
        "        f\"{links_canal['facebook']}\\n\"\n",
        "        f\"{links_canal['instagram']}\\n\\n\"\n",
        "        \"Wise (Cart√£o Internacional): https://wise.com/invite/u/ramons728\\n\"\n",
        "        \"Filmora (Programa de Edi√ß√£o): https://filmora.wondershare.com/fission/invite?share_code=25P25EuGecr&referral_id=435&lang=pt-br\\n\\n\"\n",
        "        \"Suno (M√∫sicas com IA): https://app.musicdonna.com/36BOp4Ce\\n\"\n",
        "        \"Donna (M√∫sicas com IA): https://suno.com/invite/@vievim\\n\\n\"\n",
        "        \"Opus Clip (Shorts Autom√°ticos): https://www.opus.pro/?via=757dde\"\n",
        "    )\n",
        "\n",
        "    # Injeta HASHTAGS + bloco final ao t√©rmino da descri√ß√£o (evita duplicar se j√° houver)\n",
        "    if \"HASHTAGS\" not in descricao.upper():\n",
        "        if hashtags_s:\n",
        "            descricao = f\"{descricao}\\n\\nHASHTAGS\\n{hashtags_s}\\n{padrao_envio}\"\n",
        "        else:\n",
        "            descricao = f\"{descricao}\\n{padrao_envio}\"\n",
        "\n",
        "    nome_categoria = obter_nome_categoria(categoria)\n",
        "\n",
        "    # Monta item final\n",
        "    out_item = {\n",
        "        \"codigo\": codigo,\n",
        "        \"thumb_path\": thumb_path,\n",
        "        \"titulo\": titulo,\n",
        "        \"descricao\": descricao,\n",
        "        \"tags\": tags_s,\n",
        "        \"categoria\": categoria\n",
        "    }\n",
        "    formatados.append(out_item)\n",
        "\n",
        "    # Logs\n",
        "    print(f\"   ‚úÖ {codigo}: OK\")\n",
        "    print(f\"      üìù T√≠tulo: {len(titulo)} chars\")\n",
        "    print(f\"      üìÑ Descri√ß√£o: {len(descricao)} chars\")\n",
        "    print(f\"      üè∑Ô∏è  Tags: {len(tags_s)} chars\")\n",
        "    print(f\"      üìÇ Categoria: {categoria} ({nome_categoria})\")\n",
        "\n",
        "# --------- Salvar ---------\n",
        "out_payload = {\n",
        "    \"created_from\": str(seo_in_path),\n",
        "    \"created_at\": datetime.now().strftime(\"%Y%m%d_%H%M%S\"),\n",
        "    \"count_ok\": len(formatados),\n",
        "    \"count_err\": len(erros),\n",
        "    \"items\": formatados\n",
        "}\n",
        "\n",
        "with open(seo_out_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(out_payload, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "print(\"\\nüìå RESUMO\")\n",
        "print(f\"   ‚úÖ Processados: {len(formatados)}\")\n",
        "print(f\"   ‚ùå Com erros:   {len(erros)}\")\n",
        "print(f\"   üíæ Arquivo salvo: {seo_out_path}\")\n",
        "\n",
        "if erros:\n",
        "    print(\"\\nüö® Erros:\")\n",
        "    for e in erros:\n",
        "        print(f\"   ‚ùå {e['codigo']}: {e['erro']}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vFlWKl7F2-tS"
      },
      "source": [
        "# Youtube"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 508
        },
        "id": "wKJbUOt83AkC",
        "outputId": "5a0473e2-03a3-4721-e3e3-3e1ccb4169f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîê INICIANDO AUTENTICA√á√ÉO COM YOUTUBE\n",
            "========================================\n",
            "üìÅ Base do m√≥dulo: /content/09 - Youtube\n",
            "üìÇ Credenciais:    /content/09 - Youtube/api-youtube\n",
            "üîë Token:          /content/09 - Youtube/token/token.json\n",
            "üì§ Nenhuma credencial encontrada. Envie o arquivo client_secret_*.json‚Ä¶\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-5cfd21be-7577-4a35-ad5c-b25227d0454e\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-5cfd21be-7577-4a35-ad5c-b25227d0454e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving client_secret_792731767818-84rh1ug3v4ufm5oicgkfcdf7l71h3a51.apps.googleusercontent.com.json to client_secret_792731767818-84rh1ug3v4ufm5oicgkfcdf7l71h3a51.apps.googleusercontent.com.json\n",
            "   ‚úÖ Salvo: /content/09 - Youtube/api-youtube/client_secret_792731767818-84rh1ug3v4ufm5oicgkfcdf7l71h3a51.apps.googleusercontent.com.json\n",
            "‚úÖ Credencial v√°lida: client_secret_792731767818-84rh1ug3v4ufm5oicgkfcdf7l71h3a51.apps.googleusercontent.com.json\n",
            "üìã Carregando credenciais OAuth2‚Ä¶\n",
            "‚Ü™Ô∏è redirect_uris no client_secret:\n",
            "   - http://localhost\n",
            "‚úÖ redirect_uri selecionado: http://localhost\n",
            "   üåê Modo manual com redirect_uri: http://localhost\n",
            "\n",
            "üîó Abra esta URL, autorize (ok se aparecer erro de localhost) e COPIE a URL de retorno:\n",
            "https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=792731767818-84rh1ug3v4ufm5oicgkfcdf7l71h3a51.apps.googleusercontent.com&redirect_uri=http%3A%2F%2Flocalhost&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fyoutube.upload+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fyoutube.force-ssl&state=bzx4covh8jSMw6p3A2vj85EfHF76QK&access_type=offline&include_granted_scopes=true&prompt=consent\n",
            "\n",
            "Cole a URL COMPLETA de redirecionamento (ou s√≥ o valor de 'code'):\n",
            "http://localhost/?state=bzx4covh8jSMw6p3A2vj85EfHF76QK&code=4/0Ab32j92I06n7ZRIaM3ZivD8iaZDUJwDIy1O62Pe2Iypz2UfwUm9KrSTQESWRAPT6i_ToEg&scope=https://www.googleapis.com/auth/youtube.force-ssl%20https://www.googleapis.com/auth/youtube.upload\n",
            "üíæ Salvando token‚Ä¶\n",
            "   ‚úÖ Token salvo em: /content/09 - Youtube/token/token.json\n",
            "üß™ Testando YouTube API‚Ä¶\n",
            "üéâ Conectado ao canal: Ramon Santos | ID: UCcrRJvZ-_tbb-RlMeN3dCeA\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<googleapiclient.discovery.Resource at 0x7bb4d8defad0>"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# ==============================================\n",
        "# üîê Sess√£o YouTube ‚Äî AUTENTICAR (robusto p/ Colab)\n",
        "#  - Extrai 'code' da URL e usa fetch_token(code=...)\n",
        "#  - Evita InsecureTransportError (http://localhost)\n",
        "#  - Cria pasta /content/09 - Youtube/{api-youtube,token}\n",
        "# ==============================================\n",
        "!pip -q install \"google-auth-oauthlib>=1.2.0\" \"google-api-python-client>=2.0.0\"\n",
        "\n",
        "import os, json, time\n",
        "from pathlib import Path\n",
        "from typing import Optional, Tuple, List\n",
        "from urllib.parse import urlparse, parse_qs\n",
        "\n",
        "# üîì Permite transporte inseguro (apenas para fluxo local/Colab com http://localhost)\n",
        "os.environ[\"OAUTHLIB_INSECURE_TRANSPORT\"] = \"1\"\n",
        "\n",
        "from google_auth_oauthlib.flow import InstalledAppFlow\n",
        "from googleapiclient.discovery import build\n",
        "\n",
        "# ---------- Caminhos ----------\n",
        "BASE_DIR      = Path(\"/content\")\n",
        "YT_DIR        = BASE_DIR / \"09 - Youtube\"\n",
        "PASTA_CRED    = YT_DIR / \"api-youtube\"\n",
        "PASTA_TOKEN   = YT_DIR / \"token\"\n",
        "for p in (YT_DIR, PASTA_CRED, PASTA_TOKEN):\n",
        "    p.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# (opcional) fixe aqui o seu client_secret novo (Desktop app):\n",
        "ARQUIVO_CREDENCIAL_FIXO = None\n",
        "ARQUIVO_TOKEN = PASTA_TOKEN / \"token.json\"\n",
        "\n",
        "# ---------- Escopos ----------\n",
        "SCOPES = [\n",
        "    \"https://www.googleapis.com/auth/youtube.upload\",\n",
        "    \"https://www.googleapis.com/auth/youtube.force-ssl\",\n",
        "]\n",
        "\n",
        "# ---------- Helpers ----------\n",
        "def _is_colab() -> bool:\n",
        "    try:\n",
        "        import google.colab  # type: ignore\n",
        "        return True\n",
        "    except Exception:\n",
        "        return False\n",
        "\n",
        "def _listar_candidatos_credencial() -> List[Path]:\n",
        "    candidatos = []\n",
        "    candidatos += list(PASTA_CRED.glob(\"client_secret*.json\"))\n",
        "    candidatos += list(BASE_DIR.glob(\"client_secret*.json\"))\n",
        "    candidatos += list(PASTA_CRED.glob(\"*oauth*.json\"))\n",
        "    candidatos += list(BASE_DIR.glob(\"*oauth*.json\"))\n",
        "    candidatos = [p for p in candidatos if p.exists()]\n",
        "    candidatos.sort(key=lambda p: p.stat().st_mtime, reverse=True)\n",
        "    uniq, seen = [], set()\n",
        "    for p in candidatos:\n",
        "        rp = p.resolve()\n",
        "        if rp not in seen:\n",
        "            uniq.append(p); seen.add(rp)\n",
        "    return uniq\n",
        "\n",
        "def _solicitar_upload_credencial() -> Optional[Path]:\n",
        "    if not _is_colab():\n",
        "        return None\n",
        "    try:\n",
        "        from google.colab import files  # type: ignore\n",
        "        print(\"üì§ Nenhuma credencial encontrada. Envie o arquivo client_secret_*.json‚Ä¶\")\n",
        "        uploaded = files.upload()\n",
        "        if not uploaded:\n",
        "            print(\"‚ö†Ô∏è Upload cancelado.\")\n",
        "            return None\n",
        "        ultimo = None\n",
        "        for nome, conteudo in uploaded.items():\n",
        "            destino = PASTA_CRED / Path(nome).name\n",
        "            with open(destino, \"wb\") as f:\n",
        "                f.write(conteudo)\n",
        "            print(f\"   ‚úÖ Salvo: {destino}\")\n",
        "            ultimo = destino\n",
        "        return ultimo\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Falha no upload: {e}\")\n",
        "        return None\n",
        "\n",
        "def _encontrar_credencial() -> Path:\n",
        "    if ARQUIVO_CREDENCIAL_FIXO and Path(ARQUIVO_CREDENCIAL_FIXO).exists():\n",
        "        return Path(ARQUIVO_CREDENCIAL_FIXO)\n",
        "    candidatos = _listar_candidatos_credencial()\n",
        "    if candidatos:\n",
        "        print(\"üîé Poss√≠veis credenciais:\")\n",
        "        for i, c in enumerate(candidatos[:5], 1):\n",
        "            print(f\"   {i:02d}. {c}\")\n",
        "        return candidatos[0]\n",
        "    cred = _solicitar_upload_credencial()\n",
        "    if cred and cred.exists():\n",
        "        return cred\n",
        "    raise FileNotFoundError(\n",
        "        \"‚ùå Arquivo de credenciais n√£o encontrado.\\n\"\n",
        "        f\"‚Üí Envie client_secret_*.json para {PASTA_CRED} (ou para {BASE_DIR}).\"\n",
        "    )\n",
        "\n",
        "def _listar_redirect_uris(cred_path: Path) -> List[str]:\n",
        "    data = json.loads(cred_path.read_text(encoding=\"utf-8\"))\n",
        "    uris = []\n",
        "    if \"installed\" in data:\n",
        "        uris = data[\"installed\"].get(\"redirect_uris\", []) or []\n",
        "    elif \"web\" in data:\n",
        "        uris = data[\"web\"].get(\"redirect_uris\", []) or []\n",
        "    return [u.rstrip(\"/\") for u in uris if isinstance(u, str)]\n",
        "\n",
        "def _obter_redirect_uri(cred_path: Path) -> str:\n",
        "    uris = _listar_redirect_uris(cred_path)\n",
        "    print(\"‚Ü™Ô∏è redirect_uris no client_secret:\")\n",
        "    for u in uris:\n",
        "        print(\"   -\", u)\n",
        "    # Preferir o 1¬∫ localhost do JSON\n",
        "    for u in uris:\n",
        "        if u.startswith(\"http://localhost\"):\n",
        "            print(\"‚úÖ redirect_uri selecionado:\", u)\n",
        "            return u\n",
        "    # fallback seguro p/ Desktop App (normalmente presente)\n",
        "    fallback = \"http://localhost\"\n",
        "    print(\"‚ö†Ô∏è Nenhum localhost listado. Usando fallback:\", fallback)\n",
        "    return fallback\n",
        "\n",
        "def verificar_credenciais(path: Path) -> bool:\n",
        "    try:\n",
        "        data = json.loads(path.read_text(encoding=\"utf-8\"))\n",
        "        ok = (\"installed\" in data or \"web\" in data)\n",
        "        print(f\"{'‚úÖ' if ok else '‚ùå'} Credencial {'v√°lida' if ok else 'inv√°lida'}: {path.name}\")\n",
        "        return ok\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Erro ao ler credencial: {e}\")\n",
        "        return False\n",
        "\n",
        "def verificar_token_existente() -> Tuple[bool, Optional[any]]:\n",
        "    if not ARQUIVO_TOKEN.exists():\n",
        "        return False, None\n",
        "    try:\n",
        "        print(\"üîç Verificando token existente‚Ä¶\")\n",
        "        from google.oauth2.credentials import Credentials\n",
        "        credentials = Credentials.from_authorized_user_file(str(ARQUIVO_TOKEN), SCOPES)\n",
        "        youtube = build(\"youtube\", \"v3\", credentials=credentials)\n",
        "        channels = youtube.channels().list(part=\"snippet\", mine=True).execute()\n",
        "        if channels.get(\"items\"):\n",
        "            ch = channels[\"items\"][0]\n",
        "            print(f\"‚úÖ Token v√°lido ‚Äî Canal: {ch['snippet']['title']} | ID: {ch['id']}\")\n",
        "            return True, youtube\n",
        "        print(\"‚ö†Ô∏è Token lido, mas nenhum canal acess√≠vel.\")\n",
        "        return False, None\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Token inv√°lido/expirado: {e}\")\n",
        "        return False, None\n",
        "\n",
        "def perguntar_opcao_autenticacao(channel_name: str) -> str:\n",
        "    print(\"\\n‚ùì OP√á√ïES DE AUTENTICA√á√ÉO\")\n",
        "    print(\"=\" * 32)\n",
        "    print(f\"üì∫ Canal atual: {channel_name}\")\n",
        "    print(\"1) Manter autentica√ß√£o atual\")\n",
        "    print(\"2) Autenticar em outro canal\")\n",
        "    print(\"3) Sair\")\n",
        "    while True:\n",
        "        try:\n",
        "            op = input(\"‚Üí Escolha (1/2/3): \").strip()\n",
        "            if op in (\"1\", \"2\", \"3\"):\n",
        "                return {\"1\": \"manter\", \"2\": \"novo\", \"3\": \"sair\"}[op]\n",
        "            print(\"Digite 1, 2 ou 3.\")\n",
        "        except KeyboardInterrupt:\n",
        "            return \"sair\"\n",
        "\n",
        "def forcar_nova_autenticacao() -> bool:\n",
        "    try:\n",
        "        if ARQUIVO_TOKEN.exists():\n",
        "            ARQUIVO_TOKEN.unlink()\n",
        "            print(\"üóëÔ∏è Token anterior removido.\")\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Erro ao remover token: {e}\")\n",
        "        return False\n",
        "\n",
        "def _fluxo_console_manual(flow: InstalledAppFlow, redirect_uri: str):\n",
        "    \"\"\"\n",
        "    Fluxo manual robusto:\n",
        "      - Define redirect_uri\n",
        "      - Gera authorization_url\n",
        "      - Usu√°rio cola a URL de retorno ou s√≥ o 'code'\n",
        "      - Extra√≠mos o 'code' (se veio a URL) e chamamos fetch_token(code=...)\n",
        "        ‚Üí evita InsecureTransportError de URLs http://localhost\n",
        "    \"\"\"\n",
        "    flow.redirect_uri = redirect_uri\n",
        "    auth_url, _ = flow.authorization_url(\n",
        "        access_type=\"offline\",\n",
        "        include_granted_scopes=\"true\",\n",
        "        prompt=\"consent\",\n",
        "    )\n",
        "    print(\"\\nüîó Abra esta URL, autorize (ok se aparecer erro de localhost) e COPIE a URL de retorno:\")\n",
        "    print(auth_url)\n",
        "    resposta = input(\"\\nCole a URL COMPLETA de redirecionamento (ou s√≥ o valor de 'code'):\\n\").strip()\n",
        "\n",
        "    # Se vier URL, extrai 'code'; se vier code puro, usa direto\n",
        "    code = resposta\n",
        "    if resposta.lower().startswith(\"http\"):\n",
        "        parsed = urlparse(resposta)\n",
        "        qs = parse_qs(parsed.query)\n",
        "        code = (qs.get(\"code\") or [None])[0]\n",
        "        if not code:\n",
        "            raise RuntimeError(\"N√£o encontrei 'code' na URL. Cole a URL completa de retorno do Google (com ?code=...).\")\n",
        "\n",
        "    try:\n",
        "        flow.fetch_token(code=code)\n",
        "    except Exception as e:\n",
        "        # Mensagens mais claras para casos comuns\n",
        "        msg = str(e)\n",
        "        if \"invalid_grant\" in msg:\n",
        "            raise RuntimeError(\"C√≥digo inv√°lido/expirado. Gere um novo abrindo a URL novamente e cole o 'code' imediato.\") from e\n",
        "        raise\n",
        "\n",
        "    return flow.credentials\n",
        "\n",
        "def _autenticar_fluxo(cred_path: Path):\n",
        "    flow = InstalledAppFlow.from_client_secrets_file(str(cred_path), SCOPES)\n",
        "\n",
        "    # Fora do Colab, tenta servidor local\n",
        "    if not _is_colab():\n",
        "        for porta in [8080, 8081, 8082, 8083, 8084]:\n",
        "            try:\n",
        "                print(f\"   üîå Tentando run_local_server na porta {porta}‚Ä¶\")\n",
        "                creds = flow.run_local_server(\n",
        "                    port=porta, access_type=\"offline\", prompt=\"consent\", open_browser=True\n",
        "                )\n",
        "                print(f\"   ‚úÖ Autenticado via servidor local (porta {porta}).\")\n",
        "                return creds\n",
        "            except Exception as e:\n",
        "                print(f\"   ‚ö†Ô∏è run_local_server falhou ({e}). Indo para modo manual‚Ä¶\")\n",
        "                break\n",
        "\n",
        "    # Colab / fallback manual\n",
        "    redirect_uri = _obter_redirect_uri(cred_path)\n",
        "    print(f\"   üåê Modo manual com redirect_uri: {redirect_uri}\")\n",
        "    return _fluxo_console_manual(flow, redirect_uri)\n",
        "\n",
        "def autenticar_youtube():\n",
        "    print(\"üîê INICIANDO AUTENTICA√á√ÉO COM YOUTUBE\")\n",
        "    print(\"=\" * 40)\n",
        "    print(f\"üìÅ Base do m√≥dulo: {YT_DIR}\")\n",
        "    print(f\"üìÇ Credenciais:    {PASTA_CRED}\")\n",
        "    print(f\"üîë Token:          {ARQUIVO_TOKEN}\")\n",
        "\n",
        "    # 1) Token existente?\n",
        "    token_ok, yt = verificar_token_existente()\n",
        "    if token_ok:\n",
        "        try:\n",
        "            chs = yt.channels().list(part=\"snippet\", mine=True).execute()\n",
        "            if chs.get(\"items\"):\n",
        "                canal = chs[\"items\"][0][\"snippet\"][\"title\"]\n",
        "                op = perguntar_opcao_autenticacao(canal)\n",
        "                if op == \"manter\":\n",
        "                    print(\"‚úÖ Mantendo autentica√ß√£o atual.\")\n",
        "                    return yt\n",
        "                elif op == \"novo\":\n",
        "                    print(\"üîÑ Nova autentica√ß√£o solicitada‚Ä¶\")\n",
        "                    if not forcar_nova_autenticacao():\n",
        "                        raise RuntimeError(\"Falha ao limpar token.\")\n",
        "                else:\n",
        "                    print(\"üëã Saindo da autentica√ß√£o.\")\n",
        "                    return None\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Erro ao verificar canal atual: {e}. Prosseguindo com nova autentica√ß√£o‚Ä¶\")\n",
        "\n",
        "    # 2) Credenciais\n",
        "    cred_path = _encontrar_credencial()\n",
        "    if not verificar_credenciais(cred_path):\n",
        "        raise FileNotFoundError(\"Credencial inv√°lida ou ausente.\")\n",
        "\n",
        "    # 3) OAuth\n",
        "    print(\"üìã Carregando credenciais OAuth2‚Ä¶\")\n",
        "    creds = _autenticar_fluxo(cred_path)\n",
        "\n",
        "    # 4) Salvar token\n",
        "    print(\"üíæ Salvando token‚Ä¶\")\n",
        "    with open(ARQUIVO_TOKEN, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(creds.to_json())\n",
        "    print(f\"   ‚úÖ Token salvo em: {ARQUIVO_TOKEN}\")\n",
        "\n",
        "    # 5) Testar\n",
        "    print(\"üß™ Testando YouTube API‚Ä¶\")\n",
        "    yt = build(\"youtube\", \"v3\", credentials=creds)\n",
        "    try:\n",
        "        chs = yt.channels().list(part=\"snippet\", mine=True).execute()\n",
        "        if chs.get(\"items\"):\n",
        "            ch = chs[\"items\"][0]\n",
        "            print(f\"üéâ Conectado ao canal: {ch['snippet']['title']} | ID: {ch['id']}\")\n",
        "        else:\n",
        "            print(\"‚ö†Ô∏è Conectado, mas nenhum canal retornado.\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Conectado, mas falha ao ler canal: {e}\")\n",
        "\n",
        "    return yt\n",
        "\n",
        "# ---- Executar imediatamente ----\n",
        "youtube = autenticar_youtube()\n",
        "youtube\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5OEUo6h9AsWr",
        "outputId": "6b353493-cdec-42b6-b003-b5e2e2866403"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìÑ SEO: /content/08 - SEO/20251117_134418_thumbs_right_seo_formatados.json\n",
            "\n",
            "üßæ PREVIEW\n",
            "T√≠tulo: ‚úàÔ∏è RUMO A CURITIBA NA EXPO MOTORHOME #AeroportoDeCongonhas #Curitiba\n",
            "Categoria: 19\n",
            "Tags: ['Aeroporto de Congonhas', 'Curitiba', 'Expo Motorhome', 'viagem de avi√£o', 'turismo em Curitiba', 'motorhome', 'aventura em Curitiba', 'voo tranquilo', 'Ana Maria', 'aeroporto de Curitiba', 'arquitetura moderna', 'viagem em fam√≠lia', 'dicas de viagem', 'turismo no Brasil', 'clima em Curitiba', 'aeroporto brasileiro', 'experi√™ncias de viagem', 'bolsa de viagem', 'aeroporto movimentado', 'embarque em aeroporto'] \n",
            "V√≠deo: /content/05 - Final/20251117_134644_FINAL.mp4\n",
            "Thumb: /content/07 - Thumbnails/20251117_134418_thumb_01_right.jpg\n",
            "Privacidade: unlisted\n",
            "\n",
            "üöÄ Enviando v√≠deo‚Ä¶\n",
            "‚úÖ Upload ok: https://www.youtube.com/watch?v=gA_Dq8LIqn0\n",
            "üñºÔ∏è Aplicando thumbnail (thumb #1)‚Ä¶\n",
            "‚úÖ Thumbnail definida.\n",
            "\n",
            "‚ÑπÔ∏è Teste A/B de thumbnails: n√£o dispon√≠vel na API oficial v3 ‚Äî usando apenas a thumb #1.\n",
            "üíæ Log salvo em: /content/09 - Youtube/20251117_134644_FINAL_upload_log.json\n",
            "üéâ Conclu√≠do!\n"
          ]
        }
      ],
      "source": [
        "# ==============================================\n",
        "# ‚ñ∂Ô∏è Sess√£o YouTube ‚Äî C√âLULA: Enviar v√≠deo com SEO + Thumbnail\n",
        "# Requisitos: rodar a c√©lula de AUTENTICAR antes (gera /content/09 - Youtube/token/token.json)\n",
        "# ==============================================\n",
        "from pathlib import Path\n",
        "import json, os, time, mimetypes\n",
        "from datetime import datetime\n",
        "from typing import List, Optional\n",
        "from googleapiclient.discovery import build\n",
        "from googleapiclient.http import MediaFileUpload\n",
        "from google.oauth2.credentials import Credentials\n",
        "\n",
        "# ---------- Caminhos ----------\n",
        "BASE_DIR      = Path(\"/content\")\n",
        "FINAL_DIR     = BASE_DIR / \"05 - Final\"\n",
        "SEO_DIR       = BASE_DIR / \"08 - SEO\"\n",
        "THUMBS_DIR    = BASE_DIR / \"07 - Thumbnails\"\n",
        "YT_DIR        = BASE_DIR / \"09 - Youtube\"\n",
        "TOKEN_PATH    = YT_DIR / \"token\" / \"token.json\"\n",
        "\n",
        "# ---------- Par√¢metros da execu√ß√£o ----------\n",
        "VIDEO_NAME      = \"20251117_134644_FINAL.mp4\"  # <- pedido do usu√°rio\n",
        "SEO_INDEX       = 1  # 1 = primeiro bloco de SEO (corresponde √† Thumb 1)\n",
        "THUMB_INDEX     = 1  # 1 = primeira thumb do manifest/SEO\n",
        "PRIVACY_STATUS  = \"unlisted\"  # public | unlisted | private\n",
        "\n",
        "# ---------- Utilidades ----------\n",
        "def _load_youtube():\n",
        "    global youtube\n",
        "    try:\n",
        "        youtube  # noqa: F401\n",
        "        return youtube\n",
        "    except NameError:\n",
        "        pass\n",
        "\n",
        "    if not TOKEN_PATH.exists():\n",
        "        raise FileNotFoundError(\"Token n√£o encontrado. Rode a c√©lula de AUTENTICAR.\")\n",
        "    creds = Credentials.from_authorized_user_file(\n",
        "        str(TOKEN_PATH),\n",
        "        scopes=[\"https://www.googleapis.com/auth/youtube.upload\",\n",
        "                \"https://www.googleapis.com/auth/youtube.force-ssl\"]\n",
        "    )\n",
        "    return build(\"youtube\", \"v3\", credentials=creds)\n",
        "\n",
        "def _latest_seo_file() -> Optional[Path]:\n",
        "    cands: List[Path] = []\n",
        "    cands += list(SEO_DIR.glob(\"*_seo_formatados.json\"))\n",
        "    cands += list(SEO_DIR.glob(\"*_seo.json\"))\n",
        "    if not cands:\n",
        "        return None\n",
        "    cands.sort(key=lambda p: p.stat().st_mtime, reverse=True)\n",
        "    return cands[0]\n",
        "\n",
        "def _coerce_tags(v) -> List[str]:\n",
        "    if isinstance(v, list):\n",
        "        return [str(x).strip() for x in v if str(x).strip()]\n",
        "    if isinstance(v, str):\n",
        "        return [t.strip() for t in v.split(\",\") if t.strip()]\n",
        "    return []\n",
        "\n",
        "def _ensure_mime(path: Path) -> str:\n",
        "    mt = mimetypes.guess_type(str(path))[0] or \"application/octet-stream\"\n",
        "    # For√ßa JPEG/PNG se extens√£o for conhecida\n",
        "    if path.suffix.lower() in {\".jpg\", \".jpeg\"}: return \"image/jpeg\"\n",
        "    if path.suffix.lower() == \".png\": return \"image/png\"\n",
        "    return mt\n",
        "\n",
        "# ---------- Carregar SEO ----------\n",
        "seo_file = _latest_seo_file()\n",
        "if not seo_file:\n",
        "    raise FileNotFoundError(\"Nenhum *_seo.json encontrado em /content/08 - SEO.\")\n",
        "print(f\"üìÑ SEO: {seo_file}\")\n",
        "\n",
        "seo = json.loads(seo_file.read_text(encoding=\"utf-8\"))\n",
        "items = seo.get(\"items\") or []\n",
        "if not items:\n",
        "    raise ValueError(\"Arquivo SEO sem 'items'.\")\n",
        "\n",
        "if not (1 <= SEO_INDEX <= len(items)):\n",
        "    raise IndexError(f\"SEO_INDEX={SEO_INDEX} fora do intervalo (1..{len(items)}).\")\n",
        "seo_item = items[SEO_INDEX-1]\n",
        "\n",
        "title   = (seo_item.get(\"titulo\") or \"\").strip()[:100]\n",
        "desc    = (seo_item.get(\"descricao\") or \"\").strip()[:5000]\n",
        "tags    = _coerce_tags(seo_item.get(\"tags\", []))[:500]\n",
        "cat_id  = str(seo_item.get(\"categoria\") or \"19\").strip() or \"19\"\n",
        "\n",
        "thumb_from_seo = seo_item.get(\"thumb_path\") or \"\"\n",
        "thumb_path = Path(thumb_from_seo)\n",
        "if not thumb_path.exists() and thumb_from_seo:\n",
        "    # tenta resolver por nome na pasta 07\n",
        "    thumb_guess = THUMBS_DIR / Path(thumb_from_seo).name\n",
        "    thumb_path = thumb_guess if thumb_guess.exists() else Path()\n",
        "\n",
        "# ---------- Selecionar v√≠deo ----------\n",
        "video_path = FINAL_DIR / VIDEO_NAME\n",
        "if not video_path.exists():\n",
        "    # fallback: procurar pelo nome em qualquer subpasta do FINAL_DIR\n",
        "    try:\n",
        "        video_path = next(FINAL_DIR.rglob(VIDEO_NAME))\n",
        "    except StopIteration:\n",
        "        raise FileNotFoundError(f\"V√≠deo n√£o encontrado: {VIDEO_NAME} em {FINAL_DIR}\")\n",
        "\n",
        "print(\"\\nüßæ PREVIEW\")\n",
        "print(\"T√≠tulo:\", title)\n",
        "print(\"Categoria:\", cat_id)\n",
        "print(\"Tags:\", tags[:20], \"...\" if len(tags) > 20 else \"\")\n",
        "print(\"V√≠deo:\", video_path)\n",
        "print(\"Thumb:\", thumb_path if thumb_path else \"(n√£o encontrada)\")\n",
        "print(\"Privacidade:\", PRIVACY_STATUS)\n",
        "\n",
        "# ---------- Enviar ----------\n",
        "yt = _load_youtube()\n",
        "media = MediaFileUpload(str(video_path), mimetype=\"video/mp4\", resumable=True)\n",
        "\n",
        "body = {\n",
        "    \"snippet\": {\n",
        "        \"title\": title,\n",
        "        \"description\": desc,\n",
        "        \"categoryId\": cat_id,\n",
        "        \"tags\": tags,\n",
        "        \"defaultLanguage\": \"pt-BR\",\n",
        "        \"defaultAudioLanguage\": \"pt-BR\",\n",
        "    },\n",
        "    \"status\": {\n",
        "        \"privacyStatus\": PRIVACY_STATUS,\n",
        "        \"embeddable\": True,\n",
        "        \"selfDeclaredMadeForKids\": False\n",
        "    }\n",
        "}\n",
        "\n",
        "print(\"\\nüöÄ Enviando v√≠deo‚Ä¶\")\n",
        "insert_req = yt.videos().insert(\n",
        "    part=\"snippet,status\",\n",
        "    body=body,\n",
        "    media_body=media,\n",
        "    notifySubscribers=False\n",
        ")\n",
        "resp = insert_req.execute()\n",
        "video_id = resp[\"id\"]\n",
        "print(f\"‚úÖ Upload ok: https://www.youtube.com/watch?v={video_id}\")\n",
        "\n",
        "# ---------- Thumbnail ----------\n",
        "if thumb_path and thumb_path.exists():\n",
        "    print(\"üñºÔ∏è Aplicando thumbnail (thumb #1)‚Ä¶\")\n",
        "    thumb_media = MediaFileUpload(str(thumb_path), mimetype=_ensure_mime(thumb_path))\n",
        "    yt.thumbnails().set(videoId=video_id, media_body=thumb_media).execute()\n",
        "    print(\"‚úÖ Thumbnail definida.\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Thumbnail n√£o encontrada; pulando.\")\n",
        "\n",
        "# ---------- A/B test (nota) ----------\n",
        "# A API oficial (YouTube Data API v3) n√£o exp√µe Test & Compare de thumbnails.\n",
        "# Se futuramente a API permitir, este seria o ponto para enviar varia√ß√µes.\n",
        "print(\"\\n‚ÑπÔ∏è Teste A/B de thumbnails: n√£o dispon√≠vel na API oficial v3 ‚Äî usando apenas a thumb #1.\")\n",
        "\n",
        "# ---------- Log ----------\n",
        "out_dir = YT_DIR\n",
        "out_dir.mkdir(parents=True, exist_ok=True)\n",
        "log_path = out_dir / f\"{video_path.stem}_upload_log.json\"\n",
        "with open(log_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump({\n",
        "        \"video_file\": str(video_path),\n",
        "        \"video_id\": video_id,\n",
        "        \"title\": title,\n",
        "        \"categoryId\": cat_id,\n",
        "        \"tags\": tags,\n",
        "        \"thumb_applied\": str(thumb_path) if thumb_path else \"\",\n",
        "        \"privacy\": PRIVACY_STATUS,\n",
        "        \"seo_source\": str(seo_file),\n",
        "        \"seo_index\": SEO_INDEX,\n",
        "        \"thumb_index\": THUMB_INDEX,\n",
        "        \"created_at\": datetime.now().isoformat()\n",
        "    }, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "print(f\"üíæ Log salvo em: {log_path}\")\n",
        "print(\"üéâ Conclu√≠do!\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
